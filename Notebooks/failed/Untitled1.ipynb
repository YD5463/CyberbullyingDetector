{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d6758a09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:52:28.889495Z",
     "start_time": "2022-01-01T15:52:28.874490Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "import swifter\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Embedding, Conv2D, MaxPooling2D, Dropout,Reshape, Flatten,LSTM\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a1776938",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:52:29.654492Z",
     "start_time": "2022-01-01T15:52:29.647490Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_WORKERS = 8\n",
    "TEST_SIZE = 0.3\n",
    "LABEL_COLUMN_NAME = \"oh_label\"\n",
    "TEXT_COLUMN_NAME = \"Text\"\n",
    "DATASET_PATH = \"../Data/ver1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "46e369a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T17:36:59.861503Z",
     "start_time": "2022-01-01T17:36:59.128609Z"
    }
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv(DATASET_PATH, index_col=False)\n",
    "df = df.dropna()\n",
    "df.drop([\"Unnamed: 0\", \"index\"],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "db0ce725",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T17:33:49.717597Z",
     "start_time": "2022-01-01T17:32:56.141176Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8364e22d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-01T17:37:27.231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3723bd3af0047a39f547ff13132c7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "def word2vecMateix(tokens_list):\n",
    "    vectorized = np.array([word2vec.get_vector(word) for word in tokens_list if word in word2vec ])\n",
    "    if len(vectorized) < 100:\n",
    "            vectorized = np.concatenate([vectorized,  np.zeros((100 - len(vectorized), 300))], axis = None)\n",
    "    if len(vectorized) > 100:\n",
    "            vectorized = vectorized[:100]\n",
    "    return pd.Series(vectorized.flatten())\n",
    "regex = re.compile('[^a-z ]')\n",
    "df[TEXT_COLUMN_NAME] = df[TEXT_COLUMN_NAME].swifter.apply(lambda text: word2vecMateix(regex.sub('',text.lower()).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b29953f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T17:43:38.420792Z",
     "start_time": "2022-01-01T17:43:38.378792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Im 12 and i can understand it perfectly. You s...\n",
       "1        #mkr Boy, @FourinHandyou sure know how to dish...\n",
       "2          Fuck you all. This site is full of stuck up ...\n",
       "3        `   ::I don't disagree with your point, except...\n",
       "4          do i look like i give a fuck, u are all sad ...\n",
       "                               ...                        \n",
       "99995    `  == d15b8 - just you leave it alone ==  ``co...\n",
       "99996     :Thanks for the feedback, and I'm very glad t...\n",
       "99997      ==Fast and Furious 7== Please do your resear...\n",
       "99998                            @KWiebs31 ABLOO BLOO BLOO\n",
       "99999    `  Clearly you know very little about these ba...\n",
       "Name: Text, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[TEXT_COLUMN_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0821eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# df= pd.read_csv(DATASET_PATH, index_col=False)\n",
    "# df = df.dropna()\n",
    "# df.drop([\"Unnamed: 0\", \"index\"],axis=1, inplace = True)\n",
    "# regex = re.compile('[^a-z ]')\n",
    "# df[TEXT_COLUMN_NAME] = df[TEXT_COLUMN_NAME].swifter.apply(lambda text: regex.sub('',text.lower()))\n",
    "# lens = df[TEXT_COLUMN_NAME].swifter.apply(len)\n",
    "# df = df[lens < lens.quantile(.75)]\n",
    "# print(df[LABEL_COLUMN_NAME].value_counts()/df.shape[0])\n",
    "# mask = df[TEXT_COLUMN_NAME].swifter.apply(lambda text: all([word in word2vec for word in text.split()]))\n",
    "# df[mask][LABEL_COLUMN_NAME].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21b232db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:29:03.790226Z",
     "start_time": "2022-01-01T15:27:54.998802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c48c024ee7e48ebb6b1b49370224cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X,y = df[TEXT_COLUMN_NAME],df[LABEL_COLUMN_NAME]\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "X = X.swifter.apply(lambda text: ' '.join([item for item in nltk.word_tokenize(text) if item not in stopwords]))\n",
    "X = X.str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44efe2da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:31:25.109832Z",
     "start_time": "2022-01-01T15:31:20.993243Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower=True)\n",
    "tokenizer.fit_on_texts(X)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9ea6195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:32:06.172832Z",
     "start_time": "2022-01-01T15:32:06.034833Z"
    }
   },
   "outputs": [],
   "source": [
    "not_found = set()\n",
    "for word in word_index:\n",
    "    if word not in word_vectors:\n",
    "        not_found.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d61b3fd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:32:09.334869Z",
     "start_time": "2022-01-01T15:32:08.146872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad99164b5411427fbed8837e28ccab35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = X.swifter.apply(lambda text: ' '.join([item for item in text.split() if item.lower() not in not_found]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24a848f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:23:07.359293Z",
     "start_time": "2022-01-01T15:23:07.349292Z"
    }
   },
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# results = Counter()\n",
    "# X.str.lower().str.split().apply(results.update)\n",
    "# counts = pd.DataFrame.from_dict(results, orient='index').reset_index()\n",
    "# counts.columns = [\"index\",\"count\"]\n",
    "# counts = counts.sort_values(\"count\",ascending=False).reset_index(drop=True)\n",
    "# counts['count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d72c3c71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:42:26.251874Z",
     "start_time": "2022-01-01T15:42:26.210878Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test, y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "021b59ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:32:37.839626Z",
     "start_time": "2022-01-01T15:32:32.618434Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower=True)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test=tokenizer.texts_to_sequences(X_test)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f37d3b1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:32:40.275814Z",
     "start_time": "2022-01-01T15:32:40.145816Z"
    }
   },
   "outputs": [],
   "source": [
    "not_found = set()\n",
    "for word in word_index.keys():\n",
    "    try:\n",
    "        embedding_vector = word_vectors[word]\n",
    "    except KeyError:\n",
    "        not_found.add(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b0bfc53c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:32:41.518816Z",
     "start_time": "2022-01-01T15:32:41.504815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2332"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c78d1b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:32:52.412247Z",
     "start_time": "2022-01-01T15:32:52.192249Z"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=300\n",
    "vocabulary_size=len(word_index)+1 - len(not_found)+1\n",
    "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
    "i = 0\n",
    "for word in word_index.keys():\n",
    "    if word in word_vectors:\n",
    "        embedding_matrix[i] = word_vectors[word]\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca4ad292",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:32:54.328221Z",
     "start_time": "2022-01-01T15:32:53.520828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905a5d4e6a544fd885548831944f4831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = X.swifter.apply(lambda text: ' '.join([item for item in text.split() if item not in not_found]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bd6f494a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:41:44.960969Z",
     "start_time": "2022-01-01T15:41:44.944972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50663, 300)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "65a1757f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:33:29.641286Z",
     "start_time": "2022-01-01T15:33:28.742292Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train,padding='post')\n",
    "X_test = pad_sequences(X_test,maxlen=X_train.shape[1],padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "372dc4fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:36:45.942193Z",
     "start_time": "2022-01-01T15:36:45.931202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 2809)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ebd073bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:37:11.517907Z",
     "start_time": "2022-01-01T15:37:11.295914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 2809, 300)         15198900  \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 2809, 300, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2807, 1, 100)      90100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 150)               45150     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 50)                7550      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 15,341,751\n",
      "Trainable params: 142,851\n",
      "Non-trainable params: 15,198,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_length = X_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size,EMBEDDING_DIM,weights=[embedding_matrix],trainable=False,input_length=sequence_length))\n",
    "model.add(Reshape((sequence_length,EMBEDDING_DIM,1)))\n",
    "model.add(Conv2D(100, (3, EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l1_l2(0.01)))\n",
    "model.add(MaxPooling2D((sequence_length - 4, 1), strides=(1,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(150, activation=\"relu\"))\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),metrics=[\"accuracy\",tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8308290e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:37:12.977547Z",
     "start_time": "2022-01-01T15:37:12.965542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.26771, 1.0: 0.73229}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = 1 - pd.Series(y).value_counts()/y.size\n",
    "weights = weights.to_dict()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9e0afdc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T15:38:50.542432Z",
     "start_time": "2022-01-01T15:38:47.881124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "  1/360 [..............................] - ETA: 14:07 - loss: 3.9440 - accuracy: 0.6250 - recall_6: 0.2000 - precision_6: 0.1875"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[93,2805] = 51358 is not in [0, 50663)\n\t [[node sequential_7/embedding_7/embedding_lookup (defined at <ipython-input-76-c30c230dd42d>:3) ]] [Op:__inference_train_function_10533]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_7/embedding_7/embedding_lookup:\n sequential_7/embedding_7/embedding_lookup/10009 (defined at C:\\ProgramData\\Anaconda3\\lib\\contextlib.py:113)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-c30c230dd42d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtime_stopping_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimeStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m history = model.fit(X_train,y_train,batch_size=200,epochs=1000,\n\u001b[0m\u001b[0;32m      4\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     use_multiprocessing=True,workers=8,callbacks=[callback,time_stopping_callback],shuffle=True)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  indices[93,2805] = 51358 is not in [0, 50663)\n\t [[node sequential_7/embedding_7/embedding_lookup (defined at <ipython-input-76-c30c230dd42d>:3) ]] [Op:__inference_train_function_10533]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_7/embedding_7/embedding_lookup:\n sequential_7/embedding_7/embedding_lookup/10009 (defined at C:\\ProgramData\\Anaconda3\\lib\\contextlib.py:113)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "time_stopping_callback = tfa.callbacks.TimeStopping(seconds=60*60*15, verbose=1) \n",
    "history = model.fit(X_train,y_train,batch_size=200,epochs=1000,\n",
    "                    validation_split=0.1,class_weight=weights,\n",
    "                    use_multiprocessing=True,workers=8,callbacks=[callback,time_stopping_callback],shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8965d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cnn_word2vec_second_chance\")\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Train Metrics')\n",
    "plt.ylabel('Metric')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['accuracy', 'val_accuracy','loss','val_loss'])\n",
    "plt.show()\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_test[y_pred_test > 0.5] = 1\n",
    "y_pred_test[y_pred_test <= 0.5] = 0\n",
    "print(\"Test: \\n\")\n",
    "print(classification_report(y_test.argmax(axis=1),y_pred_test))\n",
    "print(\"\\nTrain: \\n\")\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_train[y_pred_train > 0.5] = 1\n",
    "y_pred_train[y_pred_train <= 0.5] = 0\n",
    "print(classification_report(y_train.argmax(axis=1),y_pred_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
