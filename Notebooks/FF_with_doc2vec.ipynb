{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:17:10.155969Z",
     "start_time": "2021-12-26T14:17:03.373379Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import swifter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import tensorflow as tf\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:17:10.743733Z",
     "start_time": "2021-12-26T14:17:10.204320Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_WORKERS = 8\n",
    "TEST_SIZE = 0.3\n",
    "LABEL_COLUMN_NAME = \"oh_label\"\n",
    "TEXT_COLUMN_NAME = \"Text\"\n",
    "DATASET_PATH = \"../Data/ver1.csv\"\n",
    "\n",
    "df= pd.read_csv(DATASET_PATH, index_col=False)\n",
    "df = df.dropna()\n",
    "df.drop([\"Unnamed: 0\", \"index\"],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sience we dont have a good pre-trained doc2vec model we will use the pre-trained doc2vec for each word\n",
    "and take the mean of the output vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:24:06.948014Z",
     "start_time": "2021-12-26T14:24:06.626608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Im',\n",
       " '12',\n",
       " 'and',\n",
       " 'i',\n",
       " 'can',\n",
       " 'understand',\n",
       " 'it',\n",
       " 'perfectly',\n",
       " '.',\n",
       " 'You',\n",
       " 'should',\n",
       " 'learn',\n",
       " 'english',\n",
       " 'instead',\n",
       " 'of',\n",
       " 'making',\n",
       " 'us',\n",
       " 'dumb',\n",
       " 'it',\n",
       " 'down',\n",
       " 'for',\n",
       " 'you',\n",
       " '.',\n",
       " '#',\n",
       " 'mkr',\n",
       " 'Boy',\n",
       " ',',\n",
       " '@',\n",
       " 'FourinHandyou',\n",
       " 'sure',\n",
       " 'know',\n",
       " 'how',\n",
       " 'to',\n",
       " 'dish',\n",
       " 'out',\n",
       " 'an',\n",
       " 'insult',\n",
       " '``',\n",
       " 'your',\n",
       " 'sausage',\n",
       " 'was',\n",
       " 'a',\n",
       " 'little',\n",
       " 'short',\n",
       " 'of',\n",
       " 'fat',\n",
       " '...',\n",
       " \"''\",\n",
       " 'Glad',\n",
       " 'they',\n",
       " 'were',\n",
       " \"n't\",\n",
       " 'male',\n",
       " 'contestants',\n",
       " '!',\n",
       " 'Fuck',\n",
       " 'you',\n",
       " 'all',\n",
       " '.',\n",
       " 'This',\n",
       " 'site',\n",
       " 'is',\n",
       " 'full',\n",
       " 'of',\n",
       " 'stuck',\n",
       " 'up',\n",
       " 'cunts',\n",
       " ',',\n",
       " 'who',\n",
       " 'for',\n",
       " 'some',\n",
       " 'unknown',\n",
       " 'reason',\n",
       " 'think',\n",
       " 'being',\n",
       " 'a',\n",
       " 'part',\n",
       " 'of',\n",
       " 'wikipedia',\n",
       " 'promotes',\n",
       " 'them',\n",
       " 'to',\n",
       " 'President',\n",
       " 'of',\n",
       " 'the',\n",
       " 'cyberspace',\n",
       " '.',\n",
       " 'Sad',\n",
       " 'pricks',\n",
       " ',',\n",
       " 'go',\n",
       " 'fuck',\n",
       " 'yourselves',\n",
       " '.',\n",
       " 'I',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'be',\n",
       " 'returning',\n",
       " 'to',\n",
       " 'this',\n",
       " 'site',\n",
       " '.',\n",
       " 'So',\n",
       " 'off',\n",
       " 'you',\n",
       " 'all',\n",
       " 'go',\n",
       " 'to',\n",
       " 'self',\n",
       " 'congratulate',\n",
       " 'yourselves',\n",
       " '.',\n",
       " '`',\n",
       " ':',\n",
       " ':I',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'disagree',\n",
       " 'with',\n",
       " 'your',\n",
       " 'point',\n",
       " ',',\n",
       " 'except',\n",
       " 'that',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'not',\n",
       " 'exactly',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'appease',\n",
       " 'here',\n",
       " '(',\n",
       " 'I',\n",
       " 'guess',\n",
       " 'it',\n",
       " 'sounded',\n",
       " 'that',\n",
       " 'way',\n",
       " 'though',\n",
       " ')',\n",
       " '-',\n",
       " 'I',\n",
       " 'actually',\n",
       " 'think',\n",
       " 'both',\n",
       " 'points',\n",
       " 'of',\n",
       " 'view',\n",
       " 'have',\n",
       " 'merit',\n",
       " 'which',\n",
       " 'is',\n",
       " 'why',\n",
       " 'I',\n",
       " \"'d\",\n",
       " 'go',\n",
       " 'with',\n",
       " 'the',\n",
       " 'Anglo-Australian',\n",
       " 'type',\n",
       " 'of',\n",
       " 'construction',\n",
       " '(',\n",
       " 'and',\n",
       " 'maybe',\n",
       " 'drop',\n",
       " 'the',\n",
       " 'Manx',\n",
       " 'in',\n",
       " 'the',\n",
       " 'first',\n",
       " 'sentence',\n",
       " ')',\n",
       " '.',\n",
       " 'As',\n",
       " 'I',\n",
       " 'said',\n",
       " ',',\n",
       " 'if',\n",
       " 'you',\n",
       " 'had',\n",
       " 'asked',\n",
       " 'me',\n",
       " 'before',\n",
       " 'this',\n",
       " 'discussion',\n",
       " 'started',\n",
       " 'where',\n",
       " 'the',\n",
       " 'Bee',\n",
       " 'Gees',\n",
       " 'were',\n",
       " 'from',\n",
       " ',',\n",
       " 'I',\n",
       " 'would',\n",
       " 'have',\n",
       " 'said',\n",
       " 'Australia',\n",
       " ',',\n",
       " 'based',\n",
       " 'on',\n",
       " 'how',\n",
       " 'I',\n",
       " 'recall',\n",
       " 'them',\n",
       " 'being',\n",
       " 'promoted',\n",
       " 'in',\n",
       " 'the',\n",
       " '60s',\n",
       " ',',\n",
       " 'and',\n",
       " 'I',\n",
       " 'also',\n",
       " 'totally',\n",
       " 'see',\n",
       " 'the',\n",
       " 'logic',\n",
       " 'of',\n",
       " 'considering',\n",
       " 'them',\n",
       " 'English',\n",
       " 'so',\n",
       " 'the',\n",
       " 'dual',\n",
       " 'wording',\n",
       " 'does',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'to',\n",
       " 'me',\n",
       " '.',\n",
       " 'I',\n",
       " \"'ve\",\n",
       " 'looked',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'and',\n",
       " 'have',\n",
       " \"n't\",\n",
       " 'come',\n",
       " 'up',\n",
       " 'with',\n",
       " 'anything',\n",
       " 'on',\n",
       " 'the',\n",
       " 'web',\n",
       " 'to',\n",
       " 'answer',\n",
       " 'that',\n",
       " 'question',\n",
       " 'yet',\n",
       " '-',\n",
       " 'maybe',\n",
       " 'you',\n",
       " \"'ll\",\n",
       " 'have',\n",
       " 'more',\n",
       " 'luck',\n",
       " '.',\n",
       " ':',\n",
       " ':By',\n",
       " 'the',\n",
       " 'way',\n",
       " ',',\n",
       " 'Olivia',\n",
       " 'Newton-John',\n",
       " 'may',\n",
       " 'be',\n",
       " 'relevant',\n",
       " 'here',\n",
       " ':',\n",
       " 'she',\n",
       " 'is',\n",
       " 'considered',\n",
       " 'Australian',\n",
       " 'as',\n",
       " 'well',\n",
       " ',',\n",
       " 'and',\n",
       " 'her',\n",
       " 'WIki',\n",
       " 'article',\n",
       " 'calls',\n",
       " 'her',\n",
       " '``',\n",
       " 'English-born',\n",
       " 'Australian',\n",
       " '``',\n",
       " 'or',\n",
       " 'words',\n",
       " 'to',\n",
       " 'that',\n",
       " 'effect',\n",
       " '.',\n",
       " 'Her',\n",
       " 'bio',\n",
       " 'says',\n",
       " 'she',\n",
       " 'was',\n",
       " 'born',\n",
       " 'in',\n",
       " 'England',\n",
       " ',',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'Australia',\n",
       " 'at',\n",
       " 'age',\n",
       " '5',\n",
       " 'and',\n",
       " 'moved',\n",
       " 'back',\n",
       " 'to',\n",
       " 'England',\n",
       " 'at',\n",
       " '16',\n",
       " 'where',\n",
       " 'she',\n",
       " 'began',\n",
       " 'recording',\n",
       " '-',\n",
       " 'a',\n",
       " 'pretty',\n",
       " 'similar',\n",
       " 'story',\n",
       " 'to',\n",
       " 'the',\n",
       " 'BeeGees',\n",
       " ',',\n",
       " 'and',\n",
       " 'she',\n",
       " \"'s\",\n",
       " 'listed',\n",
       " 'as',\n",
       " 'Australian',\n",
       " 'which',\n",
       " 'might',\n",
       " 'be',\n",
       " 'how',\n",
       " 'she',\n",
       " 'self-identifies',\n",
       " ',',\n",
       " 'I',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'know',\n",
       " '.',\n",
       " 'But',\n",
       " 'on',\n",
       " 'a',\n",
       " 'quick',\n",
       " 'read',\n",
       " 'it',\n",
       " 'appears',\n",
       " 'she',\n",
       " 'only',\n",
       " 'lived',\n",
       " 'there',\n",
       " 'for',\n",
       " 'about',\n",
       " '10',\n",
       " 'years',\n",
       " ',',\n",
       " 'like',\n",
       " 'them',\n",
       " '.',\n",
       " ':',\n",
       " ':As',\n",
       " 'for',\n",
       " 'whether',\n",
       " 'this',\n",
       " 'editing',\n",
       " 'is',\n",
       " 'personal',\n",
       " ',',\n",
       " 'I',\n",
       " 'have',\n",
       " 'no',\n",
       " 'idea',\n",
       " 'and',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'want',\n",
       " 'to',\n",
       " 'get',\n",
       " 'into',\n",
       " 'it',\n",
       " '.',\n",
       " 'I',\n",
       " 'do',\n",
       " 'know',\n",
       " 'that',\n",
       " 'I',\n",
       " 'am',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'reach',\n",
       " 'consensus',\n",
       " 'among',\n",
       " 'different',\n",
       " 'points',\n",
       " 'of',\n",
       " 'view',\n",
       " ',',\n",
       " 'on',\n",
       " 'this',\n",
       " 'exceedingly',\n",
       " 'minor',\n",
       " 'point',\n",
       " '-',\n",
       " 'and',\n",
       " 'as',\n",
       " 'I',\n",
       " 'have',\n",
       " 'said',\n",
       " ',',\n",
       " 'there',\n",
       " 'was',\n",
       " 'some',\n",
       " 'fussing',\n",
       " 'about',\n",
       " 'it',\n",
       " 'a',\n",
       " 'couple',\n",
       " 'of',\n",
       " 'months',\n",
       " 'ago',\n",
       " 'and',\n",
       " 'it',\n",
       " 'settled',\n",
       " 'down',\n",
       " 'with',\n",
       " 'the',\n",
       " 'awkward',\n",
       " 'wording',\n",
       " ',',\n",
       " 'because',\n",
       " 'it',\n",
       " 'is',\n",
       " 'accurate',\n",
       " '.',\n",
       " 'So',\n",
       " 'I',\n",
       " 'hope',\n",
       " 'we',\n",
       " 'can',\n",
       " 'drop',\n",
       " 'this',\n",
       " 'quickly',\n",
       " 'and',\n",
       " 'move',\n",
       " 'on',\n",
       " 'to',\n",
       " 'something',\n",
       " 'more',\n",
       " 'substantive',\n",
       " '.',\n",
       " '`',\n",
       " 'do',\n",
       " 'i',\n",
       " 'look',\n",
       " 'like',\n",
       " 'i',\n",
       " 'give',\n",
       " 'a',\n",
       " 'fuck',\n",
       " ',',\n",
       " 'u',\n",
       " 'are',\n",
       " 'all',\n",
       " 'sad',\n",
       " 'fucks',\n",
       " 'with',\n",
       " 'nothing',\n",
       " 'better',\n",
       " 'to',\n",
       " 'do',\n",
       " 'ban',\n",
       " 'me',\n",
       " ',',\n",
       " 'i',\n",
       " 'dont',\n",
       " 'give',\n",
       " 'a',\n",
       " 'shit',\n",
       " 'Block',\n",
       " 'me',\n",
       " 'then',\n",
       " 'you',\n",
       " 'cocksucker',\n",
       " '-',\n",
       " 'clever',\n",
       " 'people',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'give',\n",
       " 'a',\n",
       " 'fuck',\n",
       " 'about',\n",
       " 'editing',\n",
       " 'Wikikpedia',\n",
       " '?',\n",
       " 'Just',\n",
       " 'because',\n",
       " 'Wikipedia',\n",
       " 'has',\n",
       " 'turned',\n",
       " 'you',\n",
       " 'into',\n",
       " 'its',\n",
       " 'bitch',\n",
       " ',',\n",
       " 'you',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'see',\n",
       " 'that',\n",
       " 'being',\n",
       " 'blocked',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " \"'punishment\",\n",
       " \"'\",\n",
       " '.',\n",
       " 'If',\n",
       " 'it',\n",
       " 'happened',\n",
       " 'to',\n",
       " 'you',\n",
       " 'it',\n",
       " 'would',\n",
       " 'be',\n",
       " 'a',\n",
       " 'blessing',\n",
       " ',',\n",
       " 'but',\n",
       " 'you',\n",
       " \"'ll\",\n",
       " 'never',\n",
       " 'see',\n",
       " 'how',\n",
       " 'much',\n",
       " 'time',\n",
       " 'and',\n",
       " 'life',\n",
       " 'you',\n",
       " \"'ve\",\n",
       " 'completely',\n",
       " 'WASTED',\n",
       " ',',\n",
       " 'because',\n",
       " 'your',\n",
       " 'brain',\n",
       " 'is',\n",
       " 'mush',\n",
       " '.',\n",
       " 'Fuckin',\n",
       " 'wretch',\n",
       " '`',\n",
       " '==',\n",
       " 'Release',\n",
       " 'Date',\n",
       " '==',\n",
       " 'So',\n",
       " 'what',\n",
       " \"'s\",\n",
       " 'the',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'this',\n",
       " 'film',\n",
       " '?',\n",
       " 'When',\n",
       " 'is',\n",
       " 'it',\n",
       " 'being',\n",
       " 'released',\n",
       " '?',\n",
       " 'Can',\n",
       " 'we',\n",
       " 'get',\n",
       " 'a',\n",
       " 'more',\n",
       " 'accurate',\n",
       " 'date',\n",
       " 'than',\n",
       " ',',\n",
       " '``',\n",
       " 'First',\n",
       " 'Quarter',\n",
       " 'of',\n",
       " '2007',\n",
       " '?',\n",
       " '``',\n",
       " '`',\n",
       " '==',\n",
       " 'Kurt',\n",
       " 'Cobain',\n",
       " '==',\n",
       " 'This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'one',\n",
       " 'Kurt',\n",
       " 'Cobain',\n",
       " 'suicided',\n",
       " 'with',\n",
       " '==',\n",
       " 'Vandalism',\n",
       " 'is',\n",
       " 'spreading',\n",
       " 'lies',\n",
       " '==',\n",
       " 'I',\n",
       " 'think',\n",
       " 'it',\n",
       " 'is',\n",
       " 'you',\n",
       " 'who',\n",
       " 'is',\n",
       " 'a',\n",
       " 'vandal',\n",
       " ',',\n",
       " 'for',\n",
       " 'you',\n",
       " 'are',\n",
       " 'writing',\n",
       " 'lies',\n",
       " 'about',\n",
       " 'Jami',\n",
       " '.',\n",
       " 'The',\n",
       " 'pederastic',\n",
       " 'Poetry',\n",
       " 'should',\n",
       " 'be',\n",
       " 'removed',\n",
       " ',',\n",
       " 'and',\n",
       " 'I',\n",
       " 'doubt',\n",
       " 'that',\n",
       " 'the',\n",
       " 'caption',\n",
       " 'of',\n",
       " 'the',\n",
       " 'pictures',\n",
       " 'is',\n",
       " 'from',\n",
       " 'Jami',\n",
       " 'books',\n",
       " ',',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'your',\n",
       " 'and',\n",
       " 'other',\n",
       " 'gay',\n",
       " 'lobbyist',\n",
       " 'imagination',\n",
       " '.',\n",
       " 'You',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'need',\n",
       " 'to',\n",
       " 'justify',\n",
       " 'your',\n",
       " 'way',\n",
       " 'of',\n",
       " 'living',\n",
       " 'by',\n",
       " 'labling',\n",
       " 'others',\n",
       " 'pederast',\n",
       " '.',\n",
       " 'Please',\n",
       " 'stop',\n",
       " 'making',\n",
       " 'test',\n",
       " 'edits',\n",
       " 'to',\n",
       " 'Wikipedia',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'considered',\n",
       " 'vandalism',\n",
       " ',',\n",
       " 'which',\n",
       " ',',\n",
       " 'under',\n",
       " 'Wikipedia',\n",
       " 'policy',\n",
       " ',',\n",
       " 'can',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'blocking',\n",
       " 'of',\n",
       " 'editing',\n",
       " 'privileges',\n",
       " '.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'experiment',\n",
       " 'again',\n",
       " ',',\n",
       " 'please',\n",
       " 'use',\n",
       " 'the',\n",
       " 'sandbox',\n",
       " '.',\n",
       " 'AHAHAHAHAHA',\n",
       " 'Read',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'comment',\n",
       " 'before',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'chime',\n",
       " 'in',\n",
       " '.',\n",
       " 'There',\n",
       " 'is',\n",
       " 'no',\n",
       " 'needed',\n",
       " 'discussion',\n",
       " 'for',\n",
       " 'templates',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'JoshuaZ',\n",
       " 'pattern',\n",
       " 'incite',\n",
       " 'then',\n",
       " 'banner',\n",
       " '.',\n",
       " 'Understand',\n",
       " '?',\n",
       " 'Good',\n",
       " '?',\n",
       " 'Got',\n",
       " 'it',\n",
       " '?',\n",
       " 'Good',\n",
       " '!',\n",
       " 'ROFL',\n",
       " 'http',\n",
       " ':',\n",
       " '//img153.imageshack.us/img153/7844/atopicarealist7bs.png',\n",
       " 'http',\n",
       " ':',\n",
       " '//img95.imageshack.us/img95/7497/banneduser032906ban4kt.png',\n",
       " 'http',\n",
       " ':',\n",
       " '//img90.imageshack.us/img90/1530/banneduser032906scomm3ra.png',\n",
       " 'http',\n",
       " ':',\n",
       " '//img90.imageshack.us/img90/3267/banneduser03290610013ue.png',\n",
       " 'http',\n",
       " ':',\n",
       " '//img236.imageshack.us/img236/4495/banneduser03290610077hh.png',\n",
       " 'http',\n",
       " ':',\n",
       " '//img236.imageshack.us/img236/8844/banneduser03290610149fz.png',\n",
       " 'http',\n",
       " ':',\n",
       " '//img90.imageshack.us/img90/6935/banneduser03290610180pj.png',\n",
       " 'RT',\n",
       " '@',\n",
       " 'babybrucewayne',\n",
       " ':',\n",
       " 'every',\n",
       " 'time',\n",
       " 'I',\n",
       " 'see',\n",
       " 'Kat',\n",
       " \"'s\",\n",
       " 'face',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'puking',\n",
       " '#',\n",
       " 'mkr',\n",
       " 'Your',\n",
       " 'from',\n",
       " 'a',\n",
       " 'family',\n",
       " 'of',\n",
       " 'donkeys',\n",
       " '.',\n",
       " ',',\n",
       " '30',\n",
       " 'November',\n",
       " '2012',\n",
       " '(',\n",
       " 'UTC',\n",
       " ')',\n",
       " ':',\n",
       " ':The',\n",
       " 'artilce',\n",
       " 'clearly',\n",
       " 'states',\n",
       " 'what',\n",
       " 'happened',\n",
       " 'in',\n",
       " 'February',\n",
       " '7th',\n",
       " 'day',\n",
       " 'President',\n",
       " 'nasheed',\n",
       " 'resigned',\n",
       " ',',\n",
       " 'What',\n",
       " 'proof',\n",
       " 'do',\n",
       " 'you',\n",
       " 'have',\n",
       " 'to',\n",
       " 'say',\n",
       " 'that',\n",
       " 'the',\n",
       " 'source',\n",
       " 'in',\n",
       " 'not',\n",
       " 'reliable',\n",
       " '?',\n",
       " 'It',\n",
       " 'clearly',\n",
       " 'states',\n",
       " 'what',\n",
       " 'happened',\n",
       " 'in',\n",
       " 'February',\n",
       " '7th',\n",
       " 'day',\n",
       " 'President',\n",
       " 'nasheed',\n",
       " 'resigned',\n",
       " '.',\n",
       " 'So',\n",
       " 'do',\n",
       " 'not',\n",
       " 'judge',\n",
       " 'based',\n",
       " 'on',\n",
       " 'a',\n",
       " 'point',\n",
       " 'of',\n",
       " 'view',\n",
       " '.',\n",
       " '16:45',\n",
       " 'He',\n",
       " 'can',\n",
       " 'go',\n",
       " 'fuck',\n",
       " 'himself',\n",
       " 'sideways',\n",
       " 'with',\n",
       " 'a',\n",
       " 'spiky',\n",
       " 'spoon',\n",
       " '.',\n",
       " '==',\n",
       " 'Alto',\n",
       " 'Adige',\n",
       " '==',\n",
       " 'I',\n",
       " 'see',\n",
       " 'you',\n",
       " 'are',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'change',\n",
       " 'the',\n",
       " 'name',\n",
       " 'again',\n",
       " 'to',\n",
       " 'the',\n",
       " 'German',\n",
       " 'point',\n",
       " 'of',\n",
       " 'view',\n",
       " '.',\n",
       " 'Jan',\n",
       " ',',\n",
       " 'you',\n",
       " 'really',\n",
       " 'a',\n",
       " 'pathethic',\n",
       " 'nationalistic',\n",
       " 'neo-nazi',\n",
       " 'POS',\n",
       " 'excuse',\n",
       " 'for',\n",
       " 'a',\n",
       " 'human',\n",
       " 'being',\n",
       " '.',\n",
       " 'With',\n",
       " 'this',\n",
       " 'move',\n",
       " 'request',\n",
       " ',',\n",
       " 'you',\n",
       " 'prove',\n",
       " 'it',\n",
       " '.',\n",
       " 'How',\n",
       " 'insecure',\n",
       " 'you',\n",
       " 'must',\n",
       " 'be',\n",
       " '.',\n",
       " '==Relevancy==',\n",
       " 'Are',\n",
       " 'you',\n",
       " 'from',\n",
       " 'New',\n",
       " 'York',\n",
       " '?',\n",
       " 'Are',\n",
       " 'you',\n",
       " 'well',\n",
       " 'steeped',\n",
       " 'in',\n",
       " 'the',\n",
       " 'history',\n",
       " 'and',\n",
       " 'contemporary',\n",
       " 'culture',\n",
       " 'of',\n",
       " 'hardcore',\n",
       " 'music',\n",
       " '?',\n",
       " 'In',\n",
       " 'my',\n",
       " 'opinion',\n",
       " ',',\n",
       " 'you',\n",
       " 'should',\n",
       " 'probably',\n",
       " 'stop',\n",
       " 'hanging',\n",
       " 'around',\n",
       " 'your',\n",
       " 'computer',\n",
       " 'all',\n",
       " 'day',\n",
       " 'waiting',\n",
       " 'to',\n",
       " 'make',\n",
       " 'chagnes',\n",
       " 'to',\n",
       " 'Wikipedia',\n",
       " 'articles',\n",
       " '.',\n",
       " 'Lighten',\n",
       " 'up',\n",
       " '.',\n",
       " 'Get',\n",
       " 'a',\n",
       " 'hobby',\n",
       " '.',\n",
       " 'I',\n",
       " 'politely',\n",
       " 'request',\n",
       " 'that',\n",
       " 'you',\n",
       " 'step',\n",
       " 'off',\n",
       " 'my',\n",
       " 'balls',\n",
       " '.',\n",
       " '``',\n",
       " '\\\\xa0shut',\n",
       " 'ur',\n",
       " 'nasty',\n",
       " 'ass',\n",
       " 'up',\n",
       " 'u',\n",
       " 'homo',\n",
       " 'ass',\n",
       " 'nigga',\n",
       " ',',\n",
       " 'u',\n",
       " 'still',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_path = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word2vec(tokens_list, vector, generate_missing=False, k=300):\n",
    "    if len(tokens_list)<1:\n",
    "        return np.zeros(k)\n",
    "    if generate_missing:\n",
    "        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n",
    "    else:\n",
    "        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
    "    length = len(vectorized)\n",
    "    summed = np.sum(vectorized, axis=0)\n",
    "    averaged = np.divide(summed, length)\n",
    "    return averaged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 100000/100000 [06:56<00:00, 239.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        [0.015312941419345982, 0.22473520653347204, 0....\n",
       "1        [0.015332999627281975, 0.21280927531473268, 0....\n",
       "2        [-0.007219608801433893, 0.19396265298012924, 0...\n",
       "3        [0.017972469479406367, 0.22978346115482676, 0....\n",
       "4        [0.03493955455862177, 0.20538398582791106, 0.1...\n",
       "                               ...                        \n",
       "99995    [0.03001815631774615, 0.20729014185692446, 0.1...\n",
       "99996    [0.0435618249695891, 0.2327276160123481, 0.181...\n",
       "99997    [0.03214820638988943, 0.24006346296471937, 0.1...\n",
       "99998    [-0.07424437940884678, 0.12839322934619346, 0....\n",
       "99999    [0.006174476764086151, 0.22336781633304606, 0....\n",
       "Name: Text, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[TEXT_COLUMN_NAME] = df[TEXT_COLUMN_NAME].swifter.apply(lambda x: get_average_word2vec(x, word2vec,generate_missing=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df[TEXT_COLUMN_NAME],df[LABEL_COLUMN_NAME]\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "x_test,x_val,y_test,y_val = train_test_split(x_test,y_test,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.26771, 1: 0.73229}\n"
     ]
    }
   ],
   "source": [
    "x_neg_weight = y[y==1].shape\n",
    "x_pos_weight = y[y==0].shape\n",
    "x_neg_weight[0]/x_pos_weight[0]\n",
    "weights = {0: (x_neg_weight[0]/(x_pos_weight[0]+x_neg_weight[0])),1: (x_pos_weight[0]/(x_pos_weight[0]+x_neg_weight[0]))}\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(np.stack(x_train),axis=2)\n",
    "x_test = np.expand_dims(np.stack(x_test),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 300, 200)          400       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300, 100)          20100     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 300, 100)          0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300, 50)           5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300, 10)           510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300, 1)            11        \n",
      "=================================================================\n",
      "Total params: 26,071\n",
      "Trainable params: 26,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(200, activation=\"relu\",input_shape=(300,1)))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),metrics=[\"accuracy\",tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:792 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\compile_utils.py:457 update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\metrics_utils.py:73 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\metrics.py:177 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\metrics.py:1484 update_state  **\n        return metrics_utils.update_confusion_matrix_variables(\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\metrics_utils.py:623 update_confusion_matrix_variables\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (200, 300) and (200, 1) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-97053643c104>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model.fit(x_train,y_train,batch_size=200,epochs=500,\n\u001b[0m\u001b[0;32m      3\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     use_multiprocessing=True,workers=8,callbacks=[callback])\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 759\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    760\u001b[0m             *args, **kwds))\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:792 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\compile_utils.py:457 update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\metrics_utils.py:73 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\metrics.py:177 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\metrics.py:1484 update_state  **\n        return metrics_utils.update_confusion_matrix_variables(\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\metrics_utils.py:623 update_confusion_matrix_variables\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\n    C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (200, 300) and (200, 1) are incompatible\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "history = model.fit(x_train,y_train,batch_size=200,epochs=500,\n",
    "                    validation_split=0.05,class_weight=weights,\n",
    "                    use_multiprocessing=True,workers=8,callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
