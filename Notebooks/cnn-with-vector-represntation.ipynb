{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:44:54.900971Z",
     "start_time": "2021-12-19T09:44:51.484150Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from gensim import models\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Reshape, Flatten, concatenate, Input, Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import collections\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:44:55.451812Z",
     "start_time": "2021-12-19T09:44:54.935970Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/ver1.csv', index_col=0)\n",
    "data.drop([\"index\"], inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:44:55.514782Z",
     "start_time": "2021-12-19T09:44:55.484782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Im 12 and i can understand it perfectly. You s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#mkr Boy, @FourinHandyou sure know how to dish...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuck you all. This site is full of stuck up ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>`   ::I don't disagree with your point, except...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do i look like i give a fuck, u are all sad ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>`  == d15b8 - just you leave it alone ==  ``co...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>:Thanks for the feedback, and I'm very glad t...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>==Fast and Furious 7== Please do your resear...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>@KWiebs31 ABLOO BLOO BLOO</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>`  Clearly you know very little about these ba...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label\n",
       "0      Im 12 and i can understand it perfectly. You s...       1.0\n",
       "1      #mkr Boy, @FourinHandyou sure know how to dish...       0.0\n",
       "2        Fuck you all. This site is full of stuck up ...       1.0\n",
       "3      `   ::I don't disagree with your point, except...       0.0\n",
       "4        do i look like i give a fuck, u are all sad ...       1.0\n",
       "...                                                  ...       ...\n",
       "99995  `  == d15b8 - just you leave it alone ==  ``co...       0.0\n",
       "99996   :Thanks for the feedback, and I'm very glad t...       0.0\n",
       "99997    ==Fast and Furious 7== Please do your resear...       0.0\n",
       "99998                          @KWiebs31 ABLOO BLOO BLOO       0.0\n",
       "99999  `  Clearly you know very little about these ba...       0.0\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:44:55.938196Z",
     "start_time": "2021-12-19T09:44:55.546794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(data[\"oh_label\"].value_counts(), explode = [0,0.1], labels=[\"not bulling\", \"bulling\"], autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.title(\"Data distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:44:56.066202Z",
     "start_time": "2021-12-19T09:44:56.051202Z"
    }
   },
   "outputs": [],
   "source": [
    "data.columns = ['Text', 'oh_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:44:56.114208Z",
     "start_time": "2021-12-19T09:44:56.100203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Im 12 and i can understand it perfectly. You s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#mkr Boy, @FourinHandyou sure know how to dish...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuck you all. This site is full of stuck up ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>`   ::I don't disagree with your point, except...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do i look like i give a fuck, u are all sad ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  oh_label\n",
       "0  Im 12 and i can understand it perfectly. You s...       1.0\n",
       "1  #mkr Boy, @FourinHandyou sure know how to dish...       0.0\n",
       "2    Fuck you all. This site is full of stuck up ...       1.0\n",
       "3  `   ::I don't disagree with your point, except...       0.0\n",
       "4    do i look like i give a fuck, u are all sad ...       1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:44:56.162214Z",
     "start_time": "2021-12-19T09:44:56.148203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:44:56.210207Z",
     "start_time": "2021-12-19T09:44:56.195203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:44:56.289203Z",
     "start_time": "2021-12-19T09:44:56.244205Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1 it's represent negative and 0 for positive\n",
    "pos = []\n",
    "neg = []\n",
    "for l in data.oh_label:\n",
    "    if l == 0:\n",
    "        pos.append(1)\n",
    "        neg.append(0)\n",
    "    elif l == 1:\n",
    "        pos.append(0)\n",
    "        neg.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:44:56.400201Z",
     "start_time": "2021-12-19T09:44:56.354202Z"
    }
   },
   "outputs": [],
   "source": [
    "data['Pos']= pos\n",
    "data['Neg']= neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:44:56.480209Z",
     "start_time": "2021-12-19T09:44:56.465201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Im 12 and i can understand it perfectly. You s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#mkr Boy, @FourinHandyou sure know how to dish...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuck you all. This site is full of stuck up ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>`   ::I don't disagree with your point, except...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do i look like i give a fuck, u are all sad ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  oh_label  Pos  Neg\n",
       "0  Im 12 and i can understand it perfectly. You s...       1.0    0    1\n",
       "1  #mkr Boy, @FourinHandyou sure know how to dish...       0.0    1    0\n",
       "2    Fuck you all. This site is full of stuck up ...       1.0    0    1\n",
       "3  `   ::I don't disagree with your point, except...       0.0    1    0\n",
       "4    do i look like i give a fuck, u are all sad ...       1.0    0    1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### string punctation\n",
    "#### '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:44:57.118264Z",
     "start_time": "2021-12-19T09:44:56.545202Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = ''\n",
    "    text_nopunct = re.sub('['+string.punctuation+']', '', text)\n",
    "    return text_nopunct\n",
    "\n",
    "data['Text_Clean'] = data['Text'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:45:18.970596Z",
     "start_time": "2021-12-19T09:44:57.182666Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "tokens = [word_tokenize(sen) for sen in data.Text_Clean]\n",
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:45:21.155113Z",
     "start_time": "2021-12-19T09:45:20.184114Z"
    }
   },
   "outputs": [],
   "source": [
    "def lower_token(tokens): \n",
    "    return [w.lower() for w in tokens]    \n",
    "    \n",
    "lower_tokens = [lower_token(token) for token in tokens] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:45:23.579824Z",
     "start_time": "2021-12-19T09:45:23.567828Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stoplist = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T18:55:33.358578Z",
     "start_time": "2021-11-24T18:55:33.345615Z"
    }
   },
   "source": [
    "#### Examples for stop words: \n",
    "'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your'\n",
    "##### The definition of stop words it's words that not add to the meaning of the sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:45:25.967962Z",
     "start_time": "2021-12-19T09:45:25.955965Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(tokens):\n",
    "    return [word for word in tokens if word not in stoplist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:45:35.759395Z",
     "start_time": "2021-12-19T09:45:28.332325Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_words = [remove_stop_words(sen) for sen in lower_tokens] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:45:38.978486Z",
     "start_time": "2021-12-19T09:45:38.868517Z"
    }
   },
   "outputs": [],
   "source": [
    "result = [' '.join(sen) for sen in filtered_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:45:42.386576Z",
     "start_time": "2021-12-19T09:45:42.373578Z"
    }
   },
   "outputs": [],
   "source": [
    "data['Text_Final'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:45:45.854880Z",
     "start_time": "2021-12-19T09:45:45.777873Z"
    }
   },
   "outputs": [],
   "source": [
    "data['tokens'] = filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:45:49.276895Z",
     "start_time": "2021-12-19T09:45:49.232901Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Pos', 'Neg'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b0f6c1535217>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Text_Final'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tokens'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'oh_label'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pos'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Neg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3028\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Pos', 'Neg'] not in index\""
     ]
    }
   ],
   "source": [
    "data = data[['Text_Final', 'tokens', 'oh_label', 'Pos', 'Neg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:45:52.670688Z",
     "start_time": "2021-12-19T09:45:52.655689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_Final</th>\n",
       "      <th>tokens</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im 12 understand perfectly learn english inste...</td>\n",
       "      <td>[im, 12, understand, perfectly, learn, english...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mkr boy fourinhandyou sure know dish insult sa...</td>\n",
       "      <td>[mkr, boy, fourinhandyou, sure, know, dish, in...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fuck site full stuck cunts unknown reason thin...</td>\n",
       "      <td>[fuck, site, full, stuck, cunts, unknown, reas...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dont disagree point except im exactly trying a...</td>\n",
       "      <td>[dont, disagree, point, except, im, exactly, t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text_Final  \\\n",
       "0  im 12 understand perfectly learn english inste...   \n",
       "1  mkr boy fourinhandyou sure know dish insult sa...   \n",
       "2  fuck site full stuck cunts unknown reason thin...   \n",
       "3  dont disagree point except im exactly trying a...   \n",
       "\n",
       "                                              tokens  oh_label  Pos  Neg  \n",
       "0  [im, 12, understand, perfectly, learn, english...       1.0    0    1  \n",
       "1  [mkr, boy, fourinhandyou, sure, know, dish, in...       0.0    1    0  \n",
       "2  [fuck, site, full, stuck, cunts, unknown, reas...       1.0    0    1  \n",
       "3  [dont, disagree, point, except, im, exactly, t...       0.0    1    0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:45:56.034998Z",
     "start_time": "2021-12-19T09:45:56.005533Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.30, random_state=42)\n",
    "data_test, data_test_final = train_test_split(data_test, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:45:59.430802Z",
     "start_time": "2021-12-19T09:45:59.400802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3686309779845931"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_neg_weight = data_train[data_train[\"oh_label\"]==1].shape\n",
    "x_pos_weight = data_train[data_train[\"oh_label\"]==0].shape\n",
    "x_neg_weight[0]/x_pos_weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:46:03.494509Z",
     "start_time": "2021-12-19T09:46:02.880764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2290656 words total, with a vocabulary size of 131067\n",
      "Max sentence length is 2481\n"
     ]
    }
   ],
   "source": [
    "all_training_words = [word for tokens in data_train[\"tokens\"] for word in tokens]\n",
    "training_sentence_lengths = [len(tokens) for tokens in data_train[\"tokens\"]]\n",
    "TRAINING_VOCAB = sorted(list(set(all_training_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_training_words), len(TRAINING_VOCAB)))\n",
    "print(\"Max sentence length is %s\" % max(training_sentence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:46:07.718005Z",
     "start_time": "2021-12-19T09:46:07.575003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483005 words total, with a vocabulary size of 50477\n",
      "Max sentence length is 2494\n"
     ]
    }
   ],
   "source": [
    "all_test_words = [word for tokens in data_test[\"tokens\"] for word in tokens]\n",
    "test_sentence_lengths = [len(tokens) for tokens in data_test[\"tokens\"]]\n",
    "TEST_VOCAB = sorted(list(set(all_test_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_test_words), len(TEST_VOCAB)))\n",
    "print(\"Max sentence length is %s\" % max(test_sentence_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Google News Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T10:39:59.213170Z",
     "start_time": "2021-12-19T10:39:20.722530Z"
    }
   },
   "outputs": [],
   "source": [
    "word2vec_path = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T10:40:06.347717Z",
     "start_time": "2021-12-19T10:40:06.334608Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_average_word2vec(tokens_list, vector, generate_missing=False, k=300):\n",
    "    if len(tokens_list)<1:\n",
    "        return np.zeros(k)\n",
    "    if generate_missing:\n",
    "        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n",
    "    else:\n",
    "        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
    "    length = len(vectorized)\n",
    "    summed = np.sum(vectorized, axis=0)\n",
    "    averaged = np.divide(summed, length)\n",
    "    return averaged\n",
    "\n",
    "def get_word2vec_embeddings(vectors, clean_comments, generate_missing=False):\n",
    "    embeddings = clean_comments['tokens'].apply(lambda x: get_average_word2vec(x, vectors, \n",
    "                                                                                generate_missing=generate_missing))\n",
    "    return list(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T10:40:17.625621Z",
     "start_time": "2021-12-19T10:40:10.703212Z"
    }
   },
   "outputs": [],
   "source": [
    "training_embeddings = get_word2vec_embeddings(word2vec, data_train, generate_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T10:44:31.937655Z",
     "start_time": "2021-12-19T10:44:31.923669Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 50\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T10:48:49.317622Z",
     "start_time": "2021-12-19T10:48:45.608081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 130531 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=len(TRAINING_VOCAB), lower=True, char_level=False)\n",
    "tokenizer.fit_on_texts(data_train[\"Text_Final\"].tolist())\n",
    "training_sequences = tokenizer.texts_to_sequences(data_train[\"Text_Final\"].tolist())\n",
    "\n",
    "train_word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(train_word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T10:53:07.494043Z",
     "start_time": "2021-12-19T10:53:07.179057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 50)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cnn_data = pad_sequences(training_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "train_cnn_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T10:57:22.842553Z",
     "start_time": "2021-12-19T10:57:22.271126Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-9373b9a956c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_embedding_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_word_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_word_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain_embedding_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword2vec\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEMBEDDING_DIM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_embedding_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word2vec' is not defined"
     ]
    }
   ],
   "source": [
    "train_embedding_weights = np.zeros((len(train_word_index)+1, EMBEDDING_DIM))\n",
    "for word,index in train_word_index.items():\n",
    "    train_embedding_weights[index,:] = word2vec[word] if word in word2vec else np.random.rand(EMBEDDING_DIM)\n",
    "print(train_embedding_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T11:01:37.176210Z",
     "start_time": "2021-12-19T11:01:36.767225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     3,   255,    50,  1219,\n",
       "          41,     1,   348,    52,   697,  8499,    19,   561,   764,\n",
       "         808,     5,   157,   734,  1050,  2729,   601,  1042,  2401,\n",
       "         692,  3201,     5, 22842,  4007])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(data_test[\"Text_Final\"].tolist())\n",
    "test_cnn_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_cnn_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T11:05:51.334663Z",
     "start_time": "2021-12-19T11:05:51.319672Z"
    }
   },
   "outputs": [],
   "source": [
    "label_names = ['Pos', 'Neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T11:10:07.749881Z",
     "start_time": "2021-12-19T11:10:07.736412Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = data_train[label_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T11:14:28.398014Z",
     "start_time": "2021-12-19T11:14:28.386181Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = train_cnn_data\n",
    "y_tr = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T11:27:32.810044Z",
     "start_time": "2021-12-19T11:27:32.801039Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D,MaxPool1D,Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T11:36:04.262325Z",
     "start_time": "2021-12-19T11:36:04.248293Z"
    }
   },
   "outputs": [],
   "source": [
    "def cnn(embeddings, max_sequence_length, num_words, embedding_dim, labels_index):\n",
    "    \n",
    "    embedding_layer = Embedding(num_words,\n",
    "                            embedding_dim,\n",
    "                            weights=[embeddings],\n",
    "                            input_length=max_sequence_length,\n",
    "                            trainable=False)\n",
    "    \n",
    "    sequence_input = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    conv1d = Conv1D(20,7,strides=1, use_bias=True,padding=\"valid\")(embedded_sequences)\n",
    "    max_pool = MaxPool1D(pool_size=3)(conv1d)\n",
    "    flattened = Flatten()(max_pool)\n",
    "    x1 = Dense(128, activation='relu')(flattened)\n",
    "    x1 = Dropout(0.2)(x1)\n",
    "    x2 = Dense(64, activation='relu')(x1)\n",
    "    preds = Dense(labels_index, activation='sigmoid')(x2)\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),metrics=[\"accuracy\",tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-19T11:29:50.718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 50, 300)           39159600  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 44, 20)            42020     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 14, 20)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 280)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               35968     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 39,245,974\n",
      "Trainable params: 86,374\n",
      "Non-trainable params: 39,159,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = cnn(train_embedding_weights, MAX_SEQUENCE_LENGTH, len(train_word_index)+1, EMBEDDING_DIM, \n",
    "                len(list(label_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:06:29.044239Z",
     "start_time": "2021-12-19T09:06:29.036259Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T11:23:16.306297Z",
     "start_time": "2021-12-19T11:06:25.582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T08:49:28.535480Z",
     "start_time": "2021-12-19T08:49:28.518315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:06:29.633788Z",
     "start_time": "2021-12-19T09:06:29.615810Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = {0: (x_neg_weight[0]/(x_pos_weight[0]+x_neg_weight[0])),1: (x_pos_weight[0]/(x_pos_weight[0]+x_neg_weight[0]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-19T09:06:29.727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 0.1834 - accuracy: 0.7719 - recall_1: 0.7708 - precision_1: 0.7715 - val_loss: 0.4231 - val_accuracy: 0.8031 - val_recall_1: 0.8044 - val_precision_1: 0.8018\n",
      "Epoch 2/10\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.1553 - accuracy: 0.8158 - recall_1: 0.8166 - precision_1: 0.8148 - val_loss: 0.4597 - val_accuracy: 0.7669 - val_recall_1: 0.7660 - val_precision_1: 0.7668\n",
      "Epoch 3/10\n",
      "420/420 [==============================] - 15s 35ms/step - loss: 0.1432 - accuracy: 0.8257 - recall_1: 0.8265 - precision_1: 0.8251 - val_loss: 0.4302 - val_accuracy: 0.7807 - val_recall_1: 0.7813 - val_precision_1: 0.7806\n",
      "Epoch 4/10\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.1302 - accuracy: 0.8354 - recall_1: 0.8350 - precision_1: 0.8353 - val_loss: 0.3914 - val_accuracy: 0.8066 - val_recall_1: 0.8060 - val_precision_1: 0.8065\n",
      "Epoch 5/10\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.1188 - accuracy: 0.8494 - recall_1: 0.8493 - precision_1: 0.8493 - val_loss: 0.4036 - val_accuracy: 0.8277 - val_recall_1: 0.8267 - val_precision_1: 0.8266\n",
      "Epoch 6/10\n",
      "420/420 [==============================] - 15s 36ms/step - loss: 0.1079 - accuracy: 0.8623 - recall_1: 0.8619 - precision_1: 0.8624 - val_loss: 0.4173 - val_accuracy: 0.8081 - val_recall_1: 0.8086 - val_precision_1: 0.8082\n",
      "Epoch 7/10\n",
      "420/420 [==============================] - 15s 35ms/step - loss: 0.0987 - accuracy: 0.8755 - recall_1: 0.8751 - precision_1: 0.8754 - val_loss: 0.4832 - val_accuracy: 0.7777 - val_recall_1: 0.7781 - val_precision_1: 0.7786\n",
      "Epoch 8/10\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.0921 - accuracy: 0.8817 - recall_1: 0.8813 - precision_1: 0.8820 - val_loss: 0.4584 - val_accuracy: 0.8259 - val_recall_1: 0.8259 - val_precision_1: 0.8257\n",
      "Epoch 9/10\n",
      "420/420 [==============================] - 15s 36ms/step - loss: 0.0877 - accuracy: 0.8908 - recall_1: 0.8906 - precision_1: 0.8910 - val_loss: 0.5145 - val_accuracy: 0.7794 - val_recall_1: 0.7796 - val_precision_1: 0.7796\n",
      "Epoch 10/10\n",
      "420/420 [==============================] - 15s 35ms/step - loss: 0.0832 - accuracy: 0.8960 - recall_1: 0.8960 - precision_1: 0.8962 - val_loss: 0.5268 - val_accuracy: 0.8193 - val_recall_1: 0.8191 - val_precision_1: 0.8196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e3288143d0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "hist = model.fit(x_train, y_tr, epochs=10, validation_split=0.1, shuffle=True,class_weight=weights, batch_size=batch_size,use_multiprocessing=True,workers=8)\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "predictions = model.predict(test_cnn_data)\n",
    "prediction_labels=[]\n",
    "labels = [0, 1]\n",
    "for p in predictions:\n",
    "    prediction_labels.append(labels[np.argmax(p)])\n",
    "print(classification_report(data_test.oh_label,prediction_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "420/420 [==============================] - 23s 46ms/step - loss: 0.1838 - accuracy: 0.7656 - recall: 0.7663 - precision: 0.7636 - val_loss: 0.3878 - val_accuracy: 0.8243 - val_recall: 0.8230 - val_precision: 0.8246\n",
      "Epoch 2/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.1564 - accuracy: 0.8110 - recall: 0.8100 - precision: 0.8108 - val_loss: 0.4648 - val_accuracy: 0.7816 - val_recall: 0.7793 - val_precision: 0.7814\n",
      "Epoch 3/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.1437 - accuracy: 0.8238 - recall: 0.8230 - precision: 0.8237 - val_loss: 0.4163 - val_accuracy: 0.8023 - val_recall: 0.8040 - val_precision: 0.8016\n",
      "Epoch 4/100\n",
      "420/420 [==============================] - 19s 44ms/step - loss: 0.1314 - accuracy: 0.8354 - recall: 0.8355 - precision: 0.8357 - val_loss: 0.3865 - val_accuracy: 0.8127 - val_recall: 0.8126 - val_precision: 0.8132\n",
      "Epoch 5/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.1192 - accuracy: 0.8474 - recall: 0.8473 - precision: 0.8477 - val_loss: 0.3845 - val_accuracy: 0.8234 - val_recall: 0.8233 - val_precision: 0.8243\n",
      "Epoch 6/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.1089 - accuracy: 0.8646 - recall: 0.8645 - precision: 0.8648 - val_loss: 0.3950 - val_accuracy: 0.8293 - val_recall: 0.8294 - val_precision: 0.8299\n",
      "Epoch 7/100\n",
      "420/420 [==============================] - 19s 45ms/step - loss: 0.1020 - accuracy: 0.8714 - recall: 0.8713 - precision: 0.8712 - val_loss: 0.4092 - val_accuracy: 0.8244 - val_recall: 0.8244 - val_precision: 0.8243\n",
      "Epoch 8/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0932 - accuracy: 0.8794 - recall: 0.8798 - precision: 0.8793 - val_loss: 0.4274 - val_accuracy: 0.8200 - val_recall: 0.8203 - val_precision: 0.8202\n",
      "Epoch 9/100\n",
      "420/420 [==============================] - 17s 42ms/step - loss: 0.0871 - accuracy: 0.8908 - recall: 0.8910 - precision: 0.8910 - val_loss: 0.4561 - val_accuracy: 0.8204 - val_recall: 0.8200 - val_precision: 0.8208\n",
      "Epoch 10/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0829 - accuracy: 0.8930 - recall: 0.8929 - precision: 0.8931 - val_loss: 0.4898 - val_accuracy: 0.8304 - val_recall: 0.8291 - val_precision: 0.8299\n",
      "Epoch 11/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0767 - accuracy: 0.9017 - recall: 0.9014 - precision: 0.9018 - val_loss: 0.5437 - val_accuracy: 0.8123 - val_recall: 0.8119 - val_precision: 0.8128\n",
      "Epoch 12/100\n",
      "420/420 [==============================] - 19s 44ms/step - loss: 0.0729 - accuracy: 0.9054 - recall: 0.9053 - precision: 0.9056 - val_loss: 0.5463 - val_accuracy: 0.8149 - val_recall: 0.8153 - val_precision: 0.8149\n",
      "Epoch 13/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0701 - accuracy: 0.9076 - recall: 0.9072 - precision: 0.9077 - val_loss: 0.5873 - val_accuracy: 0.8416 - val_recall: 0.8420 - val_precision: 0.8422\n",
      "Epoch 14/100\n",
      "420/420 [==============================] - 19s 45ms/step - loss: 0.0671 - accuracy: 0.9163 - recall: 0.9162 - precision: 0.9162 - val_loss: 0.5651 - val_accuracy: 0.8016 - val_recall: 0.8019 - val_precision: 0.8015\n",
      "Epoch 15/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0673 - accuracy: 0.9132 - recall: 0.9129 - precision: 0.9135 - val_loss: 0.5717 - val_accuracy: 0.8254 - val_recall: 0.8254 - val_precision: 0.8255\n",
      "Epoch 16/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0621 - accuracy: 0.9235 - recall: 0.9238 - precision: 0.9234 - val_loss: 0.5985 - val_accuracy: 0.8074 - val_recall: 0.8076 - val_precision: 0.8080\n",
      "Epoch 17/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0598 - accuracy: 0.9256 - recall: 0.9254 - precision: 0.9257 - val_loss: 0.6294 - val_accuracy: 0.8187 - val_recall: 0.8191 - val_precision: 0.8187\n",
      "Epoch 18/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0576 - accuracy: 0.9267 - recall: 0.9269 - precision: 0.9264 - val_loss: 0.7252 - val_accuracy: 0.8357 - val_recall: 0.8354 - val_precision: 0.8358\n",
      "Epoch 19/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0563 - accuracy: 0.9271 - recall: 0.9273 - precision: 0.9267 - val_loss: 0.6949 - val_accuracy: 0.8299 - val_recall: 0.8297 - val_precision: 0.8298\n",
      "Epoch 20/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0565 - accuracy: 0.9287 - recall: 0.9289 - precision: 0.9286 - val_loss: 0.8003 - val_accuracy: 0.8539 - val_recall: 0.8533 - val_precision: 0.8534\n",
      "Epoch 21/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0535 - accuracy: 0.9301 - recall: 0.9304 - precision: 0.9300 - val_loss: 0.7299 - val_accuracy: 0.8363 - val_recall: 0.8367 - val_precision: 0.8364\n",
      "Epoch 22/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0529 - accuracy: 0.9305 - recall: 0.9308 - precision: 0.9304 - val_loss: 0.7343 - val_accuracy: 0.8480 - val_recall: 0.8476 - val_precision: 0.8478\n",
      "Epoch 23/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0544 - accuracy: 0.9338 - recall: 0.9342 - precision: 0.9335 - val_loss: 0.6098 - val_accuracy: 0.8326 - val_recall: 0.8329 - val_precision: 0.8325\n",
      "Epoch 24/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0507 - accuracy: 0.9360 - recall: 0.9361 - precision: 0.9361 - val_loss: 0.7536 - val_accuracy: 0.8320 - val_recall: 0.8316 - val_precision: 0.8324\n",
      "Epoch 25/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0481 - accuracy: 0.9400 - recall: 0.9403 - precision: 0.9395 - val_loss: 0.7761 - val_accuracy: 0.8493 - val_recall: 0.8491 - val_precision: 0.8491\n",
      "Epoch 26/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0461 - accuracy: 0.9398 - recall: 0.9399 - precision: 0.9397 - val_loss: 0.8557 - val_accuracy: 0.8451 - val_recall: 0.8459 - val_precision: 0.8454\n",
      "Epoch 27/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0477 - accuracy: 0.9386 - recall: 0.9386 - precision: 0.9384 - val_loss: 0.7699 - val_accuracy: 0.8273 - val_recall: 0.8280 - val_precision: 0.8272\n",
      "Epoch 28/100\n",
      "420/420 [==============================] - 17s 42ms/step - loss: 0.0453 - accuracy: 0.9402 - recall: 0.9402 - precision: 0.9400 - val_loss: 0.8271 - val_accuracy: 0.8443 - val_recall: 0.8444 - val_precision: 0.8437\n",
      "Epoch 29/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0446 - accuracy: 0.9410 - recall: 0.9408 - precision: 0.9413 - val_loss: 0.9512 - val_accuracy: 0.8269 - val_recall: 0.8271 - val_precision: 0.8266\n",
      "Epoch 30/100\n",
      "420/420 [==============================] - 17s 42ms/step - loss: 0.0458 - accuracy: 0.9421 - recall: 0.9420 - precision: 0.9421 - val_loss: 0.8618 - val_accuracy: 0.8250 - val_recall: 0.8256 - val_precision: 0.8249\n",
      "Epoch 31/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0431 - accuracy: 0.9440 - recall: 0.9432 - precision: 0.9444 - val_loss: 0.8952 - val_accuracy: 0.8441 - val_recall: 0.8441 - val_precision: 0.8443\n",
      "Epoch 32/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0426 - accuracy: 0.9470 - recall: 0.9470 - precision: 0.9471 - val_loss: 0.8814 - val_accuracy: 0.8211 - val_recall: 0.8206 - val_precision: 0.8208\n",
      "Epoch 33/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0442 - accuracy: 0.9421 - recall: 0.9417 - precision: 0.9424 - val_loss: 0.9313 - val_accuracy: 0.8480 - val_recall: 0.8477 - val_precision: 0.8474\n",
      "Epoch 34/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0414 - accuracy: 0.9451 - recall: 0.9451 - precision: 0.9452 - val_loss: 0.8764 - val_accuracy: 0.8437 - val_recall: 0.8436 - val_precision: 0.8435\n",
      "Epoch 35/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0411 - accuracy: 0.9471 - recall: 0.9472 - precision: 0.9471 - val_loss: 0.9561 - val_accuracy: 0.8369 - val_recall: 0.8369 - val_precision: 0.8367\n",
      "Epoch 36/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0423 - accuracy: 0.9470 - recall: 0.9467 - precision: 0.9473 - val_loss: 0.8807 - val_accuracy: 0.8186 - val_recall: 0.8190 - val_precision: 0.8184\n",
      "Epoch 37/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0414 - accuracy: 0.9465 - recall: 0.9466 - precision: 0.9465 - val_loss: 0.9666 - val_accuracy: 0.8277 - val_recall: 0.8270 - val_precision: 0.8278\n",
      "Epoch 38/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0391 - accuracy: 0.9491 - recall: 0.9491 - precision: 0.9491 - val_loss: 0.8689 - val_accuracy: 0.8374 - val_recall: 0.8376 - val_precision: 0.8379\n",
      "Epoch 39/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0379 - accuracy: 0.9525 - recall: 0.9521 - precision: 0.9526 - val_loss: 0.8592 - val_accuracy: 0.8201 - val_recall: 0.8206 - val_precision: 0.8196\n",
      "Epoch 40/100\n",
      "420/420 [==============================] - 18s 44ms/step - loss: 0.0386 - accuracy: 0.9498 - recall: 0.9498 - precision: 0.9500 - val_loss: 0.9678 - val_accuracy: 0.8401 - val_recall: 0.8404 - val_precision: 0.8399\n",
      "Epoch 41/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0368 - accuracy: 0.9517 - recall: 0.9516 - precision: 0.9521 - val_loss: 1.0039 - val_accuracy: 0.8351 - val_recall: 0.8354 - val_precision: 0.8353\n",
      "Epoch 42/100\n",
      "420/420 [==============================] - 19s 44ms/step - loss: 0.0378 - accuracy: 0.9501 - recall: 0.9501 - precision: 0.9502 - val_loss: 1.0769 - val_accuracy: 0.8307 - val_recall: 0.8307 - val_precision: 0.8308\n",
      "Epoch 43/100\n",
      "420/420 [==============================] - 18s 44ms/step - loss: 0.0365 - accuracy: 0.9517 - recall: 0.9515 - precision: 0.9520 - val_loss: 1.1205 - val_accuracy: 0.8477 - val_recall: 0.8481 - val_precision: 0.8474\n",
      "Epoch 44/100\n",
      "420/420 [==============================] - 18s 44ms/step - loss: 0.0370 - accuracy: 0.9490 - recall: 0.9484 - precision: 0.9493 - val_loss: 1.0780 - val_accuracy: 0.8471 - val_recall: 0.8469 - val_precision: 0.8465\n",
      "Epoch 45/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0370 - accuracy: 0.9544 - recall: 0.9541 - precision: 0.9544 - val_loss: 0.9563 - val_accuracy: 0.8440 - val_recall: 0.8443 - val_precision: 0.8436\n",
      "Epoch 46/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0351 - accuracy: 0.9547 - recall: 0.9546 - precision: 0.9548 - val_loss: 0.9358 - val_accuracy: 0.8394 - val_recall: 0.8399 - val_precision: 0.8393\n",
      "Epoch 47/100\n",
      "420/420 [==============================] - 18s 44ms/step - loss: 0.0351 - accuracy: 0.9534 - recall: 0.9532 - precision: 0.9539 - val_loss: 1.0575 - val_accuracy: 0.8464 - val_recall: 0.8461 - val_precision: 0.8458\n",
      "Epoch 48/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0366 - accuracy: 0.9495 - recall: 0.9490 - precision: 0.9499 - val_loss: 1.0215 - val_accuracy: 0.8291 - val_recall: 0.8293 - val_precision: 0.8290\n",
      "Epoch 49/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0350 - accuracy: 0.9556 - recall: 0.9550 - precision: 0.9559 - val_loss: 1.0106 - val_accuracy: 0.8239 - val_recall: 0.8236 - val_precision: 0.8238\n",
      "Epoch 50/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0352 - accuracy: 0.9532 - recall: 0.9531 - precision: 0.9532 - val_loss: 0.9910 - val_accuracy: 0.8297 - val_recall: 0.8296 - val_precision: 0.8297\n",
      "Epoch 51/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0320 - accuracy: 0.9553 - recall: 0.9552 - precision: 0.9555 - val_loss: 1.1141 - val_accuracy: 0.8321 - val_recall: 0.8323 - val_precision: 0.8328\n",
      "Epoch 52/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0332 - accuracy: 0.9568 - recall: 0.9565 - precision: 0.9570 - val_loss: 1.1526 - val_accuracy: 0.8351 - val_recall: 0.8346 - val_precision: 0.8348\n",
      "Epoch 53/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0335 - accuracy: 0.9544 - recall: 0.9545 - precision: 0.9544 - val_loss: 1.1092 - val_accuracy: 0.8479 - val_recall: 0.8479 - val_precision: 0.8479\n",
      "Epoch 54/100\n",
      "420/420 [==============================] - 18s 44ms/step - loss: 0.0322 - accuracy: 0.9554 - recall: 0.9550 - precision: 0.9556 - val_loss: 1.1110 - val_accuracy: 0.8459 - val_recall: 0.8460 - val_precision: 0.8460\n",
      "Epoch 55/100\n",
      "420/420 [==============================] - 18s 44ms/step - loss: 0.0332 - accuracy: 0.9554 - recall: 0.9553 - precision: 0.9556 - val_loss: 1.2246 - val_accuracy: 0.8370 - val_recall: 0.8370 - val_precision: 0.8371\n",
      "Epoch 56/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0314 - accuracy: 0.9598 - recall: 0.9598 - precision: 0.9600 - val_loss: 1.1489 - val_accuracy: 0.8459 - val_recall: 0.8457 - val_precision: 0.8458\n",
      "Epoch 57/100\n",
      "420/420 [==============================] - 17s 42ms/step - loss: 0.0314 - accuracy: 0.9592 - recall: 0.9592 - precision: 0.9593 - val_loss: 1.1559 - val_accuracy: 0.8351 - val_recall: 0.8353 - val_precision: 0.8352\n",
      "Epoch 58/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0327 - accuracy: 0.9561 - recall: 0.9559 - precision: 0.9561 - val_loss: 1.1910 - val_accuracy: 0.8379 - val_recall: 0.8373 - val_precision: 0.8379\n",
      "Epoch 59/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0305 - accuracy: 0.9587 - recall: 0.9587 - precision: 0.9587 - val_loss: 1.2824 - val_accuracy: 0.8447 - val_recall: 0.8443 - val_precision: 0.8446\n",
      "Epoch 60/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0314 - accuracy: 0.9616 - recall: 0.9615 - precision: 0.9616 - val_loss: 1.1578 - val_accuracy: 0.8463 - val_recall: 0.8461 - val_precision: 0.8458\n",
      "Epoch 61/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0315 - accuracy: 0.9599 - recall: 0.9597 - precision: 0.9598 - val_loss: 1.1449 - val_accuracy: 0.8327 - val_recall: 0.8333 - val_precision: 0.8328\n",
      "Epoch 62/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0315 - accuracy: 0.9568 - recall: 0.9565 - precision: 0.9569 - val_loss: 1.2562 - val_accuracy: 0.8291 - val_recall: 0.8293 - val_precision: 0.8293\n",
      "Epoch 63/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0309 - accuracy: 0.9591 - recall: 0.9588 - precision: 0.9594 - val_loss: 1.1612 - val_accuracy: 0.8263 - val_recall: 0.8260 - val_precision: 0.8264\n",
      "Epoch 64/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0298 - accuracy: 0.9591 - recall: 0.9590 - precision: 0.9592 - val_loss: 1.1967 - val_accuracy: 0.8416 - val_recall: 0.8416 - val_precision: 0.8416\n",
      "Epoch 65/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0324 - accuracy: 0.9590 - recall: 0.9590 - precision: 0.9592 - val_loss: 1.1931 - val_accuracy: 0.8239 - val_recall: 0.8239 - val_precision: 0.8243\n",
      "Epoch 66/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0306 - accuracy: 0.9557 - recall: 0.9558 - precision: 0.9557 - val_loss: 1.2061 - val_accuracy: 0.8374 - val_recall: 0.8374 - val_precision: 0.8374\n",
      "Epoch 67/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0290 - accuracy: 0.9639 - recall: 0.9634 - precision: 0.9641 - val_loss: 1.3987 - val_accuracy: 0.8396 - val_recall: 0.8403 - val_precision: 0.8396\n",
      "Epoch 68/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0290 - accuracy: 0.9607 - recall: 0.9603 - precision: 0.9610 - val_loss: 1.3057 - val_accuracy: 0.8456 - val_recall: 0.8454 - val_precision: 0.8454\n",
      "Epoch 69/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0292 - accuracy: 0.9629 - recall: 0.9625 - precision: 0.9632 - val_loss: 1.4304 - val_accuracy: 0.8426 - val_recall: 0.8427 - val_precision: 0.8425\n",
      "Epoch 70/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0295 - accuracy: 0.9581 - recall: 0.9583 - precision: 0.9581 - val_loss: 1.3196 - val_accuracy: 0.8331 - val_recall: 0.8333 - val_precision: 0.8335\n",
      "Epoch 71/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0292 - accuracy: 0.9618 - recall: 0.9619 - precision: 0.9617 - val_loss: 1.2108 - val_accuracy: 0.8323 - val_recall: 0.8319 - val_precision: 0.8321\n",
      "Epoch 72/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0279 - accuracy: 0.9597 - recall: 0.9598 - precision: 0.9596 - val_loss: 1.2360 - val_accuracy: 0.8371 - val_recall: 0.8373 - val_precision: 0.8375\n",
      "Epoch 73/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0294 - accuracy: 0.9592 - recall: 0.9593 - precision: 0.9592 - val_loss: 1.3940 - val_accuracy: 0.8323 - val_recall: 0.8326 - val_precision: 0.8325\n",
      "Epoch 74/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0275 - accuracy: 0.9633 - recall: 0.9633 - precision: 0.9633 - val_loss: 1.5414 - val_accuracy: 0.8484 - val_recall: 0.8486 - val_precision: 0.8486\n",
      "Epoch 75/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0282 - accuracy: 0.9619 - recall: 0.9619 - precision: 0.9618 - val_loss: 1.4336 - val_accuracy: 0.8509 - val_recall: 0.8507 - val_precision: 0.8506\n",
      "Epoch 76/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0276 - accuracy: 0.9632 - recall: 0.9633 - precision: 0.9631 - val_loss: 1.4196 - val_accuracy: 0.8470 - val_recall: 0.8471 - val_precision: 0.8473\n",
      "Epoch 77/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0290 - accuracy: 0.9594 - recall: 0.9596 - precision: 0.9593 - val_loss: 1.4656 - val_accuracy: 0.8483 - val_recall: 0.8476 - val_precision: 0.8482\n",
      "Epoch 78/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0285 - accuracy: 0.9630 - recall: 0.9631 - precision: 0.9628 - val_loss: 1.3340 - val_accuracy: 0.8484 - val_recall: 0.8486 - val_precision: 0.8485\n",
      "Epoch 79/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0259 - accuracy: 0.9639 - recall: 0.9640 - precision: 0.9638 - val_loss: 1.4314 - val_accuracy: 0.8364 - val_recall: 0.8364 - val_precision: 0.8361\n",
      "Epoch 80/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0281 - accuracy: 0.9612 - recall: 0.9612 - precision: 0.9613 - val_loss: 1.4719 - val_accuracy: 0.8339 - val_recall: 0.8337 - val_precision: 0.8337\n",
      "Epoch 81/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0286 - accuracy: 0.9610 - recall: 0.9607 - precision: 0.9614 - val_loss: 1.5023 - val_accuracy: 0.8513 - val_recall: 0.8509 - val_precision: 0.8510\n",
      "Epoch 82/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0274 - accuracy: 0.9616 - recall: 0.9615 - precision: 0.9616 - val_loss: 1.3990 - val_accuracy: 0.8427 - val_recall: 0.8429 - val_precision: 0.8424\n",
      "Epoch 83/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0283 - accuracy: 0.9611 - recall: 0.9610 - precision: 0.9613 - val_loss: 1.2926 - val_accuracy: 0.8306 - val_recall: 0.8307 - val_precision: 0.8310\n",
      "Epoch 84/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0264 - accuracy: 0.9613 - recall: 0.9617 - precision: 0.9611 - val_loss: 1.3632 - val_accuracy: 0.8461 - val_recall: 0.8461 - val_precision: 0.8463\n",
      "Epoch 85/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0272 - accuracy: 0.9632 - recall: 0.9633 - precision: 0.9632 - val_loss: 1.4587 - val_accuracy: 0.8336 - val_recall: 0.8337 - val_precision: 0.8337\n",
      "Epoch 86/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0265 - accuracy: 0.9652 - recall: 0.9654 - precision: 0.9652 - val_loss: 1.3751 - val_accuracy: 0.8499 - val_recall: 0.8496 - val_precision: 0.8502\n",
      "Epoch 87/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0249 - accuracy: 0.9670 - recall: 0.9670 - precision: 0.9669 - val_loss: 1.6151 - val_accuracy: 0.8330 - val_recall: 0.8327 - val_precision: 0.8330\n",
      "Epoch 88/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0294 - accuracy: 0.9629 - recall: 0.9631 - precision: 0.9627 - val_loss: 1.5487 - val_accuracy: 0.8514 - val_recall: 0.8514 - val_precision: 0.8513\n",
      "Epoch 89/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0249 - accuracy: 0.9671 - recall: 0.9673 - precision: 0.9668 - val_loss: 1.5194 - val_accuracy: 0.8414 - val_recall: 0.8490 - val_precision: 0.8263\n",
      "Epoch 90/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0262 - accuracy: 0.9653 - recall: 0.9654 - precision: 0.9651 - val_loss: 1.4876 - val_accuracy: 0.8470 - val_recall: 0.8474 - val_precision: 0.8469\n",
      "Epoch 91/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0277 - accuracy: 0.9622 - recall: 0.9624 - precision: 0.9621 - val_loss: 1.3908 - val_accuracy: 0.8464 - val_recall: 0.8461 - val_precision: 0.8465\n",
      "Epoch 92/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0255 - accuracy: 0.9641 - recall: 0.9643 - precision: 0.9640 - val_loss: 1.5012 - val_accuracy: 0.8476 - val_recall: 0.8476 - val_precision: 0.8477\n",
      "Epoch 93/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0270 - accuracy: 0.9636 - recall: 0.9636 - precision: 0.9635 - val_loss: 1.4168 - val_accuracy: 0.8423 - val_recall: 0.8426 - val_precision: 0.8423\n",
      "Epoch 94/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0269 - accuracy: 0.9645 - recall: 0.9646 - precision: 0.9643 - val_loss: 1.4877 - val_accuracy: 0.8449 - val_recall: 0.8449 - val_precision: 0.8449\n",
      "Epoch 95/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0272 - accuracy: 0.9605 - recall: 0.9606 - precision: 0.9604 - val_loss: 1.5248 - val_accuracy: 0.8287 - val_recall: 0.8289 - val_precision: 0.8287\n",
      "Epoch 96/100\n",
      "420/420 [==============================] - 17s 42ms/step - loss: 0.0248 - accuracy: 0.9639 - recall: 0.9639 - precision: 0.9641 - val_loss: 1.4226 - val_accuracy: 0.8420 - val_recall: 0.8420 - val_precision: 0.8419\n",
      "Epoch 97/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0246 - accuracy: 0.9654 - recall: 0.9655 - precision: 0.9655 - val_loss: 1.7393 - val_accuracy: 0.8367 - val_recall: 0.8369 - val_precision: 0.8369\n",
      "Epoch 98/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0298 - accuracy: 0.9634 - recall: 0.9633 - precision: 0.9636 - val_loss: 1.3791 - val_accuracy: 0.8387 - val_recall: 0.8386 - val_precision: 0.8392\n",
      "Epoch 99/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0262 - accuracy: 0.9646 - recall: 0.9646 - precision: 0.9646 - val_loss: 1.4677 - val_accuracy: 0.8511 - val_recall: 0.8511 - val_precision: 0.8513\n",
      "Epoch 100/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0250 - accuracy: 0.9652 - recall: 0.9652 - precision: 0.9652 - val_loss: 1.5601 - val_accuracy: 0.8311 - val_recall: 0.8311 - val_precision: 0.8314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ffe2dbec40>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "hist2 = model.fit(x_train, y_tr, epochs=100, validation_split=0.1, shuffle=True,class_weight=weights, batch_size=batch_size,use_multiprocessing=True,workers=8,callbacks=[callback])\n",
    "hist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.85      0.88     11039\n",
      "         1.0       0.66      0.78      0.72      3961\n",
      "\n",
      "    accuracy                           0.84     15000\n",
      "   macro avg       0.79      0.82      0.80     15000\n",
      "weighted avg       0.85      0.84      0.84     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "predictions = model.predict(test_cnn_data)\n",
    "prediction_labels=[]\n",
    "labels = [0, 1]\n",
    "for p in predictions:\n",
    "    prediction_labels.append(labels[np.argmax(p)])\n",
    "print(classification_report(data_test.oh_label,prediction_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 50, 300)           39159600  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 44, 20)            42020     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 14, 20)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 280)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 280)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                17984     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 39,219,734\n",
      "Trainable params: 60,134\n",
      "Non-trainable params: 39,159,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embeddings, max_sequence_length, num_words, embedding_dim, labels_index = train_embedding_weights, MAX_SEQUENCE_LENGTH, len(train_word_index)+1, EMBEDDING_DIM, len(list(label_names))\n",
    "embedding_layer = Embedding(num_words,\n",
    "                        embedding_dim,\n",
    "                        weights=[embeddings],\n",
    "                        input_length=max_sequence_length,\n",
    "                        trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "conv1d = Conv1D(20,7,strides=1, use_bias=True,padding=\"valid\")(embedded_sequences)\n",
    "max_pool = MaxPool1D(pool_size=3)(conv1d)\n",
    "flattened = Flatten()(max_pool)\n",
    "x1 = Dropout(0.5)(flattened)\n",
    "x2 = Dense(64, activation='relu')(x1)\n",
    "x2 = Dropout(0.2)(x2)\n",
    "preds = Dense(labels_index, activation='sigmoid')(x2)\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),metrics=[\"accuracy\",tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "420/420 [==============================] - 19s 43ms/step - loss: 0.1965 - accuracy: 0.7478 - recall_1: 0.7462 - precision_1: 0.7458 - val_loss: 0.4094 - val_accuracy: 0.8190 - val_recall_1: 0.8157 - val_precision_1: 0.8199\n",
      "Epoch 2/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1709 - accuracy: 0.7977 - recall_1: 0.7953 - precision_1: 0.7982 - val_loss: 0.4363 - val_accuracy: 0.7903 - val_recall_1: 0.7894 - val_precision_1: 0.7917\n",
      "Epoch 3/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1646 - accuracy: 0.8043 - recall_1: 0.8011 - precision_1: 0.8057 - val_loss: 0.3857 - val_accuracy: 0.8286 - val_recall_1: 0.8274 - val_precision_1: 0.8294\n",
      "Epoch 4/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1588 - accuracy: 0.8083 - recall_1: 0.8051 - precision_1: 0.8101 - val_loss: 0.3881 - val_accuracy: 0.8291 - val_recall_1: 0.8263 - val_precision_1: 0.8295\n",
      "Epoch 5/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.1542 - accuracy: 0.8112 - recall_1: 0.8082 - precision_1: 0.8126 - val_loss: 0.3758 - val_accuracy: 0.8319 - val_recall_1: 0.8313 - val_precision_1: 0.8324\n",
      "Epoch 6/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1514 - accuracy: 0.8143 - recall_1: 0.8127 - precision_1: 0.8156 - val_loss: 0.4050 - val_accuracy: 0.7937 - val_recall_1: 0.7847 - val_precision_1: 0.8107\n",
      "Epoch 7/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1480 - accuracy: 0.8150 - recall_1: 0.8141 - precision_1: 0.8156 - val_loss: 0.3807 - val_accuracy: 0.8250 - val_recall_1: 0.8249 - val_precision_1: 0.8251\n",
      "Epoch 8/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1451 - accuracy: 0.8186 - recall_1: 0.8177 - precision_1: 0.8190 - val_loss: 0.3830 - val_accuracy: 0.8080 - val_recall_1: 0.8071 - val_precision_1: 0.8085\n",
      "Epoch 9/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1429 - accuracy: 0.8187 - recall_1: 0.8189 - precision_1: 0.8189 - val_loss: 0.3873 - val_accuracy: 0.8061 - val_recall_1: 0.8057 - val_precision_1: 0.8065\n",
      "Epoch 10/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1402 - accuracy: 0.8229 - recall_1: 0.8228 - precision_1: 0.8229 - val_loss: 0.3808 - val_accuracy: 0.8084 - val_recall_1: 0.8084 - val_precision_1: 0.8083\n",
      "Epoch 11/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.1366 - accuracy: 0.8249 - recall_1: 0.8251 - precision_1: 0.8246 - val_loss: 0.3996 - val_accuracy: 0.7967 - val_recall_1: 0.7969 - val_precision_1: 0.7965\n",
      "Epoch 12/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1352 - accuracy: 0.8267 - recall_1: 0.8275 - precision_1: 0.8264 - val_loss: 0.3910 - val_accuracy: 0.8023 - val_recall_1: 0.8031 - val_precision_1: 0.8028\n",
      "Epoch 13/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1326 - accuracy: 0.8288 - recall_1: 0.8291 - precision_1: 0.8286 - val_loss: 0.3593 - val_accuracy: 0.8463 - val_recall_1: 0.8464 - val_precision_1: 0.8464\n",
      "Epoch 14/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.1304 - accuracy: 0.8331 - recall_1: 0.8333 - precision_1: 0.8330 - val_loss: 0.3786 - val_accuracy: 0.8140 - val_recall_1: 0.8140 - val_precision_1: 0.8138\n",
      "Epoch 15/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.1282 - accuracy: 0.8349 - recall_1: 0.8354 - precision_1: 0.8349 - val_loss: 0.3614 - val_accuracy: 0.8286 - val_recall_1: 0.8289 - val_precision_1: 0.8287\n",
      "Epoch 16/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1284 - accuracy: 0.8334 - recall_1: 0.8336 - precision_1: 0.8331 - val_loss: 0.3694 - val_accuracy: 0.8261 - val_recall_1: 0.8261 - val_precision_1: 0.8260\n",
      "Epoch 17/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.1260 - accuracy: 0.8366 - recall_1: 0.8366 - precision_1: 0.8365 - val_loss: 0.3731 - val_accuracy: 0.8453 - val_recall_1: 0.8450 - val_precision_1: 0.8452\n",
      "Epoch 18/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1247 - accuracy: 0.8381 - recall_1: 0.8381 - precision_1: 0.8380 - val_loss: 0.3713 - val_accuracy: 0.8261 - val_recall_1: 0.8264 - val_precision_1: 0.8262\n",
      "Epoch 19/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1224 - accuracy: 0.8421 - recall_1: 0.8423 - precision_1: 0.8421 - val_loss: 0.3774 - val_accuracy: 0.8147 - val_recall_1: 0.8150 - val_precision_1: 0.8148\n",
      "Epoch 20/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1222 - accuracy: 0.8430 - recall_1: 0.8431 - precision_1: 0.8430 - val_loss: 0.3620 - val_accuracy: 0.8317 - val_recall_1: 0.8321 - val_precision_1: 0.8317\n",
      "Epoch 21/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1212 - accuracy: 0.8424 - recall_1: 0.8424 - precision_1: 0.8423 - val_loss: 0.3702 - val_accuracy: 0.8356 - val_recall_1: 0.8356 - val_precision_1: 0.8356\n",
      "Epoch 22/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1198 - accuracy: 0.8452 - recall_1: 0.8452 - precision_1: 0.8451 - val_loss: 0.3610 - val_accuracy: 0.8316 - val_recall_1: 0.8316 - val_precision_1: 0.8316\n",
      "Epoch 23/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1192 - accuracy: 0.8465 - recall_1: 0.8467 - precision_1: 0.8465 - val_loss: 0.3781 - val_accuracy: 0.8163 - val_recall_1: 0.8164 - val_precision_1: 0.8163\n",
      "Epoch 24/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.1181 - accuracy: 0.8467 - recall_1: 0.8468 - precision_1: 0.8467 - val_loss: 0.3766 - val_accuracy: 0.8231 - val_recall_1: 0.8231 - val_precision_1: 0.8231\n",
      "Epoch 25/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1169 - accuracy: 0.8462 - recall_1: 0.8462 - precision_1: 0.8461 - val_loss: 0.3767 - val_accuracy: 0.8309 - val_recall_1: 0.8310 - val_precision_1: 0.8309\n",
      "Epoch 26/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1144 - accuracy: 0.8510 - recall_1: 0.8510 - precision_1: 0.8510 - val_loss: 0.3883 - val_accuracy: 0.8229 - val_recall_1: 0.8230 - val_precision_1: 0.8229\n",
      "Epoch 27/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1147 - accuracy: 0.8515 - recall_1: 0.8515 - precision_1: 0.8515 - val_loss: 0.3933 - val_accuracy: 0.8146 - val_recall_1: 0.8147 - val_precision_1: 0.8145\n",
      "Epoch 28/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.1137 - accuracy: 0.8514 - recall_1: 0.8514 - precision_1: 0.8515 - val_loss: 0.3736 - val_accuracy: 0.8373 - val_recall_1: 0.8373 - val_precision_1: 0.8373\n",
      "Epoch 29/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1132 - accuracy: 0.8523 - recall_1: 0.8523 - precision_1: 0.8523 - val_loss: 0.3866 - val_accuracy: 0.8224 - val_recall_1: 0.8224 - val_precision_1: 0.8224\n",
      "Epoch 30/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1126 - accuracy: 0.8530 - recall_1: 0.8530 - precision_1: 0.8530 - val_loss: 0.3777 - val_accuracy: 0.8240 - val_recall_1: 0.8240 - val_precision_1: 0.8240\n",
      "Epoch 31/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1119 - accuracy: 0.8551 - recall_1: 0.8551 - precision_1: 0.8551 - val_loss: 0.3875 - val_accuracy: 0.8189 - val_recall_1: 0.8189 - val_precision_1: 0.8189\n",
      "Epoch 32/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.1104 - accuracy: 0.8576 - recall_1: 0.8576 - precision_1: 0.8576 - val_loss: 0.3927 - val_accuracy: 0.8251 - val_recall_1: 0.8251 - val_precision_1: 0.8251\n",
      "Epoch 33/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1103 - accuracy: 0.8588 - recall_1: 0.8588 - precision_1: 0.8588 - val_loss: 0.3735 - val_accuracy: 0.8413 - val_recall_1: 0.8413 - val_precision_1: 0.8414\n",
      "Epoch 34/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.1099 - accuracy: 0.8582 - recall_1: 0.8582 - precision_1: 0.8582 - val_loss: 0.3869 - val_accuracy: 0.8221 - val_recall_1: 0.8223 - val_precision_1: 0.8222\n",
      "Epoch 35/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1092 - accuracy: 0.8589 - recall_1: 0.8589 - precision_1: 0.8589 - val_loss: 0.3835 - val_accuracy: 0.8363 - val_recall_1: 0.8363 - val_precision_1: 0.8363\n",
      "Epoch 36/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.1091 - accuracy: 0.8594 - recall_1: 0.8594 - precision_1: 0.8594 - val_loss: 0.3713 - val_accuracy: 0.8297 - val_recall_1: 0.8297 - val_precision_1: 0.8297\n",
      "Epoch 37/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1079 - accuracy: 0.8606 - recall_1: 0.8606 - precision_1: 0.8606 - val_loss: 0.3791 - val_accuracy: 0.8270 - val_recall_1: 0.8270 - val_precision_1: 0.8270\n",
      "Epoch 38/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1065 - accuracy: 0.8620 - recall_1: 0.8620 - precision_1: 0.8620 - val_loss: 0.3806 - val_accuracy: 0.8307 - val_recall_1: 0.8307 - val_precision_1: 0.8307\n",
      "Epoch 39/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1078 - accuracy: 0.8607 - recall_1: 0.8607 - precision_1: 0.8607 - val_loss: 0.3726 - val_accuracy: 0.8327 - val_recall_1: 0.8327 - val_precision_1: 0.8327\n",
      "Epoch 40/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1077 - accuracy: 0.8595 - recall_1: 0.8595 - precision_1: 0.8595 - val_loss: 0.3858 - val_accuracy: 0.8354 - val_recall_1: 0.8354 - val_precision_1: 0.8354\n",
      "Epoch 41/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1058 - accuracy: 0.8633 - recall_1: 0.8634 - precision_1: 0.8634 - val_loss: 0.3909 - val_accuracy: 0.8241 - val_recall_1: 0.8241 - val_precision_1: 0.8241\n",
      "Epoch 42/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1063 - accuracy: 0.8632 - recall_1: 0.8632 - precision_1: 0.8632 - val_loss: 0.3900 - val_accuracy: 0.8311 - val_recall_1: 0.8311 - val_precision_1: 0.8311\n",
      "Epoch 43/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1054 - accuracy: 0.8625 - recall_1: 0.8626 - precision_1: 0.8625 - val_loss: 0.3805 - val_accuracy: 0.8260 - val_recall_1: 0.8260 - val_precision_1: 0.8260\n",
      "Epoch 44/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1054 - accuracy: 0.8642 - recall_1: 0.8642 - precision_1: 0.8642 - val_loss: 0.4027 - val_accuracy: 0.8221 - val_recall_1: 0.8221 - val_precision_1: 0.8221\n",
      "Epoch 45/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1046 - accuracy: 0.8640 - recall_1: 0.8640 - precision_1: 0.8640 - val_loss: 0.3910 - val_accuracy: 0.8327 - val_recall_1: 0.8327 - val_precision_1: 0.8327\n",
      "Epoch 46/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1045 - accuracy: 0.8653 - recall_1: 0.8653 - precision_1: 0.8653 - val_loss: 0.3847 - val_accuracy: 0.8269 - val_recall_1: 0.8269 - val_precision_1: 0.8269\n",
      "Epoch 47/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.1036 - accuracy: 0.8632 - recall_1: 0.8632 - precision_1: 0.8632 - val_loss: 0.4001 - val_accuracy: 0.8171 - val_recall_1: 0.8171 - val_precision_1: 0.8171\n",
      "Epoch 48/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1028 - accuracy: 0.8672 - recall_1: 0.8672 - precision_1: 0.8672 - val_loss: 0.3821 - val_accuracy: 0.8483 - val_recall_1: 0.8483 - val_precision_1: 0.8483\n",
      "Epoch 49/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1037 - accuracy: 0.8647 - recall_1: 0.8647 - precision_1: 0.8647 - val_loss: 0.3960 - val_accuracy: 0.8229 - val_recall_1: 0.8229 - val_precision_1: 0.8229\n",
      "Epoch 50/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1035 - accuracy: 0.8664 - recall_1: 0.8664 - precision_1: 0.8664 - val_loss: 0.3827 - val_accuracy: 0.8277 - val_recall_1: 0.8277 - val_precision_1: 0.8277\n",
      "Epoch 51/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.1019 - accuracy: 0.8684 - recall_1: 0.8684 - precision_1: 0.8684 - val_loss: 0.3922 - val_accuracy: 0.8381 - val_recall_1: 0.8381 - val_precision_1: 0.8381\n",
      "Epoch 52/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1016 - accuracy: 0.8688 - recall_1: 0.8688 - precision_1: 0.8688 - val_loss: 0.3939 - val_accuracy: 0.8327 - val_recall_1: 0.8327 - val_precision_1: 0.8327\n",
      "Epoch 53/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1012 - accuracy: 0.8683 - recall_1: 0.8683 - precision_1: 0.8683 - val_loss: 0.4052 - val_accuracy: 0.8177 - val_recall_1: 0.8177 - val_precision_1: 0.8177\n",
      "Epoch 54/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1017 - accuracy: 0.8684 - recall_1: 0.8684 - precision_1: 0.8684 - val_loss: 0.3973 - val_accuracy: 0.8244 - val_recall_1: 0.8244 - val_precision_1: 0.8244\n",
      "Epoch 55/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0995 - accuracy: 0.8705 - recall_1: 0.8705 - precision_1: 0.8705 - val_loss: 0.4024 - val_accuracy: 0.8250 - val_recall_1: 0.8250 - val_precision_1: 0.8250\n",
      "Epoch 56/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1007 - accuracy: 0.8684 - recall_1: 0.8684 - precision_1: 0.8684 - val_loss: 0.4007 - val_accuracy: 0.8316 - val_recall_1: 0.8316 - val_precision_1: 0.8316\n",
      "Epoch 57/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1003 - accuracy: 0.8695 - recall_1: 0.8695 - precision_1: 0.8695 - val_loss: 0.3929 - val_accuracy: 0.8237 - val_recall_1: 0.8237 - val_precision_1: 0.8237\n",
      "Epoch 58/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0999 - accuracy: 0.8698 - recall_1: 0.8698 - precision_1: 0.8698 - val_loss: 0.4025 - val_accuracy: 0.8380 - val_recall_1: 0.8380 - val_precision_1: 0.8380\n",
      "Epoch 59/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0992 - accuracy: 0.8714 - recall_1: 0.8714 - precision_1: 0.8714 - val_loss: 0.3947 - val_accuracy: 0.8370 - val_recall_1: 0.8370 - val_precision_1: 0.8370\n",
      "Epoch 60/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0992 - accuracy: 0.8697 - recall_1: 0.8697 - precision_1: 0.8697 - val_loss: 0.4216 - val_accuracy: 0.8226 - val_recall_1: 0.8226 - val_precision_1: 0.8226\n",
      "Epoch 61/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0985 - accuracy: 0.8725 - recall_1: 0.8725 - precision_1: 0.8725 - val_loss: 0.4135 - val_accuracy: 0.8386 - val_recall_1: 0.8386 - val_precision_1: 0.8386\n",
      "Epoch 62/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0996 - accuracy: 0.8695 - recall_1: 0.8695 - precision_1: 0.8695 - val_loss: 0.3998 - val_accuracy: 0.8273 - val_recall_1: 0.8273 - val_precision_1: 0.8273\n",
      "Epoch 63/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0981 - accuracy: 0.8727 - recall_1: 0.8727 - precision_1: 0.8727 - val_loss: 0.4068 - val_accuracy: 0.8207 - val_recall_1: 0.8207 - val_precision_1: 0.8207\n",
      "Epoch 64/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0977 - accuracy: 0.8726 - recall_1: 0.8726 - precision_1: 0.8726 - val_loss: 0.4029 - val_accuracy: 0.8514 - val_recall_1: 0.8514 - val_precision_1: 0.8514\n",
      "Epoch 65/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0968 - accuracy: 0.8743 - recall_1: 0.8743 - precision_1: 0.8743 - val_loss: 0.4055 - val_accuracy: 0.8264 - val_recall_1: 0.8264 - val_precision_1: 0.8264\n",
      "Epoch 66/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0972 - accuracy: 0.8735 - recall_1: 0.8735 - precision_1: 0.8735 - val_loss: 0.4119 - val_accuracy: 0.8310 - val_recall_1: 0.8310 - val_precision_1: 0.8310\n",
      "Epoch 67/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0975 - accuracy: 0.8720 - recall_1: 0.8720 - precision_1: 0.8720 - val_loss: 0.4236 - val_accuracy: 0.8270 - val_recall_1: 0.8270 - val_precision_1: 0.8270\n",
      "Epoch 68/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0972 - accuracy: 0.8721 - recall_1: 0.8721 - precision_1: 0.8721 - val_loss: 0.4083 - val_accuracy: 0.8340 - val_recall_1: 0.8340 - val_precision_1: 0.8340\n",
      "Epoch 69/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0974 - accuracy: 0.8751 - recall_1: 0.8751 - precision_1: 0.8751 - val_loss: 0.3937 - val_accuracy: 0.8287 - val_recall_1: 0.8287 - val_precision_1: 0.8287\n",
      "Epoch 70/1000\n",
      "420/420 [==============================] - 20s 47ms/step - loss: 0.0976 - accuracy: 0.8734 - recall_1: 0.8734 - precision_1: 0.8734 - val_loss: 0.4162 - val_accuracy: 0.8279 - val_recall_1: 0.8279 - val_precision_1: 0.8279\n",
      "Epoch 71/1000\n",
      "420/420 [==============================] - 18s 44ms/step - loss: 0.0956 - accuracy: 0.8765 - recall_1: 0.8765 - precision_1: 0.8765 - val_loss: 0.4111 - val_accuracy: 0.8280 - val_recall_1: 0.8280 - val_precision_1: 0.8280\n",
      "Epoch 72/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0959 - accuracy: 0.8749 - recall_1: 0.8749 - precision_1: 0.8749 - val_loss: 0.4269 - val_accuracy: 0.8116 - val_recall_1: 0.8116 - val_precision_1: 0.8116\n",
      "Epoch 73/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0959 - accuracy: 0.8752 - recall_1: 0.8752 - precision_1: 0.8752 - val_loss: 0.4302 - val_accuracy: 0.8434 - val_recall_1: 0.8434 - val_precision_1: 0.8434\n",
      "Epoch 74/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0940 - accuracy: 0.8783 - recall_1: 0.8783 - precision_1: 0.8783 - val_loss: 0.4130 - val_accuracy: 0.8249 - val_recall_1: 0.8249 - val_precision_1: 0.8249\n",
      "Epoch 75/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0958 - accuracy: 0.8734 - recall_1: 0.8734 - precision_1: 0.8734 - val_loss: 0.3922 - val_accuracy: 0.8341 - val_recall_1: 0.8341 - val_precision_1: 0.8341\n",
      "Epoch 76/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0944 - accuracy: 0.8778 - recall_1: 0.8778 - precision_1: 0.8778 - val_loss: 0.3977 - val_accuracy: 0.8450 - val_recall_1: 0.8450 - val_precision_1: 0.8450\n",
      "Epoch 77/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0942 - accuracy: 0.8768 - recall_1: 0.8768 - precision_1: 0.8768 - val_loss: 0.4185 - val_accuracy: 0.8196 - val_recall_1: 0.8196 - val_precision_1: 0.8196\n",
      "Epoch 78/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0946 - accuracy: 0.8769 - recall_1: 0.8769 - precision_1: 0.8769 - val_loss: 0.4055 - val_accuracy: 0.8503 - val_recall_1: 0.8503 - val_precision_1: 0.8503\n",
      "Epoch 79/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0937 - accuracy: 0.8785 - recall_1: 0.8785 - precision_1: 0.8785 - val_loss: 0.3962 - val_accuracy: 0.8300 - val_recall_1: 0.8300 - val_precision_1: 0.8300\n",
      "Epoch 80/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0947 - accuracy: 0.8764 - recall_1: 0.8764 - precision_1: 0.8764 - val_loss: 0.3830 - val_accuracy: 0.8363 - val_recall_1: 0.8363 - val_precision_1: 0.8363\n",
      "Epoch 81/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0934 - accuracy: 0.8802 - recall_1: 0.8802 - precision_1: 0.8802 - val_loss: 0.4001 - val_accuracy: 0.8323 - val_recall_1: 0.8323 - val_precision_1: 0.8323\n",
      "Epoch 82/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0939 - accuracy: 0.8770 - recall_1: 0.8770 - precision_1: 0.8770 - val_loss: 0.4110 - val_accuracy: 0.8200 - val_recall_1: 0.8200 - val_precision_1: 0.8200\n",
      "Epoch 83/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0937 - accuracy: 0.8777 - recall_1: 0.8777 - precision_1: 0.8777 - val_loss: 0.4109 - val_accuracy: 0.8301 - val_recall_1: 0.8301 - val_precision_1: 0.8301\n",
      "Epoch 84/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0931 - accuracy: 0.8787 - recall_1: 0.8787 - precision_1: 0.8787 - val_loss: 0.4048 - val_accuracy: 0.8190 - val_recall_1: 0.8190 - val_precision_1: 0.8190\n",
      "Epoch 85/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0921 - accuracy: 0.8802 - recall_1: 0.8802 - precision_1: 0.8802 - val_loss: 0.3961 - val_accuracy: 0.8213 - val_recall_1: 0.8213 - val_precision_1: 0.8213\n",
      "Epoch 86/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.0947 - accuracy: 0.8757 - recall_1: 0.8757 - precision_1: 0.8757 - val_loss: 0.4115 - val_accuracy: 0.8306 - val_recall_1: 0.8306 - val_precision_1: 0.8306\n",
      "Epoch 87/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.0930 - accuracy: 0.8771 - recall_1: 0.8771 - precision_1: 0.8771 - val_loss: 0.4075 - val_accuracy: 0.8500 - val_recall_1: 0.8500 - val_precision_1: 0.8500\n",
      "Epoch 88/1000\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.0925 - accuracy: 0.8800 - recall_1: 0.8800 - precision_1: 0.8800 - val_loss: 0.4048 - val_accuracy: 0.8240 - val_recall_1: 0.8240 - val_precision_1: 0.8240\n",
      "Epoch 89/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.0926 - accuracy: 0.8802 - recall_1: 0.8802 - precision_1: 0.8802 - val_loss: 0.3939 - val_accuracy: 0.8306 - val_recall_1: 0.8306 - val_precision_1: 0.8306\n",
      "Epoch 90/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.0923 - accuracy: 0.8797 - recall_1: 0.8797 - precision_1: 0.8797 - val_loss: 0.4056 - val_accuracy: 0.8306 - val_recall_1: 0.8306 - val_precision_1: 0.8306\n",
      "Epoch 91/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0924 - accuracy: 0.8781 - recall_1: 0.8781 - precision_1: 0.8781 - val_loss: 0.4160 - val_accuracy: 0.8266 - val_recall_1: 0.8266 - val_precision_1: 0.8266\n",
      "Epoch 92/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0919 - accuracy: 0.8806 - recall_1: 0.8806 - precision_1: 0.8806 - val_loss: 0.4360 - val_accuracy: 0.8187 - val_recall_1: 0.8187 - val_precision_1: 0.8187\n",
      "Epoch 93/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.0912 - accuracy: 0.8808 - recall_1: 0.8808 - precision_1: 0.8808 - val_loss: 0.4118 - val_accuracy: 0.8333 - val_recall_1: 0.8333 - val_precision_1: 0.8333\n",
      "Epoch 94/1000\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.0913 - accuracy: 0.8804 - recall_1: 0.8804 - precision_1: 0.8804 - val_loss: 0.4120 - val_accuracy: 0.8271 - val_recall_1: 0.8271 - val_precision_1: 0.8271\n",
      "Epoch 95/1000\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 0.0909 - accuracy: 0.8822 - recall_1: 0.8822 - precision_1: 0.8822 - val_loss: 0.4270 - val_accuracy: 0.8184 - val_recall_1: 0.8184 - val_precision_1: 0.8184\n",
      "Epoch 96/1000\n",
      "420/420 [==============================] - 15s 36ms/step - loss: 0.0905 - accuracy: 0.8798 - recall_1: 0.8798 - precision_1: 0.8798 - val_loss: 0.4156 - val_accuracy: 0.8266 - val_recall_1: 0.8266 - val_precision_1: 0.8266\n",
      "Epoch 97/1000\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.0916 - accuracy: 0.8796 - recall_1: 0.8796 - precision_1: 0.8796 - val_loss: 0.4134 - val_accuracy: 0.8304 - val_recall_1: 0.8304 - val_precision_1: 0.8304\n",
      "Epoch 98/1000\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.0909 - accuracy: 0.8821 - recall_1: 0.8821 - precision_1: 0.8821 - val_loss: 0.4088 - val_accuracy: 0.8294 - val_recall_1: 0.8294 - val_precision_1: 0.8294\n",
      "Epoch 99/1000\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 0.0900 - accuracy: 0.8820 - recall_1: 0.8820 - precision_1: 0.8820 - val_loss: 0.4103 - val_accuracy: 0.8354 - val_recall_1: 0.8354 - val_precision_1: 0.8354\n",
      "Epoch 100/1000\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 0.0895 - accuracy: 0.8826 - recall_1: 0.8826 - precision_1: 0.8826 - val_loss: 0.4428 - val_accuracy: 0.8221 - val_recall_1: 0.8221 - val_precision_1: 0.8221\n",
      "Epoch 101/1000\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 0.0906 - accuracy: 0.8802 - recall_1: 0.8802 - precision_1: 0.8802 - val_loss: 0.4056 - val_accuracy: 0.8261 - val_recall_1: 0.8261 - val_precision_1: 0.8261\n",
      "Epoch 102/1000\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.0904 - accuracy: 0.8829 - recall_1: 0.8829 - precision_1: 0.8829 - val_loss: 0.4110 - val_accuracy: 0.8333 - val_recall_1: 0.8333 - val_precision_1: 0.8333\n",
      "Epoch 103/1000\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 0.0909 - accuracy: 0.8797 - recall_1: 0.8797 - precision_1: 0.8797 - val_loss: 0.4168 - val_accuracy: 0.8414 - val_recall_1: 0.8414 - val_precision_1: 0.8414\n",
      "Epoch 104/1000\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 0.0889 - accuracy: 0.8849 - recall_1: 0.8849 - precision_1: 0.8849 - val_loss: 0.4178 - val_accuracy: 0.8356 - val_recall_1: 0.8356 - val_precision_1: 0.8356\n",
      "Epoch 105/1000\n",
      "420/420 [==============================] - 15s 36ms/step - loss: 0.0893 - accuracy: 0.8817 - recall_1: 0.8817 - precision_1: 0.8817 - val_loss: 0.4321 - val_accuracy: 0.8397 - val_recall_1: 0.8397 - val_precision_1: 0.8397\n",
      "Epoch 106/1000\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.0888 - accuracy: 0.8829 - recall_1: 0.8829 - precision_1: 0.8829 - val_loss: 0.4476 - val_accuracy: 0.8307 - val_recall_1: 0.8307 - val_precision_1: 0.8307\n",
      "Epoch 107/1000\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.0900 - accuracy: 0.8825 - recall_1: 0.8825 - precision_1: 0.8825 - val_loss: 0.4205 - val_accuracy: 0.8527 - val_recall_1: 0.8527 - val_precision_1: 0.8527\n",
      "Epoch 108/1000\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.0904 - accuracy: 0.8798 - recall_1: 0.8798 - precision_1: 0.8798 - val_loss: 0.4040 - val_accuracy: 0.8296 - val_recall_1: 0.8296 - val_precision_1: 0.8296\n",
      "Epoch 109/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0894 - accuracy: 0.8830 - recall_1: 0.8830 - precision_1: 0.8830 - val_loss: 0.4171 - val_accuracy: 0.8176 - val_recall_1: 0.8176 - val_precision_1: 0.8176\n",
      "Epoch 110/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0891 - accuracy: 0.8832 - recall_1: 0.8832 - precision_1: 0.8832 - val_loss: 0.4067 - val_accuracy: 0.8497 - val_recall_1: 0.8497 - val_precision_1: 0.8497\n",
      "Epoch 111/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.0880 - accuracy: 0.8863 - recall_1: 0.8863 - precision_1: 0.8863 - val_loss: 0.4042 - val_accuracy: 0.8323 - val_recall_1: 0.8323 - val_precision_1: 0.8323\n",
      "Epoch 112/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.0891 - accuracy: 0.8827 - recall_1: 0.8827 - precision_1: 0.8827 - val_loss: 0.4090 - val_accuracy: 0.8471 - val_recall_1: 0.8471 - val_precision_1: 0.8471\n",
      "Epoch 113/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.0893 - accuracy: 0.8831 - recall_1: 0.8831 - precision_1: 0.8831 - val_loss: 0.4150 - val_accuracy: 0.8359 - val_recall_1: 0.8359 - val_precision_1: 0.8359\n",
      "Epoch 114/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0884 - accuracy: 0.8851 - recall_1: 0.8851 - precision_1: 0.8851 - val_loss: 0.4164 - val_accuracy: 0.8344 - val_recall_1: 0.8344 - val_precision_1: 0.8344\n",
      "Epoch 115/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0880 - accuracy: 0.8851 - recall_1: 0.8851 - precision_1: 0.8851 - val_loss: 0.4315 - val_accuracy: 0.8336 - val_recall_1: 0.8336 - val_precision_1: 0.8336\n",
      "Epoch 116/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0875 - accuracy: 0.8857 - recall_1: 0.8857 - precision_1: 0.8857 - val_loss: 0.4417 - val_accuracy: 0.8287 - val_recall_1: 0.8287 - val_precision_1: 0.8287\n",
      "Epoch 117/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0875 - accuracy: 0.8851 - recall_1: 0.8851 - precision_1: 0.8851 - val_loss: 0.4375 - val_accuracy: 0.8329 - val_recall_1: 0.8329 - val_precision_1: 0.8329\n",
      "Epoch 118/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0883 - accuracy: 0.8839 - recall_1: 0.8839 - precision_1: 0.8839 - val_loss: 0.4277 - val_accuracy: 0.8414 - val_recall_1: 0.8414 - val_precision_1: 0.8414\n",
      "Epoch 119/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0881 - accuracy: 0.8845 - recall_1: 0.8845 - precision_1: 0.8845 - val_loss: 0.4199 - val_accuracy: 0.8346 - val_recall_1: 0.8346 - val_precision_1: 0.8346\n",
      "Epoch 120/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0883 - accuracy: 0.8835 - recall_1: 0.8835 - precision_1: 0.8835 - val_loss: 0.4150 - val_accuracy: 0.8410 - val_recall_1: 0.8410 - val_precision_1: 0.8410\n",
      "Epoch 121/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0877 - accuracy: 0.8847 - recall_1: 0.8847 - precision_1: 0.8847 - val_loss: 0.4252 - val_accuracy: 0.8299 - val_recall_1: 0.8299 - val_precision_1: 0.8299\n",
      "Epoch 122/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0874 - accuracy: 0.8852 - recall_1: 0.8852 - precision_1: 0.8852 - val_loss: 0.4028 - val_accuracy: 0.8277 - val_recall_1: 0.8277 - val_precision_1: 0.8277\n",
      "Epoch 123/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0873 - accuracy: 0.8852 - recall_1: 0.8852 - precision_1: 0.8852 - val_loss: 0.4212 - val_accuracy: 0.8381 - val_recall_1: 0.8381 - val_precision_1: 0.8381\n",
      "Epoch 124/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.0863 - accuracy: 0.8871 - recall_1: 0.8871 - precision_1: 0.8871 - val_loss: 0.4117 - val_accuracy: 0.8293 - val_recall_1: 0.8293 - val_precision_1: 0.8293\n",
      "Epoch 125/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0871 - accuracy: 0.8865 - recall_1: 0.8865 - precision_1: 0.8865 - val_loss: 0.4236 - val_accuracy: 0.8311 - val_recall_1: 0.8311 - val_precision_1: 0.8311\n",
      "Epoch 126/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0883 - accuracy: 0.8837 - recall_1: 0.8837 - precision_1: 0.8837 - val_loss: 0.4309 - val_accuracy: 0.8113 - val_recall_1: 0.8113 - val_precision_1: 0.8113\n",
      "Epoch 127/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0863 - accuracy: 0.8866 - recall_1: 0.8866 - precision_1: 0.8866 - val_loss: 0.4419 - val_accuracy: 0.8267 - val_recall_1: 0.8267 - val_precision_1: 0.8267\n",
      "Epoch 128/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0858 - accuracy: 0.8870 - recall_1: 0.8870 - precision_1: 0.8870 - val_loss: 0.4296 - val_accuracy: 0.8286 - val_recall_1: 0.8286 - val_precision_1: 0.8286\n",
      "Epoch 129/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0877 - accuracy: 0.8858 - recall_1: 0.8858 - precision_1: 0.8858 - val_loss: 0.4168 - val_accuracy: 0.8244 - val_recall_1: 0.8244 - val_precision_1: 0.8244\n",
      "Epoch 130/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0860 - accuracy: 0.8856 - recall_1: 0.8856 - precision_1: 0.8856 - val_loss: 0.4177 - val_accuracy: 0.8330 - val_recall_1: 0.8330 - val_precision_1: 0.8330\n",
      "Epoch 131/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0868 - accuracy: 0.8850 - recall_1: 0.8850 - precision_1: 0.8850 - val_loss: 0.4547 - val_accuracy: 0.8230 - val_recall_1: 0.8230 - val_precision_1: 0.8230\n",
      "Epoch 132/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0858 - accuracy: 0.8872 - recall_1: 0.8872 - precision_1: 0.8872 - val_loss: 0.4440 - val_accuracy: 0.8206 - val_recall_1: 0.8206 - val_precision_1: 0.8206\n",
      "Epoch 133/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0859 - accuracy: 0.8857 - recall_1: 0.8857 - precision_1: 0.8857 - val_loss: 0.4318 - val_accuracy: 0.8360 - val_recall_1: 0.8360 - val_precision_1: 0.8360\n",
      "Epoch 134/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0866 - accuracy: 0.8868 - recall_1: 0.8868 - precision_1: 0.8868 - val_loss: 0.4211 - val_accuracy: 0.8296 - val_recall_1: 0.8296 - val_precision_1: 0.8296\n",
      "Epoch 135/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0842 - accuracy: 0.8885 - recall_1: 0.8885 - precision_1: 0.8885 - val_loss: 0.4402 - val_accuracy: 0.8313 - val_recall_1: 0.8313 - val_precision_1: 0.8313\n",
      "Epoch 136/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0847 - accuracy: 0.8882 - recall_1: 0.8882 - precision_1: 0.8882 - val_loss: 0.4174 - val_accuracy: 0.8231 - val_recall_1: 0.8231 - val_precision_1: 0.8231\n",
      "Epoch 137/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0856 - accuracy: 0.8855 - recall_1: 0.8855 - precision_1: 0.8855 - val_loss: 0.4330 - val_accuracy: 0.8309 - val_recall_1: 0.8309 - val_precision_1: 0.8309\n",
      "Epoch 138/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0847 - accuracy: 0.8890 - recall_1: 0.8890 - precision_1: 0.8890 - val_loss: 0.4395 - val_accuracy: 0.8381 - val_recall_1: 0.8381 - val_precision_1: 0.8381\n",
      "Epoch 139/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0860 - accuracy: 0.8879 - recall_1: 0.8879 - precision_1: 0.8879 - val_loss: 0.4311 - val_accuracy: 0.8286 - val_recall_1: 0.8286 - val_precision_1: 0.8286\n",
      "Epoch 140/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0860 - accuracy: 0.8860 - recall_1: 0.8860 - precision_1: 0.8860 - val_loss: 0.4284 - val_accuracy: 0.8399 - val_recall_1: 0.8399 - val_precision_1: 0.8399\n",
      "Epoch 141/1000\n",
      "420/420 [==============================] - 17s 42ms/step - loss: 0.0847 - accuracy: 0.8877 - recall_1: 0.8877 - precision_1: 0.8877 - val_loss: 0.4343 - val_accuracy: 0.8113 - val_recall_1: 0.8113 - val_precision_1: 0.8113\n",
      "Epoch 142/1000\n",
      "420/420 [==============================] - 28s 66ms/step - loss: 0.0846 - accuracy: 0.8897 - recall_1: 0.8897 - precision_1: 0.8897 - val_loss: 0.4263 - val_accuracy: 0.8326 - val_recall_1: 0.8326 - val_precision_1: 0.8326\n",
      "Epoch 143/1000\n",
      "420/420 [==============================] - 37s 89ms/step - loss: 0.0856 - accuracy: 0.8865 - recall_1: 0.8865 - precision_1: 0.8865 - val_loss: 0.4173 - val_accuracy: 0.8466 - val_recall_1: 0.8466 - val_precision_1: 0.8466\n",
      "Epoch 144/1000\n",
      "420/420 [==============================] - 38s 90ms/step - loss: 0.0842 - accuracy: 0.8892 - recall_1: 0.8892 - precision_1: 0.8892 - val_loss: 0.4527 - val_accuracy: 0.8304 - val_recall_1: 0.8304 - val_precision_1: 0.8304\n",
      "Epoch 145/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0837 - accuracy: 0.8882 - recall_1: 0.8882 - precision_1: 0.8882 - val_loss: 0.4458 - val_accuracy: 0.8207 - val_recall_1: 0.8207 - val_precision_1: 0.8207\n",
      "Epoch 146/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0858 - accuracy: 0.8877 - recall_1: 0.8877 - precision_1: 0.8877 - val_loss: 0.4150 - val_accuracy: 0.8286 - val_recall_1: 0.8286 - val_precision_1: 0.8286\n",
      "Epoch 147/1000\n",
      "420/420 [==============================] - 38s 90ms/step - loss: 0.0854 - accuracy: 0.8876 - recall_1: 0.8876 - precision_1: 0.8876 - val_loss: 0.4406 - val_accuracy: 0.8290 - val_recall_1: 0.8290 - val_precision_1: 0.8290\n",
      "Epoch 148/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0849 - accuracy: 0.8879 - recall_1: 0.8879 - precision_1: 0.8879 - val_loss: 0.4292 - val_accuracy: 0.8239 - val_recall_1: 0.8239 - val_precision_1: 0.8239\n",
      "Epoch 149/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0837 - accuracy: 0.8894 - recall_1: 0.8894 - precision_1: 0.8894 - val_loss: 0.4145 - val_accuracy: 0.8384 - val_recall_1: 0.8384 - val_precision_1: 0.8384\n",
      "Epoch 150/1000\n",
      "420/420 [==============================] - 39s 93ms/step - loss: 0.0841 - accuracy: 0.8898 - recall_1: 0.8898 - precision_1: 0.8898 - val_loss: 0.4448 - val_accuracy: 0.8361 - val_recall_1: 0.8361 - val_precision_1: 0.8361\n",
      "Epoch 151/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0841 - accuracy: 0.8891 - recall_1: 0.8891 - precision_1: 0.8891 - val_loss: 0.4275 - val_accuracy: 0.8374 - val_recall_1: 0.8374 - val_precision_1: 0.8374\n",
      "Epoch 152/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0839 - accuracy: 0.8921 - recall_1: 0.8921 - precision_1: 0.8921 - val_loss: 0.4352 - val_accuracy: 0.8196 - val_recall_1: 0.8196 - val_precision_1: 0.8196\n",
      "Epoch 153/1000\n",
      "420/420 [==============================] - 39s 93ms/step - loss: 0.0841 - accuracy: 0.8877 - recall_1: 0.8877 - precision_1: 0.8877 - val_loss: 0.4251 - val_accuracy: 0.8337 - val_recall_1: 0.8337 - val_precision_1: 0.8337\n",
      "Epoch 154/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0823 - accuracy: 0.8922 - recall_1: 0.8922 - precision_1: 0.8922 - val_loss: 0.4476 - val_accuracy: 0.8363 - val_recall_1: 0.8363 - val_precision_1: 0.8363\n",
      "Epoch 155/1000\n",
      "420/420 [==============================] - 39s 94ms/step - loss: 0.0834 - accuracy: 0.8888 - recall_1: 0.8888 - precision_1: 0.8888 - val_loss: 0.4266 - val_accuracy: 0.8554 - val_recall_1: 0.8554 - val_precision_1: 0.8554\n",
      "Epoch 156/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0833 - accuracy: 0.8897 - recall_1: 0.8897 - precision_1: 0.8897 - val_loss: 0.4391 - val_accuracy: 0.8294 - val_recall_1: 0.8294 - val_precision_1: 0.8294\n",
      "Epoch 157/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0835 - accuracy: 0.8907 - recall_1: 0.8907 - precision_1: 0.8907 - val_loss: 0.4393 - val_accuracy: 0.8386 - val_recall_1: 0.8386 - val_precision_1: 0.8386\n",
      "Epoch 158/1000\n",
      "420/420 [==============================] - 38s 90ms/step - loss: 0.0829 - accuracy: 0.8906 - recall_1: 0.8906 - precision_1: 0.8906 - val_loss: 0.4663 - val_accuracy: 0.8366 - val_recall_1: 0.8366 - val_precision_1: 0.8366\n",
      "Epoch 159/1000\n",
      "420/420 [==============================] - 38s 90ms/step - loss: 0.0823 - accuracy: 0.8934 - recall_1: 0.8934 - precision_1: 0.8934 - val_loss: 0.4597 - val_accuracy: 0.8311 - val_recall_1: 0.8311 - val_precision_1: 0.8311\n",
      "Epoch 160/1000\n",
      "420/420 [==============================] - 39s 93ms/step - loss: 0.0829 - accuracy: 0.8919 - recall_1: 0.8919 - precision_1: 0.8919 - val_loss: 0.4389 - val_accuracy: 0.8330 - val_recall_1: 0.8330 - val_precision_1: 0.8330\n",
      "Epoch 161/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0820 - accuracy: 0.8923 - recall_1: 0.8923 - precision_1: 0.8923 - val_loss: 0.4551 - val_accuracy: 0.8384 - val_recall_1: 0.8384 - val_precision_1: 0.8384\n",
      "Epoch 162/1000\n",
      "420/420 [==============================] - 39s 93ms/step - loss: 0.0829 - accuracy: 0.8908 - recall_1: 0.8908 - precision_1: 0.8908 - val_loss: 0.4525 - val_accuracy: 0.8430 - val_recall_1: 0.8430 - val_precision_1: 0.8430\n",
      "Epoch 163/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0816 - accuracy: 0.8909 - recall_1: 0.8909 - precision_1: 0.8909 - val_loss: 0.4403 - val_accuracy: 0.8359 - val_recall_1: 0.8359 - val_precision_1: 0.8359\n",
      "Epoch 164/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0830 - accuracy: 0.8896 - recall_1: 0.8896 - precision_1: 0.8896 - val_loss: 0.4518 - val_accuracy: 0.8146 - val_recall_1: 0.8146 - val_precision_1: 0.8146\n",
      "Epoch 165/1000\n",
      "420/420 [==============================] - 39s 93ms/step - loss: 0.0821 - accuracy: 0.8907 - recall_1: 0.8907 - precision_1: 0.8907 - val_loss: 0.4328 - val_accuracy: 0.8553 - val_recall_1: 0.8553 - val_precision_1: 0.8553\n",
      "Epoch 166/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0837 - accuracy: 0.8911 - recall_1: 0.8911 - precision_1: 0.8911 - val_loss: 0.4305 - val_accuracy: 0.8264 - val_recall_1: 0.8264 - val_precision_1: 0.8264\n",
      "Epoch 167/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0820 - accuracy: 0.8923 - recall_1: 0.8923 - precision_1: 0.8923 - val_loss: 0.4309 - val_accuracy: 0.8331 - val_recall_1: 0.8331 - val_precision_1: 0.8331\n",
      "Epoch 168/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0813 - accuracy: 0.8929 - recall_1: 0.8929 - precision_1: 0.8929 - val_loss: 0.4315 - val_accuracy: 0.8364 - val_recall_1: 0.8364 - val_precision_1: 0.8364\n",
      "Epoch 169/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0836 - accuracy: 0.8904 - recall_1: 0.8904 - precision_1: 0.8904 - val_loss: 0.4417 - val_accuracy: 0.8334 - val_recall_1: 0.8334 - val_precision_1: 0.8334\n",
      "Epoch 170/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0825 - accuracy: 0.8919 - recall_1: 0.8919 - precision_1: 0.8919 - val_loss: 0.4272 - val_accuracy: 0.8234 - val_recall_1: 0.8234 - val_precision_1: 0.8234\n",
      "Epoch 171/1000\n",
      "420/420 [==============================] - 39s 93ms/step - loss: 0.0823 - accuracy: 0.8912 - recall_1: 0.8912 - precision_1: 0.8912 - val_loss: 0.4540 - val_accuracy: 0.8104 - val_recall_1: 0.8104 - val_precision_1: 0.8104\n",
      "Epoch 172/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0828 - accuracy: 0.8908 - recall_1: 0.8908 - precision_1: 0.8908 - val_loss: 0.4315 - val_accuracy: 0.8433 - val_recall_1: 0.8433 - val_precision_1: 0.8433\n",
      "Epoch 173/1000\n",
      "420/420 [==============================] - 38s 90ms/step - loss: 0.0826 - accuracy: 0.8922 - recall_1: 0.8922 - precision_1: 0.8922 - val_loss: 0.4373 - val_accuracy: 0.8334 - val_recall_1: 0.8334 - val_precision_1: 0.8334\n",
      "Epoch 174/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0803 - accuracy: 0.8934 - recall_1: 0.8934 - precision_1: 0.8934 - val_loss: 0.4508 - val_accuracy: 0.8367 - val_recall_1: 0.8367 - val_precision_1: 0.8367\n",
      "Epoch 175/1000\n",
      "420/420 [==============================] - 38s 92ms/step - loss: 0.0820 - accuracy: 0.8924 - recall_1: 0.8924 - precision_1: 0.8924 - val_loss: 0.4476 - val_accuracy: 0.8217 - val_recall_1: 0.8217 - val_precision_1: 0.8217\n",
      "Epoch 176/1000\n",
      "420/420 [==============================] - 38s 92ms/step - loss: 0.0813 - accuracy: 0.8914 - recall_1: 0.8914 - precision_1: 0.8914 - val_loss: 0.4302 - val_accuracy: 0.8311 - val_recall_1: 0.8311 - val_precision_1: 0.8311\n",
      "Epoch 177/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0816 - accuracy: 0.8924 - recall_1: 0.8924 - precision_1: 0.8924 - val_loss: 0.4541 - val_accuracy: 0.8307 - val_recall_1: 0.8307 - val_precision_1: 0.8307\n",
      "Epoch 178/1000\n",
      "420/420 [==============================] - 38s 92ms/step - loss: 0.0826 - accuracy: 0.8910 - recall_1: 0.8910 - precision_1: 0.8910 - val_loss: 0.4488 - val_accuracy: 0.8300 - val_recall_1: 0.8300 - val_precision_1: 0.8300\n",
      "Epoch 179/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0818 - accuracy: 0.8915 - recall_1: 0.8915 - precision_1: 0.8915 - val_loss: 0.4373 - val_accuracy: 0.8230 - val_recall_1: 0.8230 - val_precision_1: 0.8230\n",
      "Epoch 180/1000\n",
      "420/420 [==============================] - 38s 92ms/step - loss: 0.0813 - accuracy: 0.8908 - recall_1: 0.8908 - precision_1: 0.8908 - val_loss: 0.4578 - val_accuracy: 0.8379 - val_recall_1: 0.8379 - val_precision_1: 0.8379\n",
      "Epoch 181/1000\n",
      "420/420 [==============================] - 38s 90ms/step - loss: 0.0814 - accuracy: 0.8915 - recall_1: 0.8915 - precision_1: 0.8915 - val_loss: 0.4531 - val_accuracy: 0.8356 - val_recall_1: 0.8356 - val_precision_1: 0.8356\n",
      "Epoch 182/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0806 - accuracy: 0.8913 - recall_1: 0.8913 - precision_1: 0.8913 - val_loss: 0.4414 - val_accuracy: 0.8293 - val_recall_1: 0.8293 - val_precision_1: 0.8293\n",
      "Epoch 183/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0811 - accuracy: 0.8915 - recall_1: 0.8915 - precision_1: 0.8915 - val_loss: 0.4660 - val_accuracy: 0.8327 - val_recall_1: 0.8327 - val_precision_1: 0.8327\n",
      "Epoch 184/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0812 - accuracy: 0.8946 - recall_1: 0.8946 - precision_1: 0.8946 - val_loss: 0.4481 - val_accuracy: 0.8351 - val_recall_1: 0.8351 - val_precision_1: 0.8351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ffe2d3ebb0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "hist3 = model.fit(x_train, y_tr, epochs=1000, validation_split=0.1, shuffle=True,class_weight=weights, batch_size=batch_size,use_multiprocessing=True,workers=8,callbacks=[callback])\n",
    "hist3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-19T09:06:30.168Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_cnn_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-19T09:06:30.342Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-19T09:06:30.539Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction_labels=[]\n",
    "for p in predictions:\n",
    "    prediction_labels.append(labels[np.argmax(p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-19T09:06:30.794Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(data_test.oh_label==prediction_labels)/len(prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-19T09:06:30.951Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(data_test.oh_label,prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T11:49:52.591895Z",
     "start_time": "2021-12-01T11:49:52.507135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9001459 , 0.10048452]], dtype=float32)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([\"i not love hate you\"])  # correct \n",
    "x = np.array([\"I stop to hate this boy\"])  # mistake \n",
    "x = np.array([\"I liked the book, especially the ending.\"])  # correct \n",
    "test_sequences = tokenizer.texts_to_sequences(x.tolist())\n",
    "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "predictions = model.predict(test_data, batch_size=1, verbose=1)\n",
    "predictions      # [pos, neg]\n",
    "# test_sequences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
