{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:37:28.002133Z",
     "start_time": "2021-12-26T14:37:26.772713Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from gensim import models\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:37:29.263508Z",
     "start_time": "2021-12-26T14:37:28.764502Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/ver1.csv', index_col=0)\n",
    "data.drop([\"index\"], inplace = True, axis=1)\n",
    "data.columns = ['Text', 'oh_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:37:29.644112Z",
     "start_time": "2021-12-26T14:37:29.561515Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1 it's represent negative and 0 for positive\n",
    "pos = []\n",
    "neg = []\n",
    "for l in data.oh_label:\n",
    "    if l == 0:\n",
    "        pos.append(1)\n",
    "        neg.append(0)\n",
    "    elif l == 1:\n",
    "        pos.append(0)\n",
    "        neg.append(1)\n",
    "data['Pos']= pos\n",
    "data['Neg']= neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:38:01.224337Z",
     "start_time": "2021-12-26T14:37:30.416163Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = ''\n",
    "    text_nopunct = re.sub('['+string.punctuation+']', '', text)\n",
    "    return text_nopunct\n",
    "\n",
    "data['Text_Clean'] = data['Text'].apply(lambda x: remove_punct(x))\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "tokens = [word_tokenize(sen) for sen in data.Text_Clean]\n",
    "def lower_token(tokens): \n",
    "    return [w.lower() for w in tokens]    \n",
    "    \n",
    "lower_tokens = [lower_token(token) for token in tokens]\n",
    "from nltk.corpus import stopwords\n",
    "stoplist = stopwords.words('english') \n",
    "def remove_stop_words(tokens):\n",
    "    return [word for word in tokens if word not in stoplist]\n",
    "filtered_words = [remove_stop_words(sen) for sen in lower_tokens] \n",
    "result = [' '.join(sen) for sen in filtered_words]\n",
    "\n",
    "data['Text_Final'] = result\n",
    "data['tokens'] = filtered_words\n",
    "data = data[['Text_Final', 'tokens', 'oh_label', 'Pos', 'Neg']]\n",
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:38:06.633874Z",
     "start_time": "2021-12-26T14:38:06.602869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_Final</th>\n",
       "      <th>tokens</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im 12 understand perfectly learn english inste...</td>\n",
       "      <td>[im, 12, understand, perfectly, learn, english...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mkr boy fourinhandyou sure know dish insult sa...</td>\n",
       "      <td>[mkr, boy, fourinhandyou, sure, know, dish, in...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fuck site full stuck cunts unknown reason thin...</td>\n",
       "      <td>[fuck, site, full, stuck, cunts, unknown, reas...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dont disagree point except im exactly trying a...</td>\n",
       "      <td>[dont, disagree, point, except, im, exactly, t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>look like give fuck u sad fucks nothing better...</td>\n",
       "      <td>[look, like, give, fuck, u, sad, fucks, nothin...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text_Final  \\\n",
       "0  im 12 understand perfectly learn english inste...   \n",
       "1  mkr boy fourinhandyou sure know dish insult sa...   \n",
       "2  fuck site full stuck cunts unknown reason thin...   \n",
       "3  dont disagree point except im exactly trying a...   \n",
       "4  look like give fuck u sad fucks nothing better...   \n",
       "\n",
       "                                              tokens  oh_label  Pos  Neg  \n",
       "0  [im, 12, understand, perfectly, learn, english...       1.0    0    1  \n",
       "1  [mkr, boy, fourinhandyou, sure, know, dish, in...       0.0    1    0  \n",
       "2  [fuck, site, full, stuck, cunts, unknown, reas...       1.0    0    1  \n",
       "3  [dont, disagree, point, except, im, exactly, t...       0.0    1    0  \n",
       "4  [look, like, give, fuck, u, sad, fucks, nothin...       1.0    0    1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:57:51.882658Z",
     "start_time": "2021-12-26T14:57:51.831581Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.30, random_state=42)\n",
    "data_test, data_test_final = train_test_split(data_test, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:58:03.054995Z",
     "start_time": "2021-12-26T14:58:03.025988Z"
    }
   },
   "outputs": [],
   "source": [
    "x_neg_weight = data_train[data_train[\"oh_label\"]==1].shape\n",
    "x_pos_weight = data_train[data_train[\"oh_label\"]==0].shape\n",
    "x_neg_weight[0]/x_pos_weight[0]\n",
    "weights = {0: (x_neg_weight[0]/(x_pos_weight[0]+x_neg_weight[0])),1: (x_pos_weight[0]/(x_pos_weight[0]+x_neg_weight[0]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:39:10.389971Z",
     "start_time": "2021-12-26T14:39:09.779620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2290656 words total, with a vocabulary size of 131067\n",
      "Max sentence length is 2481\n",
      "483005 words total, with a vocabulary size of 50477\n",
      "Max sentence length is 2494\n"
     ]
    }
   ],
   "source": [
    "def get_vocab(df,key):\n",
    "    all_training_words = [word for tokens in df[key] for word in tokens]\n",
    "    training_sentence_lengths = [len(tokens) for tokens in df[key]]\n",
    "    vocab = sorted(list(set(all_training_words)))\n",
    "    print(\"%s words total, with a vocabulary size of %s\" % (len(all_training_words), len(vocab)))\n",
    "    print(\"Max sentence length is %s\" % max(training_sentence_lengths))\n",
    "    return vocab\n",
    "TRAINING_VOCAB = get_vocab(data_train,\"tokens\")\n",
    "TEST_VOCAB = get_vocab(data_test,\"tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Google News Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:38:22.946737Z",
     "start_time": "2021-12-26T14:37:39.672Z"
    }
   },
   "outputs": [],
   "source": [
    "word2vec_path = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T10:44:31.937655Z",
     "start_time": "2021-12-19T10:44:31.923669Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 50\n",
    "EMBEDDING_DIM = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:44:05.616431Z",
     "start_time": "2021-12-26T14:44:05.612420Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def to_one_hot(df,vocb_len,TEXT_COLUMN_NAME):\n",
    "    tokenizer = Tokenizer(num_words=vocb_len, lower=True, char_level=False)\n",
    "    tokenizer.fit_on_texts(df[TEXT_COLUMN_NAME].tolist())\n",
    "    training_sequences = tokenizer.texts_to_sequences(df[TEXT_COLUMN_NAME].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:58:25.332525Z",
     "start_time": "2021-12-26T14:58:25.292502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_Final</th>\n",
       "      <th>tokens</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76513</th>\n",
       "      <td>please stop removing content wikipedia conside...</td>\n",
       "      <td>[please, stop, removing, content, wikipedia, c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60406</th>\n",
       "      <td>adult discussion please found today comments p...</td>\n",
       "      <td>[adult, discussion, please, found, today, comm...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27322</th>\n",
       "      <td>wikinews demo running hi im writing let know w...</td>\n",
       "      <td>[wikinews, demo, running, hi, im, writing, let...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53699</th>\n",
       "      <td>message sponsors</td>\n",
       "      <td>[message, sponsors]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65412</th>\n",
       "      <td>cant figure conversation even first place with...</td>\n",
       "      <td>[cant, figure, conversation, even, first, plac...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>howdy hows weather los angeles</td>\n",
       "      <td>[howdy, hows, weather, los, angeles]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>almost links provided good sources tretiakov h...</td>\n",
       "      <td>[almost, links, provided, good, sources, treti...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>rt emilyylam 14 teams screen means one good th...</td>\n",
       "      <td>[rt, emilyylam, 14, teams, screen, means, one,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>german reich 1935–1945svg</td>\n",
       "      <td>[german, reich, 1935–1945svg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>ask wikipedia correct ask followed outline wik...</td>\n",
       "      <td>[ask, wikipedia, correct, ask, followed, outli...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Text_Final  \\\n",
       "76513  please stop removing content wikipedia conside...   \n",
       "60406  adult discussion please found today comments p...   \n",
       "27322  wikinews demo running hi im writing let know w...   \n",
       "53699                                   message sponsors   \n",
       "65412  cant figure conversation even first place with...   \n",
       "...                                                  ...   \n",
       "6265                      howdy hows weather los angeles   \n",
       "54886  almost links provided good sources tretiakov h...   \n",
       "76820  rt emilyylam 14 teams screen means one good th...   \n",
       "860                            german reich 1935–1945svg   \n",
       "15795  ask wikipedia correct ask followed outline wik...   \n",
       "\n",
       "                                                  tokens  oh_label  Pos  Neg  \n",
       "76513  [please, stop, removing, content, wikipedia, c...       0.0    1    0  \n",
       "60406  [adult, discussion, please, found, today, comm...       0.0    1    0  \n",
       "27322  [wikinews, demo, running, hi, im, writing, let...       0.0    1    0  \n",
       "53699                                [message, sponsors]       0.0    1    0  \n",
       "65412  [cant, figure, conversation, even, first, plac...       0.0    1    0  \n",
       "...                                                  ...       ...  ...  ...  \n",
       "6265                [howdy, hows, weather, los, angeles]       0.0    1    0  \n",
       "54886  [almost, links, provided, good, sources, treti...       0.0    1    0  \n",
       "76820  [rt, emilyylam, 14, teams, screen, means, one,...       0.0    1    0  \n",
       "860                        [german, reich, 1935–1945svg]       0.0    1    0  \n",
       "15795  [ask, wikipedia, correct, ask, followed, outli...       0.0    1    0  \n",
       "\n",
       "[70000 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:58:41.123712Z",
     "start_time": "2021-12-26T14:58:36.579126Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a custom standardization function to strip HTML break tags '<br />'.\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html,'[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "\n",
    "# Vocabulary size and number of words in a sequence.\n",
    "vocab_size = 10000\n",
    "sequence_length = 100\n",
    "\n",
    "# Use the text vectorization layer to normalize, split, and map strings to\n",
    "# integers. Note that the layer uses the custom standardization defined above.\n",
    "# Set maximum_sequence length as all samples are not of the same length.\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)\n",
    "\n",
    "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
    "vectorize_layer.adapt(data_train[\"Text_Final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T15:00:03.249240Z",
     "start_time": "2021-12-26T15:00:01.153686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im 12 understand perfectly learn english instead making us dumb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py:2215: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
       "array([  10,   50,  352,  128,    4,  362,   84,   27, 1517,   10,   25,\n",
       "        729,   80,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0], dtype=int64)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_train[\"Text_Final\"][0])\n",
    "vectorize_layer.apply(data_train[\"Text_Final\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda(lambda x: tf.one_hot(x[:,0], len(set(X))))(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T10:48:49.317622Z",
     "start_time": "2021-12-19T10:48:45.608081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 130531 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=len(TRAINING_VOCAB), lower=True, char_level=False)\n",
    "tokenizer.fit_on_texts(data_train[\"Text_Final\"].tolist())\n",
    "training_sequences = tokenizer.texts_to_sequences(data_train[\"Text_Final\"].tolist())\n",
    "\n",
    "train_word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(train_word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T10:53:07.494043Z",
     "start_time": "2021-12-19T10:53:07.179057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 50)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cnn_data = pad_sequences(training_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "train_cnn_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T10:57:22.842553Z",
     "start_time": "2021-12-19T10:57:22.271126Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-9373b9a956c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_embedding_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_word_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_word_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain_embedding_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword2vec\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEMBEDDING_DIM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_embedding_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word2vec' is not defined"
     ]
    }
   ],
   "source": [
    "train_embedding_weights = np.zeros((len(train_word_index)+1, EMBEDDING_DIM))\n",
    "for word,index in train_word_index.items():\n",
    "    train_embedding_weights[index,:] = word2vec[word] if word in word2vec else np.random.rand(EMBEDDING_DIM)\n",
    "print(train_embedding_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T11:01:37.176210Z",
     "start_time": "2021-12-19T11:01:36.767225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     3,   255,    50,  1219,\n",
       "          41,     1,   348,    52,   697,  8499,    19,   561,   764,\n",
       "         808,     5,   157,   734,  1050,  2729,   601,  1042,  2401,\n",
       "         692,  3201,     5, 22842,  4007])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(data_test[\"Text_Final\"].tolist())\n",
    "test_cnn_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_cnn_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T11:05:51.334663Z",
     "start_time": "2021-12-19T11:05:51.319672Z"
    }
   },
   "outputs": [],
   "source": [
    "label_names = ['Pos', 'Neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T11:10:07.749881Z",
     "start_time": "2021-12-19T11:10:07.736412Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = data_train[label_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T11:14:28.398014Z",
     "start_time": "2021-12-19T11:14:28.386181Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = train_cnn_data\n",
    "y_tr = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T11:27:32.810044Z",
     "start_time": "2021-12-19T11:27:32.801039Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D,MaxPool1D,Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T11:36:04.262325Z",
     "start_time": "2021-12-19T11:36:04.248293Z"
    }
   },
   "outputs": [],
   "source": [
    "def cnn(embeddings, max_sequence_length, num_words, embedding_dim, labels_index):\n",
    "    \n",
    "    embedding_layer = Embedding(num_words,\n",
    "                            embedding_dim,\n",
    "                            weights=[embeddings],\n",
    "                            input_length=max_sequence_length,\n",
    "                            trainable=False)\n",
    "    \n",
    "    sequence_input = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    conv1d = Conv1D(20,7,strides=1, use_bias=True,padding=\"valid\")(embedded_sequences)\n",
    "    max_pool = MaxPool1D(pool_size=3)(conv1d)\n",
    "    flattened = Flatten()(max_pool)\n",
    "    x1 = Dense(128, activation='relu')(flattened)\n",
    "    x1 = Dropout(0.2)(x1)\n",
    "    x2 = Dense(64, activation='relu')(x1)\n",
    "    preds = Dense(labels_index, activation='sigmoid')(x2)\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),metrics=[\"accuracy\",tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-19T11:29:50.718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 50, 300)           39159600  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 44, 20)            42020     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 14, 20)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 280)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               35968     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 39,245,974\n",
      "Trainable params: 86,374\n",
      "Non-trainable params: 39,159,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = cnn(train_embedding_weights, MAX_SEQUENCE_LENGTH, len(train_word_index)+1, EMBEDDING_DIM, \n",
    "                len(list(label_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:06:29.044239Z",
     "start_time": "2021-12-19T09:06:29.036259Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-19T09:06:29.727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 0.1834 - accuracy: 0.7719 - recall_1: 0.7708 - precision_1: 0.7715 - val_loss: 0.4231 - val_accuracy: 0.8031 - val_recall_1: 0.8044 - val_precision_1: 0.8018\n",
      "Epoch 2/10\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.1553 - accuracy: 0.8158 - recall_1: 0.8166 - precision_1: 0.8148 - val_loss: 0.4597 - val_accuracy: 0.7669 - val_recall_1: 0.7660 - val_precision_1: 0.7668\n",
      "Epoch 3/10\n",
      "420/420 [==============================] - 15s 35ms/step - loss: 0.1432 - accuracy: 0.8257 - recall_1: 0.8265 - precision_1: 0.8251 - val_loss: 0.4302 - val_accuracy: 0.7807 - val_recall_1: 0.7813 - val_precision_1: 0.7806\n",
      "Epoch 4/10\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.1302 - accuracy: 0.8354 - recall_1: 0.8350 - precision_1: 0.8353 - val_loss: 0.3914 - val_accuracy: 0.8066 - val_recall_1: 0.8060 - val_precision_1: 0.8065\n",
      "Epoch 5/10\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.1188 - accuracy: 0.8494 - recall_1: 0.8493 - precision_1: 0.8493 - val_loss: 0.4036 - val_accuracy: 0.8277 - val_recall_1: 0.8267 - val_precision_1: 0.8266\n",
      "Epoch 6/10\n",
      "420/420 [==============================] - 15s 36ms/step - loss: 0.1079 - accuracy: 0.8623 - recall_1: 0.8619 - precision_1: 0.8624 - val_loss: 0.4173 - val_accuracy: 0.8081 - val_recall_1: 0.8086 - val_precision_1: 0.8082\n",
      "Epoch 7/10\n",
      "420/420 [==============================] - 15s 35ms/step - loss: 0.0987 - accuracy: 0.8755 - recall_1: 0.8751 - precision_1: 0.8754 - val_loss: 0.4832 - val_accuracy: 0.7777 - val_recall_1: 0.7781 - val_precision_1: 0.7786\n",
      "Epoch 8/10\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.0921 - accuracy: 0.8817 - recall_1: 0.8813 - precision_1: 0.8820 - val_loss: 0.4584 - val_accuracy: 0.8259 - val_recall_1: 0.8259 - val_precision_1: 0.8257\n",
      "Epoch 9/10\n",
      "420/420 [==============================] - 15s 36ms/step - loss: 0.0877 - accuracy: 0.8908 - recall_1: 0.8906 - precision_1: 0.8910 - val_loss: 0.5145 - val_accuracy: 0.7794 - val_recall_1: 0.7796 - val_precision_1: 0.7796\n",
      "Epoch 10/10\n",
      "420/420 [==============================] - 15s 35ms/step - loss: 0.0832 - accuracy: 0.8960 - recall_1: 0.8960 - precision_1: 0.8962 - val_loss: 0.5268 - val_accuracy: 0.8193 - val_recall_1: 0.8191 - val_precision_1: 0.8196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e3288143d0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "hist = model.fit(x_train, y_tr, epochs=10, validation_split=0.1, shuffle=True,class_weight=weights, batch_size=batch_size,use_multiprocessing=True,workers=8)\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "predictions = model.predict(test_cnn_data)\n",
    "prediction_labels=[]\n",
    "labels = [0, 1]\n",
    "for p in predictions:\n",
    "    prediction_labels.append(labels[np.argmax(p)])\n",
    "print(classification_report(data_test.oh_label,prediction_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "420/420 [==============================] - 23s 46ms/step - loss: 0.1838 - accuracy: 0.7656 - recall: 0.7663 - precision: 0.7636 - val_loss: 0.3878 - val_accuracy: 0.8243 - val_recall: 0.8230 - val_precision: 0.8246\n",
      "Epoch 2/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.1564 - accuracy: 0.8110 - recall: 0.8100 - precision: 0.8108 - val_loss: 0.4648 - val_accuracy: 0.7816 - val_recall: 0.7793 - val_precision: 0.7814\n",
      "Epoch 3/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.1437 - accuracy: 0.8238 - recall: 0.8230 - precision: 0.8237 - val_loss: 0.4163 - val_accuracy: 0.8023 - val_recall: 0.8040 - val_precision: 0.8016\n",
      "Epoch 4/100\n",
      "420/420 [==============================] - 19s 44ms/step - loss: 0.1314 - accuracy: 0.8354 - recall: 0.8355 - precision: 0.8357 - val_loss: 0.3865 - val_accuracy: 0.8127 - val_recall: 0.8126 - val_precision: 0.8132\n",
      "Epoch 5/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.1192 - accuracy: 0.8474 - recall: 0.8473 - precision: 0.8477 - val_loss: 0.3845 - val_accuracy: 0.8234 - val_recall: 0.8233 - val_precision: 0.8243\n",
      "Epoch 6/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.1089 - accuracy: 0.8646 - recall: 0.8645 - precision: 0.8648 - val_loss: 0.3950 - val_accuracy: 0.8293 - val_recall: 0.8294 - val_precision: 0.8299\n",
      "Epoch 7/100\n",
      "420/420 [==============================] - 19s 45ms/step - loss: 0.1020 - accuracy: 0.8714 - recall: 0.8713 - precision: 0.8712 - val_loss: 0.4092 - val_accuracy: 0.8244 - val_recall: 0.8244 - val_precision: 0.8243\n",
      "Epoch 8/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0932 - accuracy: 0.8794 - recall: 0.8798 - precision: 0.8793 - val_loss: 0.4274 - val_accuracy: 0.8200 - val_recall: 0.8203 - val_precision: 0.8202\n",
      "Epoch 9/100\n",
      "420/420 [==============================] - 17s 42ms/step - loss: 0.0871 - accuracy: 0.8908 - recall: 0.8910 - precision: 0.8910 - val_loss: 0.4561 - val_accuracy: 0.8204 - val_recall: 0.8200 - val_precision: 0.8208\n",
      "Epoch 10/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0829 - accuracy: 0.8930 - recall: 0.8929 - precision: 0.8931 - val_loss: 0.4898 - val_accuracy: 0.8304 - val_recall: 0.8291 - val_precision: 0.8299\n",
      "Epoch 11/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0767 - accuracy: 0.9017 - recall: 0.9014 - precision: 0.9018 - val_loss: 0.5437 - val_accuracy: 0.8123 - val_recall: 0.8119 - val_precision: 0.8128\n",
      "Epoch 12/100\n",
      "420/420 [==============================] - 19s 44ms/step - loss: 0.0729 - accuracy: 0.9054 - recall: 0.9053 - precision: 0.9056 - val_loss: 0.5463 - val_accuracy: 0.8149 - val_recall: 0.8153 - val_precision: 0.8149\n",
      "Epoch 13/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0701 - accuracy: 0.9076 - recall: 0.9072 - precision: 0.9077 - val_loss: 0.5873 - val_accuracy: 0.8416 - val_recall: 0.8420 - val_precision: 0.8422\n",
      "Epoch 14/100\n",
      "420/420 [==============================] - 19s 45ms/step - loss: 0.0671 - accuracy: 0.9163 - recall: 0.9162 - precision: 0.9162 - val_loss: 0.5651 - val_accuracy: 0.8016 - val_recall: 0.8019 - val_precision: 0.8015\n",
      "Epoch 15/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0673 - accuracy: 0.9132 - recall: 0.9129 - precision: 0.9135 - val_loss: 0.5717 - val_accuracy: 0.8254 - val_recall: 0.8254 - val_precision: 0.8255\n",
      "Epoch 16/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0621 - accuracy: 0.9235 - recall: 0.9238 - precision: 0.9234 - val_loss: 0.5985 - val_accuracy: 0.8074 - val_recall: 0.8076 - val_precision: 0.8080\n",
      "Epoch 17/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0598 - accuracy: 0.9256 - recall: 0.9254 - precision: 0.9257 - val_loss: 0.6294 - val_accuracy: 0.8187 - val_recall: 0.8191 - val_precision: 0.8187\n",
      "Epoch 18/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0576 - accuracy: 0.9267 - recall: 0.9269 - precision: 0.9264 - val_loss: 0.7252 - val_accuracy: 0.8357 - val_recall: 0.8354 - val_precision: 0.8358\n",
      "Epoch 19/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0563 - accuracy: 0.9271 - recall: 0.9273 - precision: 0.9267 - val_loss: 0.6949 - val_accuracy: 0.8299 - val_recall: 0.8297 - val_precision: 0.8298\n",
      "Epoch 20/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0565 - accuracy: 0.9287 - recall: 0.9289 - precision: 0.9286 - val_loss: 0.8003 - val_accuracy: 0.8539 - val_recall: 0.8533 - val_precision: 0.8534\n",
      "Epoch 21/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0535 - accuracy: 0.9301 - recall: 0.9304 - precision: 0.9300 - val_loss: 0.7299 - val_accuracy: 0.8363 - val_recall: 0.8367 - val_precision: 0.8364\n",
      "Epoch 22/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0529 - accuracy: 0.9305 - recall: 0.9308 - precision: 0.9304 - val_loss: 0.7343 - val_accuracy: 0.8480 - val_recall: 0.8476 - val_precision: 0.8478\n",
      "Epoch 23/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0544 - accuracy: 0.9338 - recall: 0.9342 - precision: 0.9335 - val_loss: 0.6098 - val_accuracy: 0.8326 - val_recall: 0.8329 - val_precision: 0.8325\n",
      "Epoch 24/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0507 - accuracy: 0.9360 - recall: 0.9361 - precision: 0.9361 - val_loss: 0.7536 - val_accuracy: 0.8320 - val_recall: 0.8316 - val_precision: 0.8324\n",
      "Epoch 25/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0481 - accuracy: 0.9400 - recall: 0.9403 - precision: 0.9395 - val_loss: 0.7761 - val_accuracy: 0.8493 - val_recall: 0.8491 - val_precision: 0.8491\n",
      "Epoch 26/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0461 - accuracy: 0.9398 - recall: 0.9399 - precision: 0.9397 - val_loss: 0.8557 - val_accuracy: 0.8451 - val_recall: 0.8459 - val_precision: 0.8454\n",
      "Epoch 27/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0477 - accuracy: 0.9386 - recall: 0.9386 - precision: 0.9384 - val_loss: 0.7699 - val_accuracy: 0.8273 - val_recall: 0.8280 - val_precision: 0.8272\n",
      "Epoch 28/100\n",
      "420/420 [==============================] - 17s 42ms/step - loss: 0.0453 - accuracy: 0.9402 - recall: 0.9402 - precision: 0.9400 - val_loss: 0.8271 - val_accuracy: 0.8443 - val_recall: 0.8444 - val_precision: 0.8437\n",
      "Epoch 29/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0446 - accuracy: 0.9410 - recall: 0.9408 - precision: 0.9413 - val_loss: 0.9512 - val_accuracy: 0.8269 - val_recall: 0.8271 - val_precision: 0.8266\n",
      "Epoch 30/100\n",
      "420/420 [==============================] - 17s 42ms/step - loss: 0.0458 - accuracy: 0.9421 - recall: 0.9420 - precision: 0.9421 - val_loss: 0.8618 - val_accuracy: 0.8250 - val_recall: 0.8256 - val_precision: 0.8249\n",
      "Epoch 31/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0431 - accuracy: 0.9440 - recall: 0.9432 - precision: 0.9444 - val_loss: 0.8952 - val_accuracy: 0.8441 - val_recall: 0.8441 - val_precision: 0.8443\n",
      "Epoch 32/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0426 - accuracy: 0.9470 - recall: 0.9470 - precision: 0.9471 - val_loss: 0.8814 - val_accuracy: 0.8211 - val_recall: 0.8206 - val_precision: 0.8208\n",
      "Epoch 33/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0442 - accuracy: 0.9421 - recall: 0.9417 - precision: 0.9424 - val_loss: 0.9313 - val_accuracy: 0.8480 - val_recall: 0.8477 - val_precision: 0.8474\n",
      "Epoch 34/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0414 - accuracy: 0.9451 - recall: 0.9451 - precision: 0.9452 - val_loss: 0.8764 - val_accuracy: 0.8437 - val_recall: 0.8436 - val_precision: 0.8435\n",
      "Epoch 35/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0411 - accuracy: 0.9471 - recall: 0.9472 - precision: 0.9471 - val_loss: 0.9561 - val_accuracy: 0.8369 - val_recall: 0.8369 - val_precision: 0.8367\n",
      "Epoch 36/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0423 - accuracy: 0.9470 - recall: 0.9467 - precision: 0.9473 - val_loss: 0.8807 - val_accuracy: 0.8186 - val_recall: 0.8190 - val_precision: 0.8184\n",
      "Epoch 37/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0414 - accuracy: 0.9465 - recall: 0.9466 - precision: 0.9465 - val_loss: 0.9666 - val_accuracy: 0.8277 - val_recall: 0.8270 - val_precision: 0.8278\n",
      "Epoch 38/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0391 - accuracy: 0.9491 - recall: 0.9491 - precision: 0.9491 - val_loss: 0.8689 - val_accuracy: 0.8374 - val_recall: 0.8376 - val_precision: 0.8379\n",
      "Epoch 39/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0379 - accuracy: 0.9525 - recall: 0.9521 - precision: 0.9526 - val_loss: 0.8592 - val_accuracy: 0.8201 - val_recall: 0.8206 - val_precision: 0.8196\n",
      "Epoch 40/100\n",
      "420/420 [==============================] - 18s 44ms/step - loss: 0.0386 - accuracy: 0.9498 - recall: 0.9498 - precision: 0.9500 - val_loss: 0.9678 - val_accuracy: 0.8401 - val_recall: 0.8404 - val_precision: 0.8399\n",
      "Epoch 41/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0368 - accuracy: 0.9517 - recall: 0.9516 - precision: 0.9521 - val_loss: 1.0039 - val_accuracy: 0.8351 - val_recall: 0.8354 - val_precision: 0.8353\n",
      "Epoch 42/100\n",
      "420/420 [==============================] - 19s 44ms/step - loss: 0.0378 - accuracy: 0.9501 - recall: 0.9501 - precision: 0.9502 - val_loss: 1.0769 - val_accuracy: 0.8307 - val_recall: 0.8307 - val_precision: 0.8308\n",
      "Epoch 43/100\n",
      "420/420 [==============================] - 18s 44ms/step - loss: 0.0365 - accuracy: 0.9517 - recall: 0.9515 - precision: 0.9520 - val_loss: 1.1205 - val_accuracy: 0.8477 - val_recall: 0.8481 - val_precision: 0.8474\n",
      "Epoch 44/100\n",
      "420/420 [==============================] - 18s 44ms/step - loss: 0.0370 - accuracy: 0.9490 - recall: 0.9484 - precision: 0.9493 - val_loss: 1.0780 - val_accuracy: 0.8471 - val_recall: 0.8469 - val_precision: 0.8465\n",
      "Epoch 45/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0370 - accuracy: 0.9544 - recall: 0.9541 - precision: 0.9544 - val_loss: 0.9563 - val_accuracy: 0.8440 - val_recall: 0.8443 - val_precision: 0.8436\n",
      "Epoch 46/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0351 - accuracy: 0.9547 - recall: 0.9546 - precision: 0.9548 - val_loss: 0.9358 - val_accuracy: 0.8394 - val_recall: 0.8399 - val_precision: 0.8393\n",
      "Epoch 47/100\n",
      "420/420 [==============================] - 18s 44ms/step - loss: 0.0351 - accuracy: 0.9534 - recall: 0.9532 - precision: 0.9539 - val_loss: 1.0575 - val_accuracy: 0.8464 - val_recall: 0.8461 - val_precision: 0.8458\n",
      "Epoch 48/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0366 - accuracy: 0.9495 - recall: 0.9490 - precision: 0.9499 - val_loss: 1.0215 - val_accuracy: 0.8291 - val_recall: 0.8293 - val_precision: 0.8290\n",
      "Epoch 49/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0350 - accuracy: 0.9556 - recall: 0.9550 - precision: 0.9559 - val_loss: 1.0106 - val_accuracy: 0.8239 - val_recall: 0.8236 - val_precision: 0.8238\n",
      "Epoch 50/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0352 - accuracy: 0.9532 - recall: 0.9531 - precision: 0.9532 - val_loss: 0.9910 - val_accuracy: 0.8297 - val_recall: 0.8296 - val_precision: 0.8297\n",
      "Epoch 51/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0320 - accuracy: 0.9553 - recall: 0.9552 - precision: 0.9555 - val_loss: 1.1141 - val_accuracy: 0.8321 - val_recall: 0.8323 - val_precision: 0.8328\n",
      "Epoch 52/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0332 - accuracy: 0.9568 - recall: 0.9565 - precision: 0.9570 - val_loss: 1.1526 - val_accuracy: 0.8351 - val_recall: 0.8346 - val_precision: 0.8348\n",
      "Epoch 53/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0335 - accuracy: 0.9544 - recall: 0.9545 - precision: 0.9544 - val_loss: 1.1092 - val_accuracy: 0.8479 - val_recall: 0.8479 - val_precision: 0.8479\n",
      "Epoch 54/100\n",
      "420/420 [==============================] - 18s 44ms/step - loss: 0.0322 - accuracy: 0.9554 - recall: 0.9550 - precision: 0.9556 - val_loss: 1.1110 - val_accuracy: 0.8459 - val_recall: 0.8460 - val_precision: 0.8460\n",
      "Epoch 55/100\n",
      "420/420 [==============================] - 18s 44ms/step - loss: 0.0332 - accuracy: 0.9554 - recall: 0.9553 - precision: 0.9556 - val_loss: 1.2246 - val_accuracy: 0.8370 - val_recall: 0.8370 - val_precision: 0.8371\n",
      "Epoch 56/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0314 - accuracy: 0.9598 - recall: 0.9598 - precision: 0.9600 - val_loss: 1.1489 - val_accuracy: 0.8459 - val_recall: 0.8457 - val_precision: 0.8458\n",
      "Epoch 57/100\n",
      "420/420 [==============================] - 17s 42ms/step - loss: 0.0314 - accuracy: 0.9592 - recall: 0.9592 - precision: 0.9593 - val_loss: 1.1559 - val_accuracy: 0.8351 - val_recall: 0.8353 - val_precision: 0.8352\n",
      "Epoch 58/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0327 - accuracy: 0.9561 - recall: 0.9559 - precision: 0.9561 - val_loss: 1.1910 - val_accuracy: 0.8379 - val_recall: 0.8373 - val_precision: 0.8379\n",
      "Epoch 59/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0305 - accuracy: 0.9587 - recall: 0.9587 - precision: 0.9587 - val_loss: 1.2824 - val_accuracy: 0.8447 - val_recall: 0.8443 - val_precision: 0.8446\n",
      "Epoch 60/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0314 - accuracy: 0.9616 - recall: 0.9615 - precision: 0.9616 - val_loss: 1.1578 - val_accuracy: 0.8463 - val_recall: 0.8461 - val_precision: 0.8458\n",
      "Epoch 61/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0315 - accuracy: 0.9599 - recall: 0.9597 - precision: 0.9598 - val_loss: 1.1449 - val_accuracy: 0.8327 - val_recall: 0.8333 - val_precision: 0.8328\n",
      "Epoch 62/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0315 - accuracy: 0.9568 - recall: 0.9565 - precision: 0.9569 - val_loss: 1.2562 - val_accuracy: 0.8291 - val_recall: 0.8293 - val_precision: 0.8293\n",
      "Epoch 63/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0309 - accuracy: 0.9591 - recall: 0.9588 - precision: 0.9594 - val_loss: 1.1612 - val_accuracy: 0.8263 - val_recall: 0.8260 - val_precision: 0.8264\n",
      "Epoch 64/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0298 - accuracy: 0.9591 - recall: 0.9590 - precision: 0.9592 - val_loss: 1.1967 - val_accuracy: 0.8416 - val_recall: 0.8416 - val_precision: 0.8416\n",
      "Epoch 65/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0324 - accuracy: 0.9590 - recall: 0.9590 - precision: 0.9592 - val_loss: 1.1931 - val_accuracy: 0.8239 - val_recall: 0.8239 - val_precision: 0.8243\n",
      "Epoch 66/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0306 - accuracy: 0.9557 - recall: 0.9558 - precision: 0.9557 - val_loss: 1.2061 - val_accuracy: 0.8374 - val_recall: 0.8374 - val_precision: 0.8374\n",
      "Epoch 67/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0290 - accuracy: 0.9639 - recall: 0.9634 - precision: 0.9641 - val_loss: 1.3987 - val_accuracy: 0.8396 - val_recall: 0.8403 - val_precision: 0.8396\n",
      "Epoch 68/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0290 - accuracy: 0.9607 - recall: 0.9603 - precision: 0.9610 - val_loss: 1.3057 - val_accuracy: 0.8456 - val_recall: 0.8454 - val_precision: 0.8454\n",
      "Epoch 69/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0292 - accuracy: 0.9629 - recall: 0.9625 - precision: 0.9632 - val_loss: 1.4304 - val_accuracy: 0.8426 - val_recall: 0.8427 - val_precision: 0.8425\n",
      "Epoch 70/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0295 - accuracy: 0.9581 - recall: 0.9583 - precision: 0.9581 - val_loss: 1.3196 - val_accuracy: 0.8331 - val_recall: 0.8333 - val_precision: 0.8335\n",
      "Epoch 71/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0292 - accuracy: 0.9618 - recall: 0.9619 - precision: 0.9617 - val_loss: 1.2108 - val_accuracy: 0.8323 - val_recall: 0.8319 - val_precision: 0.8321\n",
      "Epoch 72/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0279 - accuracy: 0.9597 - recall: 0.9598 - precision: 0.9596 - val_loss: 1.2360 - val_accuracy: 0.8371 - val_recall: 0.8373 - val_precision: 0.8375\n",
      "Epoch 73/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0294 - accuracy: 0.9592 - recall: 0.9593 - precision: 0.9592 - val_loss: 1.3940 - val_accuracy: 0.8323 - val_recall: 0.8326 - val_precision: 0.8325\n",
      "Epoch 74/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0275 - accuracy: 0.9633 - recall: 0.9633 - precision: 0.9633 - val_loss: 1.5414 - val_accuracy: 0.8484 - val_recall: 0.8486 - val_precision: 0.8486\n",
      "Epoch 75/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0282 - accuracy: 0.9619 - recall: 0.9619 - precision: 0.9618 - val_loss: 1.4336 - val_accuracy: 0.8509 - val_recall: 0.8507 - val_precision: 0.8506\n",
      "Epoch 76/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0276 - accuracy: 0.9632 - recall: 0.9633 - precision: 0.9631 - val_loss: 1.4196 - val_accuracy: 0.8470 - val_recall: 0.8471 - val_precision: 0.8473\n",
      "Epoch 77/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0290 - accuracy: 0.9594 - recall: 0.9596 - precision: 0.9593 - val_loss: 1.4656 - val_accuracy: 0.8483 - val_recall: 0.8476 - val_precision: 0.8482\n",
      "Epoch 78/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0285 - accuracy: 0.9630 - recall: 0.9631 - precision: 0.9628 - val_loss: 1.3340 - val_accuracy: 0.8484 - val_recall: 0.8486 - val_precision: 0.8485\n",
      "Epoch 79/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0259 - accuracy: 0.9639 - recall: 0.9640 - precision: 0.9638 - val_loss: 1.4314 - val_accuracy: 0.8364 - val_recall: 0.8364 - val_precision: 0.8361\n",
      "Epoch 80/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0281 - accuracy: 0.9612 - recall: 0.9612 - precision: 0.9613 - val_loss: 1.4719 - val_accuracy: 0.8339 - val_recall: 0.8337 - val_precision: 0.8337\n",
      "Epoch 81/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0286 - accuracy: 0.9610 - recall: 0.9607 - precision: 0.9614 - val_loss: 1.5023 - val_accuracy: 0.8513 - val_recall: 0.8509 - val_precision: 0.8510\n",
      "Epoch 82/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0274 - accuracy: 0.9616 - recall: 0.9615 - precision: 0.9616 - val_loss: 1.3990 - val_accuracy: 0.8427 - val_recall: 0.8429 - val_precision: 0.8424\n",
      "Epoch 83/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0283 - accuracy: 0.9611 - recall: 0.9610 - precision: 0.9613 - val_loss: 1.2926 - val_accuracy: 0.8306 - val_recall: 0.8307 - val_precision: 0.8310\n",
      "Epoch 84/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0264 - accuracy: 0.9613 - recall: 0.9617 - precision: 0.9611 - val_loss: 1.3632 - val_accuracy: 0.8461 - val_recall: 0.8461 - val_precision: 0.8463\n",
      "Epoch 85/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0272 - accuracy: 0.9632 - recall: 0.9633 - precision: 0.9632 - val_loss: 1.4587 - val_accuracy: 0.8336 - val_recall: 0.8337 - val_precision: 0.8337\n",
      "Epoch 86/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0265 - accuracy: 0.9652 - recall: 0.9654 - precision: 0.9652 - val_loss: 1.3751 - val_accuracy: 0.8499 - val_recall: 0.8496 - val_precision: 0.8502\n",
      "Epoch 87/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0249 - accuracy: 0.9670 - recall: 0.9670 - precision: 0.9669 - val_loss: 1.6151 - val_accuracy: 0.8330 - val_recall: 0.8327 - val_precision: 0.8330\n",
      "Epoch 88/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0294 - accuracy: 0.9629 - recall: 0.9631 - precision: 0.9627 - val_loss: 1.5487 - val_accuracy: 0.8514 - val_recall: 0.8514 - val_precision: 0.8513\n",
      "Epoch 89/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0249 - accuracy: 0.9671 - recall: 0.9673 - precision: 0.9668 - val_loss: 1.5194 - val_accuracy: 0.8414 - val_recall: 0.8490 - val_precision: 0.8263\n",
      "Epoch 90/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0262 - accuracy: 0.9653 - recall: 0.9654 - precision: 0.9651 - val_loss: 1.4876 - val_accuracy: 0.8470 - val_recall: 0.8474 - val_precision: 0.8469\n",
      "Epoch 91/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0277 - accuracy: 0.9622 - recall: 0.9624 - precision: 0.9621 - val_loss: 1.3908 - val_accuracy: 0.8464 - val_recall: 0.8461 - val_precision: 0.8465\n",
      "Epoch 92/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0255 - accuracy: 0.9641 - recall: 0.9643 - precision: 0.9640 - val_loss: 1.5012 - val_accuracy: 0.8476 - val_recall: 0.8476 - val_precision: 0.8477\n",
      "Epoch 93/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0270 - accuracy: 0.9636 - recall: 0.9636 - precision: 0.9635 - val_loss: 1.4168 - val_accuracy: 0.8423 - val_recall: 0.8426 - val_precision: 0.8423\n",
      "Epoch 94/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0269 - accuracy: 0.9645 - recall: 0.9646 - precision: 0.9643 - val_loss: 1.4877 - val_accuracy: 0.8449 - val_recall: 0.8449 - val_precision: 0.8449\n",
      "Epoch 95/100\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0272 - accuracy: 0.9605 - recall: 0.9606 - precision: 0.9604 - val_loss: 1.5248 - val_accuracy: 0.8287 - val_recall: 0.8289 - val_precision: 0.8287\n",
      "Epoch 96/100\n",
      "420/420 [==============================] - 17s 42ms/step - loss: 0.0248 - accuracy: 0.9639 - recall: 0.9639 - precision: 0.9641 - val_loss: 1.4226 - val_accuracy: 0.8420 - val_recall: 0.8420 - val_precision: 0.8419\n",
      "Epoch 97/100\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0246 - accuracy: 0.9654 - recall: 0.9655 - precision: 0.9655 - val_loss: 1.7393 - val_accuracy: 0.8367 - val_recall: 0.8369 - val_precision: 0.8369\n",
      "Epoch 98/100\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0298 - accuracy: 0.9634 - recall: 0.9633 - precision: 0.9636 - val_loss: 1.3791 - val_accuracy: 0.8387 - val_recall: 0.8386 - val_precision: 0.8392\n",
      "Epoch 99/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0262 - accuracy: 0.9646 - recall: 0.9646 - precision: 0.9646 - val_loss: 1.4677 - val_accuracy: 0.8511 - val_recall: 0.8511 - val_precision: 0.8513\n",
      "Epoch 100/100\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0250 - accuracy: 0.9652 - recall: 0.9652 - precision: 0.9652 - val_loss: 1.5601 - val_accuracy: 0.8311 - val_recall: 0.8311 - val_precision: 0.8314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ffe2dbec40>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "hist2 = model.fit(x_train, y_tr, epochs=100, validation_split=0.1, shuffle=True,class_weight=weights, batch_size=batch_size,use_multiprocessing=True,workers=8,callbacks=[callback])\n",
    "hist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.85      0.88     11039\n",
      "         1.0       0.66      0.78      0.72      3961\n",
      "\n",
      "    accuracy                           0.84     15000\n",
      "   macro avg       0.79      0.82      0.80     15000\n",
      "weighted avg       0.85      0.84      0.84     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "predictions = model.predict(test_cnn_data)\n",
    "prediction_labels=[]\n",
    "labels = [0, 1]\n",
    "for p in predictions:\n",
    "    prediction_labels.append(labels[np.argmax(p)])\n",
    "print(classification_report(data_test.oh_label,prediction_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 50, 300)           39159600  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 44, 20)            42020     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 14, 20)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 280)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 280)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                17984     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 39,219,734\n",
      "Trainable params: 60,134\n",
      "Non-trainable params: 39,159,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embeddings, max_sequence_length, num_words, embedding_dim, labels_index = train_embedding_weights, MAX_SEQUENCE_LENGTH, len(train_word_index)+1, EMBEDDING_DIM, len(list(label_names))\n",
    "embedding_layer = Embedding(num_words,\n",
    "                        embedding_dim,\n",
    "                        weights=[embeddings],\n",
    "                        input_length=max_sequence_length,\n",
    "                        trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "conv1d = Conv1D(20,7,strides=1, use_bias=True,padding=\"valid\")(embedded_sequences)\n",
    "max_pool = MaxPool1D(pool_size=3)(conv1d)\n",
    "flattened = Flatten()(max_pool)\n",
    "x1 = Dropout(0.5)(flattened)\n",
    "x2 = Dense(64, activation='relu')(x1)\n",
    "x2 = Dropout(0.2)(x2)\n",
    "preds = Dense(labels_index, activation='sigmoid')(x2)\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),metrics=[\"accuracy\",tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "420/420 [==============================] - 19s 43ms/step - loss: 0.1965 - accuracy: 0.7478 - recall_1: 0.7462 - precision_1: 0.7458 - val_loss: 0.4094 - val_accuracy: 0.8190 - val_recall_1: 0.8157 - val_precision_1: 0.8199\n",
      "Epoch 2/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1709 - accuracy: 0.7977 - recall_1: 0.7953 - precision_1: 0.7982 - val_loss: 0.4363 - val_accuracy: 0.7903 - val_recall_1: 0.7894 - val_precision_1: 0.7917\n",
      "Epoch 3/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1646 - accuracy: 0.8043 - recall_1: 0.8011 - precision_1: 0.8057 - val_loss: 0.3857 - val_accuracy: 0.8286 - val_recall_1: 0.8274 - val_precision_1: 0.8294\n",
      "Epoch 4/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1588 - accuracy: 0.8083 - recall_1: 0.8051 - precision_1: 0.8101 - val_loss: 0.3881 - val_accuracy: 0.8291 - val_recall_1: 0.8263 - val_precision_1: 0.8295\n",
      "Epoch 5/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.1542 - accuracy: 0.8112 - recall_1: 0.8082 - precision_1: 0.8126 - val_loss: 0.3758 - val_accuracy: 0.8319 - val_recall_1: 0.8313 - val_precision_1: 0.8324\n",
      "Epoch 6/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1514 - accuracy: 0.8143 - recall_1: 0.8127 - precision_1: 0.8156 - val_loss: 0.4050 - val_accuracy: 0.7937 - val_recall_1: 0.7847 - val_precision_1: 0.8107\n",
      "Epoch 7/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1480 - accuracy: 0.8150 - recall_1: 0.8141 - precision_1: 0.8156 - val_loss: 0.3807 - val_accuracy: 0.8250 - val_recall_1: 0.8249 - val_precision_1: 0.8251\n",
      "Epoch 8/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1451 - accuracy: 0.8186 - recall_1: 0.8177 - precision_1: 0.8190 - val_loss: 0.3830 - val_accuracy: 0.8080 - val_recall_1: 0.8071 - val_precision_1: 0.8085\n",
      "Epoch 9/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1429 - accuracy: 0.8187 - recall_1: 0.8189 - precision_1: 0.8189 - val_loss: 0.3873 - val_accuracy: 0.8061 - val_recall_1: 0.8057 - val_precision_1: 0.8065\n",
      "Epoch 10/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1402 - accuracy: 0.8229 - recall_1: 0.8228 - precision_1: 0.8229 - val_loss: 0.3808 - val_accuracy: 0.8084 - val_recall_1: 0.8084 - val_precision_1: 0.8083\n",
      "Epoch 11/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.1366 - accuracy: 0.8249 - recall_1: 0.8251 - precision_1: 0.8246 - val_loss: 0.3996 - val_accuracy: 0.7967 - val_recall_1: 0.7969 - val_precision_1: 0.7965\n",
      "Epoch 12/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1352 - accuracy: 0.8267 - recall_1: 0.8275 - precision_1: 0.8264 - val_loss: 0.3910 - val_accuracy: 0.8023 - val_recall_1: 0.8031 - val_precision_1: 0.8028\n",
      "Epoch 13/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1326 - accuracy: 0.8288 - recall_1: 0.8291 - precision_1: 0.8286 - val_loss: 0.3593 - val_accuracy: 0.8463 - val_recall_1: 0.8464 - val_precision_1: 0.8464\n",
      "Epoch 14/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.1304 - accuracy: 0.8331 - recall_1: 0.8333 - precision_1: 0.8330 - val_loss: 0.3786 - val_accuracy: 0.8140 - val_recall_1: 0.8140 - val_precision_1: 0.8138\n",
      "Epoch 15/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.1282 - accuracy: 0.8349 - recall_1: 0.8354 - precision_1: 0.8349 - val_loss: 0.3614 - val_accuracy: 0.8286 - val_recall_1: 0.8289 - val_precision_1: 0.8287\n",
      "Epoch 16/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1284 - accuracy: 0.8334 - recall_1: 0.8336 - precision_1: 0.8331 - val_loss: 0.3694 - val_accuracy: 0.8261 - val_recall_1: 0.8261 - val_precision_1: 0.8260\n",
      "Epoch 17/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.1260 - accuracy: 0.8366 - recall_1: 0.8366 - precision_1: 0.8365 - val_loss: 0.3731 - val_accuracy: 0.8453 - val_recall_1: 0.8450 - val_precision_1: 0.8452\n",
      "Epoch 18/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1247 - accuracy: 0.8381 - recall_1: 0.8381 - precision_1: 0.8380 - val_loss: 0.3713 - val_accuracy: 0.8261 - val_recall_1: 0.8264 - val_precision_1: 0.8262\n",
      "Epoch 19/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1224 - accuracy: 0.8421 - recall_1: 0.8423 - precision_1: 0.8421 - val_loss: 0.3774 - val_accuracy: 0.8147 - val_recall_1: 0.8150 - val_precision_1: 0.8148\n",
      "Epoch 20/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1222 - accuracy: 0.8430 - recall_1: 0.8431 - precision_1: 0.8430 - val_loss: 0.3620 - val_accuracy: 0.8317 - val_recall_1: 0.8321 - val_precision_1: 0.8317\n",
      "Epoch 21/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1212 - accuracy: 0.8424 - recall_1: 0.8424 - precision_1: 0.8423 - val_loss: 0.3702 - val_accuracy: 0.8356 - val_recall_1: 0.8356 - val_precision_1: 0.8356\n",
      "Epoch 22/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1198 - accuracy: 0.8452 - recall_1: 0.8452 - precision_1: 0.8451 - val_loss: 0.3610 - val_accuracy: 0.8316 - val_recall_1: 0.8316 - val_precision_1: 0.8316\n",
      "Epoch 23/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1192 - accuracy: 0.8465 - recall_1: 0.8467 - precision_1: 0.8465 - val_loss: 0.3781 - val_accuracy: 0.8163 - val_recall_1: 0.8164 - val_precision_1: 0.8163\n",
      "Epoch 24/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.1181 - accuracy: 0.8467 - recall_1: 0.8468 - precision_1: 0.8467 - val_loss: 0.3766 - val_accuracy: 0.8231 - val_recall_1: 0.8231 - val_precision_1: 0.8231\n",
      "Epoch 25/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1169 - accuracy: 0.8462 - recall_1: 0.8462 - precision_1: 0.8461 - val_loss: 0.3767 - val_accuracy: 0.8309 - val_recall_1: 0.8310 - val_precision_1: 0.8309\n",
      "Epoch 26/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1144 - accuracy: 0.8510 - recall_1: 0.8510 - precision_1: 0.8510 - val_loss: 0.3883 - val_accuracy: 0.8229 - val_recall_1: 0.8230 - val_precision_1: 0.8229\n",
      "Epoch 27/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1147 - accuracy: 0.8515 - recall_1: 0.8515 - precision_1: 0.8515 - val_loss: 0.3933 - val_accuracy: 0.8146 - val_recall_1: 0.8147 - val_precision_1: 0.8145\n",
      "Epoch 28/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.1137 - accuracy: 0.8514 - recall_1: 0.8514 - precision_1: 0.8515 - val_loss: 0.3736 - val_accuracy: 0.8373 - val_recall_1: 0.8373 - val_precision_1: 0.8373\n",
      "Epoch 29/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1132 - accuracy: 0.8523 - recall_1: 0.8523 - precision_1: 0.8523 - val_loss: 0.3866 - val_accuracy: 0.8224 - val_recall_1: 0.8224 - val_precision_1: 0.8224\n",
      "Epoch 30/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1126 - accuracy: 0.8530 - recall_1: 0.8530 - precision_1: 0.8530 - val_loss: 0.3777 - val_accuracy: 0.8240 - val_recall_1: 0.8240 - val_precision_1: 0.8240\n",
      "Epoch 31/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.1119 - accuracy: 0.8551 - recall_1: 0.8551 - precision_1: 0.8551 - val_loss: 0.3875 - val_accuracy: 0.8189 - val_recall_1: 0.8189 - val_precision_1: 0.8189\n",
      "Epoch 32/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.1104 - accuracy: 0.8576 - recall_1: 0.8576 - precision_1: 0.8576 - val_loss: 0.3927 - val_accuracy: 0.8251 - val_recall_1: 0.8251 - val_precision_1: 0.8251\n",
      "Epoch 33/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1103 - accuracy: 0.8588 - recall_1: 0.8588 - precision_1: 0.8588 - val_loss: 0.3735 - val_accuracy: 0.8413 - val_recall_1: 0.8413 - val_precision_1: 0.8414\n",
      "Epoch 34/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.1099 - accuracy: 0.8582 - recall_1: 0.8582 - precision_1: 0.8582 - val_loss: 0.3869 - val_accuracy: 0.8221 - val_recall_1: 0.8223 - val_precision_1: 0.8222\n",
      "Epoch 35/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1092 - accuracy: 0.8589 - recall_1: 0.8589 - precision_1: 0.8589 - val_loss: 0.3835 - val_accuracy: 0.8363 - val_recall_1: 0.8363 - val_precision_1: 0.8363\n",
      "Epoch 36/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.1091 - accuracy: 0.8594 - recall_1: 0.8594 - precision_1: 0.8594 - val_loss: 0.3713 - val_accuracy: 0.8297 - val_recall_1: 0.8297 - val_precision_1: 0.8297\n",
      "Epoch 37/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1079 - accuracy: 0.8606 - recall_1: 0.8606 - precision_1: 0.8606 - val_loss: 0.3791 - val_accuracy: 0.8270 - val_recall_1: 0.8270 - val_precision_1: 0.8270\n",
      "Epoch 38/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1065 - accuracy: 0.8620 - recall_1: 0.8620 - precision_1: 0.8620 - val_loss: 0.3806 - val_accuracy: 0.8307 - val_recall_1: 0.8307 - val_precision_1: 0.8307\n",
      "Epoch 39/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1078 - accuracy: 0.8607 - recall_1: 0.8607 - precision_1: 0.8607 - val_loss: 0.3726 - val_accuracy: 0.8327 - val_recall_1: 0.8327 - val_precision_1: 0.8327\n",
      "Epoch 40/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1077 - accuracy: 0.8595 - recall_1: 0.8595 - precision_1: 0.8595 - val_loss: 0.3858 - val_accuracy: 0.8354 - val_recall_1: 0.8354 - val_precision_1: 0.8354\n",
      "Epoch 41/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1058 - accuracy: 0.8633 - recall_1: 0.8634 - precision_1: 0.8634 - val_loss: 0.3909 - val_accuracy: 0.8241 - val_recall_1: 0.8241 - val_precision_1: 0.8241\n",
      "Epoch 42/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1063 - accuracy: 0.8632 - recall_1: 0.8632 - precision_1: 0.8632 - val_loss: 0.3900 - val_accuracy: 0.8311 - val_recall_1: 0.8311 - val_precision_1: 0.8311\n",
      "Epoch 43/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1054 - accuracy: 0.8625 - recall_1: 0.8626 - precision_1: 0.8625 - val_loss: 0.3805 - val_accuracy: 0.8260 - val_recall_1: 0.8260 - val_precision_1: 0.8260\n",
      "Epoch 44/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1054 - accuracy: 0.8642 - recall_1: 0.8642 - precision_1: 0.8642 - val_loss: 0.4027 - val_accuracy: 0.8221 - val_recall_1: 0.8221 - val_precision_1: 0.8221\n",
      "Epoch 45/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1046 - accuracy: 0.8640 - recall_1: 0.8640 - precision_1: 0.8640 - val_loss: 0.3910 - val_accuracy: 0.8327 - val_recall_1: 0.8327 - val_precision_1: 0.8327\n",
      "Epoch 46/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1045 - accuracy: 0.8653 - recall_1: 0.8653 - precision_1: 0.8653 - val_loss: 0.3847 - val_accuracy: 0.8269 - val_recall_1: 0.8269 - val_precision_1: 0.8269\n",
      "Epoch 47/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.1036 - accuracy: 0.8632 - recall_1: 0.8632 - precision_1: 0.8632 - val_loss: 0.4001 - val_accuracy: 0.8171 - val_recall_1: 0.8171 - val_precision_1: 0.8171\n",
      "Epoch 48/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.1028 - accuracy: 0.8672 - recall_1: 0.8672 - precision_1: 0.8672 - val_loss: 0.3821 - val_accuracy: 0.8483 - val_recall_1: 0.8483 - val_precision_1: 0.8483\n",
      "Epoch 49/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1037 - accuracy: 0.8647 - recall_1: 0.8647 - precision_1: 0.8647 - val_loss: 0.3960 - val_accuracy: 0.8229 - val_recall_1: 0.8229 - val_precision_1: 0.8229\n",
      "Epoch 50/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1035 - accuracy: 0.8664 - recall_1: 0.8664 - precision_1: 0.8664 - val_loss: 0.3827 - val_accuracy: 0.8277 - val_recall_1: 0.8277 - val_precision_1: 0.8277\n",
      "Epoch 51/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.1019 - accuracy: 0.8684 - recall_1: 0.8684 - precision_1: 0.8684 - val_loss: 0.3922 - val_accuracy: 0.8381 - val_recall_1: 0.8381 - val_precision_1: 0.8381\n",
      "Epoch 52/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1016 - accuracy: 0.8688 - recall_1: 0.8688 - precision_1: 0.8688 - val_loss: 0.3939 - val_accuracy: 0.8327 - val_recall_1: 0.8327 - val_precision_1: 0.8327\n",
      "Epoch 53/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1012 - accuracy: 0.8683 - recall_1: 0.8683 - precision_1: 0.8683 - val_loss: 0.4052 - val_accuracy: 0.8177 - val_recall_1: 0.8177 - val_precision_1: 0.8177\n",
      "Epoch 54/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1017 - accuracy: 0.8684 - recall_1: 0.8684 - precision_1: 0.8684 - val_loss: 0.3973 - val_accuracy: 0.8244 - val_recall_1: 0.8244 - val_precision_1: 0.8244\n",
      "Epoch 55/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0995 - accuracy: 0.8705 - recall_1: 0.8705 - precision_1: 0.8705 - val_loss: 0.4024 - val_accuracy: 0.8250 - val_recall_1: 0.8250 - val_precision_1: 0.8250\n",
      "Epoch 56/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1007 - accuracy: 0.8684 - recall_1: 0.8684 - precision_1: 0.8684 - val_loss: 0.4007 - val_accuracy: 0.8316 - val_recall_1: 0.8316 - val_precision_1: 0.8316\n",
      "Epoch 57/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.1003 - accuracy: 0.8695 - recall_1: 0.8695 - precision_1: 0.8695 - val_loss: 0.3929 - val_accuracy: 0.8237 - val_recall_1: 0.8237 - val_precision_1: 0.8237\n",
      "Epoch 58/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0999 - accuracy: 0.8698 - recall_1: 0.8698 - precision_1: 0.8698 - val_loss: 0.4025 - val_accuracy: 0.8380 - val_recall_1: 0.8380 - val_precision_1: 0.8380\n",
      "Epoch 59/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0992 - accuracy: 0.8714 - recall_1: 0.8714 - precision_1: 0.8714 - val_loss: 0.3947 - val_accuracy: 0.8370 - val_recall_1: 0.8370 - val_precision_1: 0.8370\n",
      "Epoch 60/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0992 - accuracy: 0.8697 - recall_1: 0.8697 - precision_1: 0.8697 - val_loss: 0.4216 - val_accuracy: 0.8226 - val_recall_1: 0.8226 - val_precision_1: 0.8226\n",
      "Epoch 61/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0985 - accuracy: 0.8725 - recall_1: 0.8725 - precision_1: 0.8725 - val_loss: 0.4135 - val_accuracy: 0.8386 - val_recall_1: 0.8386 - val_precision_1: 0.8386\n",
      "Epoch 62/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0996 - accuracy: 0.8695 - recall_1: 0.8695 - precision_1: 0.8695 - val_loss: 0.3998 - val_accuracy: 0.8273 - val_recall_1: 0.8273 - val_precision_1: 0.8273\n",
      "Epoch 63/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0981 - accuracy: 0.8727 - recall_1: 0.8727 - precision_1: 0.8727 - val_loss: 0.4068 - val_accuracy: 0.8207 - val_recall_1: 0.8207 - val_precision_1: 0.8207\n",
      "Epoch 64/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0977 - accuracy: 0.8726 - recall_1: 0.8726 - precision_1: 0.8726 - val_loss: 0.4029 - val_accuracy: 0.8514 - val_recall_1: 0.8514 - val_precision_1: 0.8514\n",
      "Epoch 65/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0968 - accuracy: 0.8743 - recall_1: 0.8743 - precision_1: 0.8743 - val_loss: 0.4055 - val_accuracy: 0.8264 - val_recall_1: 0.8264 - val_precision_1: 0.8264\n",
      "Epoch 66/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0972 - accuracy: 0.8735 - recall_1: 0.8735 - precision_1: 0.8735 - val_loss: 0.4119 - val_accuracy: 0.8310 - val_recall_1: 0.8310 - val_precision_1: 0.8310\n",
      "Epoch 67/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0975 - accuracy: 0.8720 - recall_1: 0.8720 - precision_1: 0.8720 - val_loss: 0.4236 - val_accuracy: 0.8270 - val_recall_1: 0.8270 - val_precision_1: 0.8270\n",
      "Epoch 68/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0972 - accuracy: 0.8721 - recall_1: 0.8721 - precision_1: 0.8721 - val_loss: 0.4083 - val_accuracy: 0.8340 - val_recall_1: 0.8340 - val_precision_1: 0.8340\n",
      "Epoch 69/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0974 - accuracy: 0.8751 - recall_1: 0.8751 - precision_1: 0.8751 - val_loss: 0.3937 - val_accuracy: 0.8287 - val_recall_1: 0.8287 - val_precision_1: 0.8287\n",
      "Epoch 70/1000\n",
      "420/420 [==============================] - 20s 47ms/step - loss: 0.0976 - accuracy: 0.8734 - recall_1: 0.8734 - precision_1: 0.8734 - val_loss: 0.4162 - val_accuracy: 0.8279 - val_recall_1: 0.8279 - val_precision_1: 0.8279\n",
      "Epoch 71/1000\n",
      "420/420 [==============================] - 18s 44ms/step - loss: 0.0956 - accuracy: 0.8765 - recall_1: 0.8765 - precision_1: 0.8765 - val_loss: 0.4111 - val_accuracy: 0.8280 - val_recall_1: 0.8280 - val_precision_1: 0.8280\n",
      "Epoch 72/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0959 - accuracy: 0.8749 - recall_1: 0.8749 - precision_1: 0.8749 - val_loss: 0.4269 - val_accuracy: 0.8116 - val_recall_1: 0.8116 - val_precision_1: 0.8116\n",
      "Epoch 73/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0959 - accuracy: 0.8752 - recall_1: 0.8752 - precision_1: 0.8752 - val_loss: 0.4302 - val_accuracy: 0.8434 - val_recall_1: 0.8434 - val_precision_1: 0.8434\n",
      "Epoch 74/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0940 - accuracy: 0.8783 - recall_1: 0.8783 - precision_1: 0.8783 - val_loss: 0.4130 - val_accuracy: 0.8249 - val_recall_1: 0.8249 - val_precision_1: 0.8249\n",
      "Epoch 75/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0958 - accuracy: 0.8734 - recall_1: 0.8734 - precision_1: 0.8734 - val_loss: 0.3922 - val_accuracy: 0.8341 - val_recall_1: 0.8341 - val_precision_1: 0.8341\n",
      "Epoch 76/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0944 - accuracy: 0.8778 - recall_1: 0.8778 - precision_1: 0.8778 - val_loss: 0.3977 - val_accuracy: 0.8450 - val_recall_1: 0.8450 - val_precision_1: 0.8450\n",
      "Epoch 77/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0942 - accuracy: 0.8768 - recall_1: 0.8768 - precision_1: 0.8768 - val_loss: 0.4185 - val_accuracy: 0.8196 - val_recall_1: 0.8196 - val_precision_1: 0.8196\n",
      "Epoch 78/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0946 - accuracy: 0.8769 - recall_1: 0.8769 - precision_1: 0.8769 - val_loss: 0.4055 - val_accuracy: 0.8503 - val_recall_1: 0.8503 - val_precision_1: 0.8503\n",
      "Epoch 79/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0937 - accuracy: 0.8785 - recall_1: 0.8785 - precision_1: 0.8785 - val_loss: 0.3962 - val_accuracy: 0.8300 - val_recall_1: 0.8300 - val_precision_1: 0.8300\n",
      "Epoch 80/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0947 - accuracy: 0.8764 - recall_1: 0.8764 - precision_1: 0.8764 - val_loss: 0.3830 - val_accuracy: 0.8363 - val_recall_1: 0.8363 - val_precision_1: 0.8363\n",
      "Epoch 81/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0934 - accuracy: 0.8802 - recall_1: 0.8802 - precision_1: 0.8802 - val_loss: 0.4001 - val_accuracy: 0.8323 - val_recall_1: 0.8323 - val_precision_1: 0.8323\n",
      "Epoch 82/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0939 - accuracy: 0.8770 - recall_1: 0.8770 - precision_1: 0.8770 - val_loss: 0.4110 - val_accuracy: 0.8200 - val_recall_1: 0.8200 - val_precision_1: 0.8200\n",
      "Epoch 83/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0937 - accuracy: 0.8777 - recall_1: 0.8777 - precision_1: 0.8777 - val_loss: 0.4109 - val_accuracy: 0.8301 - val_recall_1: 0.8301 - val_precision_1: 0.8301\n",
      "Epoch 84/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0931 - accuracy: 0.8787 - recall_1: 0.8787 - precision_1: 0.8787 - val_loss: 0.4048 - val_accuracy: 0.8190 - val_recall_1: 0.8190 - val_precision_1: 0.8190\n",
      "Epoch 85/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0921 - accuracy: 0.8802 - recall_1: 0.8802 - precision_1: 0.8802 - val_loss: 0.3961 - val_accuracy: 0.8213 - val_recall_1: 0.8213 - val_precision_1: 0.8213\n",
      "Epoch 86/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.0947 - accuracy: 0.8757 - recall_1: 0.8757 - precision_1: 0.8757 - val_loss: 0.4115 - val_accuracy: 0.8306 - val_recall_1: 0.8306 - val_precision_1: 0.8306\n",
      "Epoch 87/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.0930 - accuracy: 0.8771 - recall_1: 0.8771 - precision_1: 0.8771 - val_loss: 0.4075 - val_accuracy: 0.8500 - val_recall_1: 0.8500 - val_precision_1: 0.8500\n",
      "Epoch 88/1000\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.0925 - accuracy: 0.8800 - recall_1: 0.8800 - precision_1: 0.8800 - val_loss: 0.4048 - val_accuracy: 0.8240 - val_recall_1: 0.8240 - val_precision_1: 0.8240\n",
      "Epoch 89/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.0926 - accuracy: 0.8802 - recall_1: 0.8802 - precision_1: 0.8802 - val_loss: 0.3939 - val_accuracy: 0.8306 - val_recall_1: 0.8306 - val_precision_1: 0.8306\n",
      "Epoch 90/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.0923 - accuracy: 0.8797 - recall_1: 0.8797 - precision_1: 0.8797 - val_loss: 0.4056 - val_accuracy: 0.8306 - val_recall_1: 0.8306 - val_precision_1: 0.8306\n",
      "Epoch 91/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0924 - accuracy: 0.8781 - recall_1: 0.8781 - precision_1: 0.8781 - val_loss: 0.4160 - val_accuracy: 0.8266 - val_recall_1: 0.8266 - val_precision_1: 0.8266\n",
      "Epoch 92/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0919 - accuracy: 0.8806 - recall_1: 0.8806 - precision_1: 0.8806 - val_loss: 0.4360 - val_accuracy: 0.8187 - val_recall_1: 0.8187 - val_precision_1: 0.8187\n",
      "Epoch 93/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.0912 - accuracy: 0.8808 - recall_1: 0.8808 - precision_1: 0.8808 - val_loss: 0.4118 - val_accuracy: 0.8333 - val_recall_1: 0.8333 - val_precision_1: 0.8333\n",
      "Epoch 94/1000\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.0913 - accuracy: 0.8804 - recall_1: 0.8804 - precision_1: 0.8804 - val_loss: 0.4120 - val_accuracy: 0.8271 - val_recall_1: 0.8271 - val_precision_1: 0.8271\n",
      "Epoch 95/1000\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 0.0909 - accuracy: 0.8822 - recall_1: 0.8822 - precision_1: 0.8822 - val_loss: 0.4270 - val_accuracy: 0.8184 - val_recall_1: 0.8184 - val_precision_1: 0.8184\n",
      "Epoch 96/1000\n",
      "420/420 [==============================] - 15s 36ms/step - loss: 0.0905 - accuracy: 0.8798 - recall_1: 0.8798 - precision_1: 0.8798 - val_loss: 0.4156 - val_accuracy: 0.8266 - val_recall_1: 0.8266 - val_precision_1: 0.8266\n",
      "Epoch 97/1000\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.0916 - accuracy: 0.8796 - recall_1: 0.8796 - precision_1: 0.8796 - val_loss: 0.4134 - val_accuracy: 0.8304 - val_recall_1: 0.8304 - val_precision_1: 0.8304\n",
      "Epoch 98/1000\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.0909 - accuracy: 0.8821 - recall_1: 0.8821 - precision_1: 0.8821 - val_loss: 0.4088 - val_accuracy: 0.8294 - val_recall_1: 0.8294 - val_precision_1: 0.8294\n",
      "Epoch 99/1000\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 0.0900 - accuracy: 0.8820 - recall_1: 0.8820 - precision_1: 0.8820 - val_loss: 0.4103 - val_accuracy: 0.8354 - val_recall_1: 0.8354 - val_precision_1: 0.8354\n",
      "Epoch 100/1000\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 0.0895 - accuracy: 0.8826 - recall_1: 0.8826 - precision_1: 0.8826 - val_loss: 0.4428 - val_accuracy: 0.8221 - val_recall_1: 0.8221 - val_precision_1: 0.8221\n",
      "Epoch 101/1000\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 0.0906 - accuracy: 0.8802 - recall_1: 0.8802 - precision_1: 0.8802 - val_loss: 0.4056 - val_accuracy: 0.8261 - val_recall_1: 0.8261 - val_precision_1: 0.8261\n",
      "Epoch 102/1000\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.0904 - accuracy: 0.8829 - recall_1: 0.8829 - precision_1: 0.8829 - val_loss: 0.4110 - val_accuracy: 0.8333 - val_recall_1: 0.8333 - val_precision_1: 0.8333\n",
      "Epoch 103/1000\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 0.0909 - accuracy: 0.8797 - recall_1: 0.8797 - precision_1: 0.8797 - val_loss: 0.4168 - val_accuracy: 0.8414 - val_recall_1: 0.8414 - val_precision_1: 0.8414\n",
      "Epoch 104/1000\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 0.0889 - accuracy: 0.8849 - recall_1: 0.8849 - precision_1: 0.8849 - val_loss: 0.4178 - val_accuracy: 0.8356 - val_recall_1: 0.8356 - val_precision_1: 0.8356\n",
      "Epoch 105/1000\n",
      "420/420 [==============================] - 15s 36ms/step - loss: 0.0893 - accuracy: 0.8817 - recall_1: 0.8817 - precision_1: 0.8817 - val_loss: 0.4321 - val_accuracy: 0.8397 - val_recall_1: 0.8397 - val_precision_1: 0.8397\n",
      "Epoch 106/1000\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.0888 - accuracy: 0.8829 - recall_1: 0.8829 - precision_1: 0.8829 - val_loss: 0.4476 - val_accuracy: 0.8307 - val_recall_1: 0.8307 - val_precision_1: 0.8307\n",
      "Epoch 107/1000\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.0900 - accuracy: 0.8825 - recall_1: 0.8825 - precision_1: 0.8825 - val_loss: 0.4205 - val_accuracy: 0.8527 - val_recall_1: 0.8527 - val_precision_1: 0.8527\n",
      "Epoch 108/1000\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 0.0904 - accuracy: 0.8798 - recall_1: 0.8798 - precision_1: 0.8798 - val_loss: 0.4040 - val_accuracy: 0.8296 - val_recall_1: 0.8296 - val_precision_1: 0.8296\n",
      "Epoch 109/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0894 - accuracy: 0.8830 - recall_1: 0.8830 - precision_1: 0.8830 - val_loss: 0.4171 - val_accuracy: 0.8176 - val_recall_1: 0.8176 - val_precision_1: 0.8176\n",
      "Epoch 110/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0891 - accuracy: 0.8832 - recall_1: 0.8832 - precision_1: 0.8832 - val_loss: 0.4067 - val_accuracy: 0.8497 - val_recall_1: 0.8497 - val_precision_1: 0.8497\n",
      "Epoch 111/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.0880 - accuracy: 0.8863 - recall_1: 0.8863 - precision_1: 0.8863 - val_loss: 0.4042 - val_accuracy: 0.8323 - val_recall_1: 0.8323 - val_precision_1: 0.8323\n",
      "Epoch 112/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.0891 - accuracy: 0.8827 - recall_1: 0.8827 - precision_1: 0.8827 - val_loss: 0.4090 - val_accuracy: 0.8471 - val_recall_1: 0.8471 - val_precision_1: 0.8471\n",
      "Epoch 113/1000\n",
      "420/420 [==============================] - 16s 39ms/step - loss: 0.0893 - accuracy: 0.8831 - recall_1: 0.8831 - precision_1: 0.8831 - val_loss: 0.4150 - val_accuracy: 0.8359 - val_recall_1: 0.8359 - val_precision_1: 0.8359\n",
      "Epoch 114/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0884 - accuracy: 0.8851 - recall_1: 0.8851 - precision_1: 0.8851 - val_loss: 0.4164 - val_accuracy: 0.8344 - val_recall_1: 0.8344 - val_precision_1: 0.8344\n",
      "Epoch 115/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0880 - accuracy: 0.8851 - recall_1: 0.8851 - precision_1: 0.8851 - val_loss: 0.4315 - val_accuracy: 0.8336 - val_recall_1: 0.8336 - val_precision_1: 0.8336\n",
      "Epoch 116/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0875 - accuracy: 0.8857 - recall_1: 0.8857 - precision_1: 0.8857 - val_loss: 0.4417 - val_accuracy: 0.8287 - val_recall_1: 0.8287 - val_precision_1: 0.8287\n",
      "Epoch 117/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0875 - accuracy: 0.8851 - recall_1: 0.8851 - precision_1: 0.8851 - val_loss: 0.4375 - val_accuracy: 0.8329 - val_recall_1: 0.8329 - val_precision_1: 0.8329\n",
      "Epoch 118/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0883 - accuracy: 0.8839 - recall_1: 0.8839 - precision_1: 0.8839 - val_loss: 0.4277 - val_accuracy: 0.8414 - val_recall_1: 0.8414 - val_precision_1: 0.8414\n",
      "Epoch 119/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0881 - accuracy: 0.8845 - recall_1: 0.8845 - precision_1: 0.8845 - val_loss: 0.4199 - val_accuracy: 0.8346 - val_recall_1: 0.8346 - val_precision_1: 0.8346\n",
      "Epoch 120/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0883 - accuracy: 0.8835 - recall_1: 0.8835 - precision_1: 0.8835 - val_loss: 0.4150 - val_accuracy: 0.8410 - val_recall_1: 0.8410 - val_precision_1: 0.8410\n",
      "Epoch 121/1000\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.0877 - accuracy: 0.8847 - recall_1: 0.8847 - precision_1: 0.8847 - val_loss: 0.4252 - val_accuracy: 0.8299 - val_recall_1: 0.8299 - val_precision_1: 0.8299\n",
      "Epoch 122/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0874 - accuracy: 0.8852 - recall_1: 0.8852 - precision_1: 0.8852 - val_loss: 0.4028 - val_accuracy: 0.8277 - val_recall_1: 0.8277 - val_precision_1: 0.8277\n",
      "Epoch 123/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0873 - accuracy: 0.8852 - recall_1: 0.8852 - precision_1: 0.8852 - val_loss: 0.4212 - val_accuracy: 0.8381 - val_recall_1: 0.8381 - val_precision_1: 0.8381\n",
      "Epoch 124/1000\n",
      "420/420 [==============================] - 17s 39ms/step - loss: 0.0863 - accuracy: 0.8871 - recall_1: 0.8871 - precision_1: 0.8871 - val_loss: 0.4117 - val_accuracy: 0.8293 - val_recall_1: 0.8293 - val_precision_1: 0.8293\n",
      "Epoch 125/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0871 - accuracy: 0.8865 - recall_1: 0.8865 - precision_1: 0.8865 - val_loss: 0.4236 - val_accuracy: 0.8311 - val_recall_1: 0.8311 - val_precision_1: 0.8311\n",
      "Epoch 126/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0883 - accuracy: 0.8837 - recall_1: 0.8837 - precision_1: 0.8837 - val_loss: 0.4309 - val_accuracy: 0.8113 - val_recall_1: 0.8113 - val_precision_1: 0.8113\n",
      "Epoch 127/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0863 - accuracy: 0.8866 - recall_1: 0.8866 - precision_1: 0.8866 - val_loss: 0.4419 - val_accuracy: 0.8267 - val_recall_1: 0.8267 - val_precision_1: 0.8267\n",
      "Epoch 128/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0858 - accuracy: 0.8870 - recall_1: 0.8870 - precision_1: 0.8870 - val_loss: 0.4296 - val_accuracy: 0.8286 - val_recall_1: 0.8286 - val_precision_1: 0.8286\n",
      "Epoch 129/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0877 - accuracy: 0.8858 - recall_1: 0.8858 - precision_1: 0.8858 - val_loss: 0.4168 - val_accuracy: 0.8244 - val_recall_1: 0.8244 - val_precision_1: 0.8244\n",
      "Epoch 130/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0860 - accuracy: 0.8856 - recall_1: 0.8856 - precision_1: 0.8856 - val_loss: 0.4177 - val_accuracy: 0.8330 - val_recall_1: 0.8330 - val_precision_1: 0.8330\n",
      "Epoch 131/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0868 - accuracy: 0.8850 - recall_1: 0.8850 - precision_1: 0.8850 - val_loss: 0.4547 - val_accuracy: 0.8230 - val_recall_1: 0.8230 - val_precision_1: 0.8230\n",
      "Epoch 132/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0858 - accuracy: 0.8872 - recall_1: 0.8872 - precision_1: 0.8872 - val_loss: 0.4440 - val_accuracy: 0.8206 - val_recall_1: 0.8206 - val_precision_1: 0.8206\n",
      "Epoch 133/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0859 - accuracy: 0.8857 - recall_1: 0.8857 - precision_1: 0.8857 - val_loss: 0.4318 - val_accuracy: 0.8360 - val_recall_1: 0.8360 - val_precision_1: 0.8360\n",
      "Epoch 134/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0866 - accuracy: 0.8868 - recall_1: 0.8868 - precision_1: 0.8868 - val_loss: 0.4211 - val_accuracy: 0.8296 - val_recall_1: 0.8296 - val_precision_1: 0.8296\n",
      "Epoch 135/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0842 - accuracy: 0.8885 - recall_1: 0.8885 - precision_1: 0.8885 - val_loss: 0.4402 - val_accuracy: 0.8313 - val_recall_1: 0.8313 - val_precision_1: 0.8313\n",
      "Epoch 136/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0847 - accuracy: 0.8882 - recall_1: 0.8882 - precision_1: 0.8882 - val_loss: 0.4174 - val_accuracy: 0.8231 - val_recall_1: 0.8231 - val_precision_1: 0.8231\n",
      "Epoch 137/1000\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 0.0856 - accuracy: 0.8855 - recall_1: 0.8855 - precision_1: 0.8855 - val_loss: 0.4330 - val_accuracy: 0.8309 - val_recall_1: 0.8309 - val_precision_1: 0.8309\n",
      "Epoch 138/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0847 - accuracy: 0.8890 - recall_1: 0.8890 - precision_1: 0.8890 - val_loss: 0.4395 - val_accuracy: 0.8381 - val_recall_1: 0.8381 - val_precision_1: 0.8381\n",
      "Epoch 139/1000\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.0860 - accuracy: 0.8879 - recall_1: 0.8879 - precision_1: 0.8879 - val_loss: 0.4311 - val_accuracy: 0.8286 - val_recall_1: 0.8286 - val_precision_1: 0.8286\n",
      "Epoch 140/1000\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.0860 - accuracy: 0.8860 - recall_1: 0.8860 - precision_1: 0.8860 - val_loss: 0.4284 - val_accuracy: 0.8399 - val_recall_1: 0.8399 - val_precision_1: 0.8399\n",
      "Epoch 141/1000\n",
      "420/420 [==============================] - 17s 42ms/step - loss: 0.0847 - accuracy: 0.8877 - recall_1: 0.8877 - precision_1: 0.8877 - val_loss: 0.4343 - val_accuracy: 0.8113 - val_recall_1: 0.8113 - val_precision_1: 0.8113\n",
      "Epoch 142/1000\n",
      "420/420 [==============================] - 28s 66ms/step - loss: 0.0846 - accuracy: 0.8897 - recall_1: 0.8897 - precision_1: 0.8897 - val_loss: 0.4263 - val_accuracy: 0.8326 - val_recall_1: 0.8326 - val_precision_1: 0.8326\n",
      "Epoch 143/1000\n",
      "420/420 [==============================] - 37s 89ms/step - loss: 0.0856 - accuracy: 0.8865 - recall_1: 0.8865 - precision_1: 0.8865 - val_loss: 0.4173 - val_accuracy: 0.8466 - val_recall_1: 0.8466 - val_precision_1: 0.8466\n",
      "Epoch 144/1000\n",
      "420/420 [==============================] - 38s 90ms/step - loss: 0.0842 - accuracy: 0.8892 - recall_1: 0.8892 - precision_1: 0.8892 - val_loss: 0.4527 - val_accuracy: 0.8304 - val_recall_1: 0.8304 - val_precision_1: 0.8304\n",
      "Epoch 145/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0837 - accuracy: 0.8882 - recall_1: 0.8882 - precision_1: 0.8882 - val_loss: 0.4458 - val_accuracy: 0.8207 - val_recall_1: 0.8207 - val_precision_1: 0.8207\n",
      "Epoch 146/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0858 - accuracy: 0.8877 - recall_1: 0.8877 - precision_1: 0.8877 - val_loss: 0.4150 - val_accuracy: 0.8286 - val_recall_1: 0.8286 - val_precision_1: 0.8286\n",
      "Epoch 147/1000\n",
      "420/420 [==============================] - 38s 90ms/step - loss: 0.0854 - accuracy: 0.8876 - recall_1: 0.8876 - precision_1: 0.8876 - val_loss: 0.4406 - val_accuracy: 0.8290 - val_recall_1: 0.8290 - val_precision_1: 0.8290\n",
      "Epoch 148/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0849 - accuracy: 0.8879 - recall_1: 0.8879 - precision_1: 0.8879 - val_loss: 0.4292 - val_accuracy: 0.8239 - val_recall_1: 0.8239 - val_precision_1: 0.8239\n",
      "Epoch 149/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0837 - accuracy: 0.8894 - recall_1: 0.8894 - precision_1: 0.8894 - val_loss: 0.4145 - val_accuracy: 0.8384 - val_recall_1: 0.8384 - val_precision_1: 0.8384\n",
      "Epoch 150/1000\n",
      "420/420 [==============================] - 39s 93ms/step - loss: 0.0841 - accuracy: 0.8898 - recall_1: 0.8898 - precision_1: 0.8898 - val_loss: 0.4448 - val_accuracy: 0.8361 - val_recall_1: 0.8361 - val_precision_1: 0.8361\n",
      "Epoch 151/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0841 - accuracy: 0.8891 - recall_1: 0.8891 - precision_1: 0.8891 - val_loss: 0.4275 - val_accuracy: 0.8374 - val_recall_1: 0.8374 - val_precision_1: 0.8374\n",
      "Epoch 152/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0839 - accuracy: 0.8921 - recall_1: 0.8921 - precision_1: 0.8921 - val_loss: 0.4352 - val_accuracy: 0.8196 - val_recall_1: 0.8196 - val_precision_1: 0.8196\n",
      "Epoch 153/1000\n",
      "420/420 [==============================] - 39s 93ms/step - loss: 0.0841 - accuracy: 0.8877 - recall_1: 0.8877 - precision_1: 0.8877 - val_loss: 0.4251 - val_accuracy: 0.8337 - val_recall_1: 0.8337 - val_precision_1: 0.8337\n",
      "Epoch 154/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0823 - accuracy: 0.8922 - recall_1: 0.8922 - precision_1: 0.8922 - val_loss: 0.4476 - val_accuracy: 0.8363 - val_recall_1: 0.8363 - val_precision_1: 0.8363\n",
      "Epoch 155/1000\n",
      "420/420 [==============================] - 39s 94ms/step - loss: 0.0834 - accuracy: 0.8888 - recall_1: 0.8888 - precision_1: 0.8888 - val_loss: 0.4266 - val_accuracy: 0.8554 - val_recall_1: 0.8554 - val_precision_1: 0.8554\n",
      "Epoch 156/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0833 - accuracy: 0.8897 - recall_1: 0.8897 - precision_1: 0.8897 - val_loss: 0.4391 - val_accuracy: 0.8294 - val_recall_1: 0.8294 - val_precision_1: 0.8294\n",
      "Epoch 157/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0835 - accuracy: 0.8907 - recall_1: 0.8907 - precision_1: 0.8907 - val_loss: 0.4393 - val_accuracy: 0.8386 - val_recall_1: 0.8386 - val_precision_1: 0.8386\n",
      "Epoch 158/1000\n",
      "420/420 [==============================] - 38s 90ms/step - loss: 0.0829 - accuracy: 0.8906 - recall_1: 0.8906 - precision_1: 0.8906 - val_loss: 0.4663 - val_accuracy: 0.8366 - val_recall_1: 0.8366 - val_precision_1: 0.8366\n",
      "Epoch 159/1000\n",
      "420/420 [==============================] - 38s 90ms/step - loss: 0.0823 - accuracy: 0.8934 - recall_1: 0.8934 - precision_1: 0.8934 - val_loss: 0.4597 - val_accuracy: 0.8311 - val_recall_1: 0.8311 - val_precision_1: 0.8311\n",
      "Epoch 160/1000\n",
      "420/420 [==============================] - 39s 93ms/step - loss: 0.0829 - accuracy: 0.8919 - recall_1: 0.8919 - precision_1: 0.8919 - val_loss: 0.4389 - val_accuracy: 0.8330 - val_recall_1: 0.8330 - val_precision_1: 0.8330\n",
      "Epoch 161/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0820 - accuracy: 0.8923 - recall_1: 0.8923 - precision_1: 0.8923 - val_loss: 0.4551 - val_accuracy: 0.8384 - val_recall_1: 0.8384 - val_precision_1: 0.8384\n",
      "Epoch 162/1000\n",
      "420/420 [==============================] - 39s 93ms/step - loss: 0.0829 - accuracy: 0.8908 - recall_1: 0.8908 - precision_1: 0.8908 - val_loss: 0.4525 - val_accuracy: 0.8430 - val_recall_1: 0.8430 - val_precision_1: 0.8430\n",
      "Epoch 163/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0816 - accuracy: 0.8909 - recall_1: 0.8909 - precision_1: 0.8909 - val_loss: 0.4403 - val_accuracy: 0.8359 - val_recall_1: 0.8359 - val_precision_1: 0.8359\n",
      "Epoch 164/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0830 - accuracy: 0.8896 - recall_1: 0.8896 - precision_1: 0.8896 - val_loss: 0.4518 - val_accuracy: 0.8146 - val_recall_1: 0.8146 - val_precision_1: 0.8146\n",
      "Epoch 165/1000\n",
      "420/420 [==============================] - 39s 93ms/step - loss: 0.0821 - accuracy: 0.8907 - recall_1: 0.8907 - precision_1: 0.8907 - val_loss: 0.4328 - val_accuracy: 0.8553 - val_recall_1: 0.8553 - val_precision_1: 0.8553\n",
      "Epoch 166/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0837 - accuracy: 0.8911 - recall_1: 0.8911 - precision_1: 0.8911 - val_loss: 0.4305 - val_accuracy: 0.8264 - val_recall_1: 0.8264 - val_precision_1: 0.8264\n",
      "Epoch 167/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0820 - accuracy: 0.8923 - recall_1: 0.8923 - precision_1: 0.8923 - val_loss: 0.4309 - val_accuracy: 0.8331 - val_recall_1: 0.8331 - val_precision_1: 0.8331\n",
      "Epoch 168/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0813 - accuracy: 0.8929 - recall_1: 0.8929 - precision_1: 0.8929 - val_loss: 0.4315 - val_accuracy: 0.8364 - val_recall_1: 0.8364 - val_precision_1: 0.8364\n",
      "Epoch 169/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0836 - accuracy: 0.8904 - recall_1: 0.8904 - precision_1: 0.8904 - val_loss: 0.4417 - val_accuracy: 0.8334 - val_recall_1: 0.8334 - val_precision_1: 0.8334\n",
      "Epoch 170/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0825 - accuracy: 0.8919 - recall_1: 0.8919 - precision_1: 0.8919 - val_loss: 0.4272 - val_accuracy: 0.8234 - val_recall_1: 0.8234 - val_precision_1: 0.8234\n",
      "Epoch 171/1000\n",
      "420/420 [==============================] - 39s 93ms/step - loss: 0.0823 - accuracy: 0.8912 - recall_1: 0.8912 - precision_1: 0.8912 - val_loss: 0.4540 - val_accuracy: 0.8104 - val_recall_1: 0.8104 - val_precision_1: 0.8104\n",
      "Epoch 172/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0828 - accuracy: 0.8908 - recall_1: 0.8908 - precision_1: 0.8908 - val_loss: 0.4315 - val_accuracy: 0.8433 - val_recall_1: 0.8433 - val_precision_1: 0.8433\n",
      "Epoch 173/1000\n",
      "420/420 [==============================] - 38s 90ms/step - loss: 0.0826 - accuracy: 0.8922 - recall_1: 0.8922 - precision_1: 0.8922 - val_loss: 0.4373 - val_accuracy: 0.8334 - val_recall_1: 0.8334 - val_precision_1: 0.8334\n",
      "Epoch 174/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0803 - accuracy: 0.8934 - recall_1: 0.8934 - precision_1: 0.8934 - val_loss: 0.4508 - val_accuracy: 0.8367 - val_recall_1: 0.8367 - val_precision_1: 0.8367\n",
      "Epoch 175/1000\n",
      "420/420 [==============================] - 38s 92ms/step - loss: 0.0820 - accuracy: 0.8924 - recall_1: 0.8924 - precision_1: 0.8924 - val_loss: 0.4476 - val_accuracy: 0.8217 - val_recall_1: 0.8217 - val_precision_1: 0.8217\n",
      "Epoch 176/1000\n",
      "420/420 [==============================] - 38s 92ms/step - loss: 0.0813 - accuracy: 0.8914 - recall_1: 0.8914 - precision_1: 0.8914 - val_loss: 0.4302 - val_accuracy: 0.8311 - val_recall_1: 0.8311 - val_precision_1: 0.8311\n",
      "Epoch 177/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0816 - accuracy: 0.8924 - recall_1: 0.8924 - precision_1: 0.8924 - val_loss: 0.4541 - val_accuracy: 0.8307 - val_recall_1: 0.8307 - val_precision_1: 0.8307\n",
      "Epoch 178/1000\n",
      "420/420 [==============================] - 38s 92ms/step - loss: 0.0826 - accuracy: 0.8910 - recall_1: 0.8910 - precision_1: 0.8910 - val_loss: 0.4488 - val_accuracy: 0.8300 - val_recall_1: 0.8300 - val_precision_1: 0.8300\n",
      "Epoch 179/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0818 - accuracy: 0.8915 - recall_1: 0.8915 - precision_1: 0.8915 - val_loss: 0.4373 - val_accuracy: 0.8230 - val_recall_1: 0.8230 - val_precision_1: 0.8230\n",
      "Epoch 180/1000\n",
      "420/420 [==============================] - 38s 92ms/step - loss: 0.0813 - accuracy: 0.8908 - recall_1: 0.8908 - precision_1: 0.8908 - val_loss: 0.4578 - val_accuracy: 0.8379 - val_recall_1: 0.8379 - val_precision_1: 0.8379\n",
      "Epoch 181/1000\n",
      "420/420 [==============================] - 38s 90ms/step - loss: 0.0814 - accuracy: 0.8915 - recall_1: 0.8915 - precision_1: 0.8915 - val_loss: 0.4531 - val_accuracy: 0.8356 - val_recall_1: 0.8356 - val_precision_1: 0.8356\n",
      "Epoch 182/1000\n",
      "420/420 [==============================] - 38s 91ms/step - loss: 0.0806 - accuracy: 0.8913 - recall_1: 0.8913 - precision_1: 0.8913 - val_loss: 0.4414 - val_accuracy: 0.8293 - val_recall_1: 0.8293 - val_precision_1: 0.8293\n",
      "Epoch 183/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0811 - accuracy: 0.8915 - recall_1: 0.8915 - precision_1: 0.8915 - val_loss: 0.4660 - val_accuracy: 0.8327 - val_recall_1: 0.8327 - val_precision_1: 0.8327\n",
      "Epoch 184/1000\n",
      "420/420 [==============================] - 39s 92ms/step - loss: 0.0812 - accuracy: 0.8946 - recall_1: 0.8946 - precision_1: 0.8946 - val_loss: 0.4481 - val_accuracy: 0.8351 - val_recall_1: 0.8351 - val_precision_1: 0.8351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ffe2d3ebb0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "hist3 = model.fit(x_train, y_tr, epochs=1000, validation_split=0.1, shuffle=True,class_weight=weights, batch_size=batch_size,use_multiprocessing=True,workers=8,callbacks=[callback])\n",
    "hist3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
