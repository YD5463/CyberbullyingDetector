{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb1278e",
   "metadata": {},
   "source": [
    "# Cyber Bullying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7887365",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T15:30:11.842429Z",
     "start_time": "2021-11-07T15:30:04.671659Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yosef\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yosef\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import re\n",
    "tf.disable_v2_behavior()\n",
    "from autocorrect import spell\n",
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ab1f7b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T15:30:13.175063Z",
     "start_time": "2021-11-07T15:30:11.874427Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from enchant.checker import SpellChecker\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# import re\n",
    "import swifter\n",
    "\n",
    "\n",
    "def merge_datasets(data_path='../Data/Source1') -> pd.DataFrame:\n",
    "    df = pd.DataFrame()\n",
    "    for filename in os.listdir(data_path):\n",
    "        df1 = pd.read_csv(f'{data_path}/{filename}')\n",
    "        df1 = df1[['Text', 'oh_label']]\n",
    "        df = pd.concat([df, df1], axis=0)\n",
    "    df[\"Text\"] = df[\"Text\"].astype(str)\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(\"database merged successfully!\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_punctuation_stopwords_curse_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    def get_curses():\n",
    "        lst = []\n",
    "        with open(\"english_curse.csv\") as curses_file:\n",
    "            for curse in curses_file.readlines():\n",
    "                lst.append(curse.replace(\"\\n\", \"\"))\n",
    "        return lst\n",
    "\n",
    "    curses = get_curses()\n",
    "    features = list(string.punctuation) + list(stopwords.words('english')) + curses\n",
    "    # new_features_cols = []\n",
    "    for ch in features:\n",
    "        df[ch] = df['Text'].astype(str).apply(lambda s: s.count(ch) / len(s))\n",
    "    print(\"add_punctuation_and_stopwords_features successfully!\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_count_misspell_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    def helper(data: str) -> float:\n",
    "        spell = SpellChecker(\"en_US\", data)\n",
    "        counter = 0\n",
    "        for _ in spell:\n",
    "            counter += 1\n",
    "        return counter / len(data)\n",
    "\n",
    "    misspell_count = df[\"Text\"].swifter.apply(helper).rename(\"misspell_count\")\n",
    "    df = pd.concat([df, misspell_count], axis=1)\n",
    "    print(\"add_count_misspell_feature successfully!\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_avg_word_len_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    avg_word_len = df[\"Text\"].astype(str).swifter.apply(\n",
    "        lambda s: pd.Series(nltk.word_tokenize(s)).map(len).mean()).rename(\"avg_word_len\")\n",
    "    df = pd.concat([df, avg_word_len], axis=1)\n",
    "    print(\"add_avg_word_len_feature successfully!\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_avg_sentence_len_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    sentence_count = df[\"Text\"].astype(str).swifter.apply(\n",
    "        lambda text: pd.Series(nltk.sent_tokenize(text)).map(lambda sent: len(nltk.word_tokenize(sent))).mean()) \\\n",
    "        .rename(\"sentence_count\")\n",
    "\n",
    "    df = pd.concat([df, sentence_count], axis=1)\n",
    "    print(\"add_avg_sentence_len_feature successfully!\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_uppercase_count_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    uppercase_count = df['Text'].str.findall(r'[A-Z]').str.len().rename(\"uppercase_count\")/df[\"Text\"].str.len()\n",
    "    df = pd.concat([df, uppercase_count], axis=1)\n",
    "    print(\"add_uppercase_count_feature successfully!\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_pos_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    def group_pos(tag):\n",
    "        groups = {\"noun\": ['NN', 'NNS', 'NNP', 'NNPS'], \"verb\": ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'],\n",
    "                  \"adverb\": ['RB', 'RBR', 'RBS'], \"adjective\": ['JJ', 'JJR', 'JJS']}\n",
    "        for key, group in groups.items():\n",
    "            if tag in group:\n",
    "                return key\n",
    "        return None\n",
    "\n",
    "    features = df[\"Text\"].swifter.apply(lambda s: pd.Series([x[1] for x in nltk.pos_tag(nltk.word_tokenize(s))]).\n",
    "                                        apply(group_pos).value_counts(normalize=True).copy())\n",
    "    print(\"add_pos_features successfully!\")\n",
    "    features = features.fillna(0)\n",
    "    return pd.concat([df, features], axis=1)\n",
    "\n",
    "\n",
    "def to_one_hot_rep(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    cv = CountVectorizer()\n",
    "    data_cv = cv.fit_transform(df[col_name])\n",
    "    data_cv = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "    data_cv[\"oh_label\"] = df[\"oh_label\"]\n",
    "    return data_cv\n",
    "\n",
    "\n",
    "# def filter_noise(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     res = df.sum(axis=0)\n",
    "#     res = res[res > res.median()]\n",
    "#     ls = res.index.to_list()\n",
    "#     del ls[0]\n",
    "#     return df[df.columns.intersection(ls)]\n",
    "\n",
    "def bug_fix(df:pd.DataFrame,ignored_columns:List[str])->pd.DataFrame:\n",
    "    print(\"loaded!\")\n",
    "    df[\"uppercase_count\"] /= df[\"Text\"].str.len()\n",
    "    print(\"fix broken col\")\n",
    "    X_df = df.drop(ignored_columns,axis=1)\n",
    "    normalized_X_df = (X_df-X_df.mean())/X_df.std()\n",
    "    df = pd.concat([df[ignored_columns],normalized_X_df],axis=1)\n",
    "    print(\"normalized\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess(train_part=0.7, use_cache=True) -> (np.ndarray, np.ndarray, np.ndarray, np.ndarray):\n",
    "    print(\"preprocess...\")\n",
    "    cleaned_output_path = \"../Data/cleaned.csv\"\n",
    "    label_name = \"oh_label\"\n",
    "    ignored_columns = [\"Text\", label_name]\n",
    "    if use_cache and os.path.isfile(cleaned_output_path):\n",
    "        df = pd.read_csv(cleaned_output_path,index_col=0)\n",
    "        # df = bug_fix(df,label_name)\n",
    "    else:\n",
    "        df = merge_datasets()\n",
    "        df = add_pos_features(df)\n",
    "        df = add_punctuation_stopwords_curse_features(df)\n",
    "        df = add_uppercase_count_feature(df)\n",
    "        df = add_avg_word_len_feature(df)\n",
    "        df = add_count_misspell_feature(df)\n",
    "        df = add_avg_sentence_len_feature(df)\n",
    "        # df[\"Text\"] = df[\"Text\"].apply(process_row)\n",
    "        # df = to_one_hot_rep(df)\n",
    "#         df.to_csv(cleaned_output_path)\n",
    "        print(\"Saved\")\n",
    "    df = df.fillna(0)\n",
    "    x = df.drop(ignored_columns, axis=1).values\n",
    "    y = df[label_name].values\n",
    "    num_rows = x.shape[0]\n",
    "    mask_train = np.zeros(num_rows, dtype=bool)\n",
    "    mask_train[np.random.choice(num_rows, int(num_rows * train_part), replace=False)] = True\n",
    "    print(mask_train.shape, x.shape, y.shape)\n",
    "    return x[mask_train, :], y[mask_train], x[~mask_train, :], y[~mask_train],df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c462e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T15:31:02.199366Z",
     "start_time": "2021-11-07T15:30:13.208152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess...\n",
      "(448880,) (448880, 595) (448880,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>adjective</th>\n",
       "      <th>adverb</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>#</th>\n",
       "      <th>$</th>\n",
       "      <th>...</th>\n",
       "      <th>xx</th>\n",
       "      <th>xxx</th>\n",
       "      <th>yaoi</th>\n",
       "      <th>yellow showers</th>\n",
       "      <th>yiffy</th>\n",
       "      <th>zoophilia</th>\n",
       "      <th>ðŸ–•</th>\n",
       "      <th>uppercase_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>misspell_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>`- This is not ``creative``.  Those are the di...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.704151</td>\n",
       "      <td>0.130975</td>\n",
       "      <td>-0.511120</td>\n",
       "      <td>0.113224</td>\n",
       "      <td>-0.141856</td>\n",
       "      <td>-0.122218</td>\n",
       "      <td>-0.175769</td>\n",
       "      <td>-0.031636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025241</td>\n",
       "      <td>-0.013459</td>\n",
       "      <td>-0.004278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.097900</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>-0.534211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>`  :: the term ``standard model`` is itself le...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.611175</td>\n",
       "      <td>0.069942</td>\n",
       "      <td>-0.154997</td>\n",
       "      <td>-0.234684</td>\n",
       "      <td>-0.141856</td>\n",
       "      <td>-0.122218</td>\n",
       "      <td>-0.175769</td>\n",
       "      <td>-0.031636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025241</td>\n",
       "      <td>-0.013459</td>\n",
       "      <td>-0.004278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.113050</td>\n",
       "      <td>-0.041753</td>\n",
       "      <td>-0.579315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True or false, the situation as of March 200...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.431937</td>\n",
       "      <td>-1.116819</td>\n",
       "      <td>0.881958</td>\n",
       "      <td>-0.694260</td>\n",
       "      <td>-0.141856</td>\n",
       "      <td>-0.122218</td>\n",
       "      <td>-0.175769</td>\n",
       "      <td>-0.031636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025241</td>\n",
       "      <td>-0.013459</td>\n",
       "      <td>-0.004278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.080581</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>-0.471277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Next, maybe you could work on being less cond...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.516089</td>\n",
       "      <td>1.165731</td>\n",
       "      <td>-1.184439</td>\n",
       "      <td>1.098284</td>\n",
       "      <td>-0.141856</td>\n",
       "      <td>-0.122218</td>\n",
       "      <td>-0.175769</td>\n",
       "      <td>-0.031636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025241</td>\n",
       "      <td>-0.013459</td>\n",
       "      <td>-0.004278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.125048</td>\n",
       "      <td>0.040398</td>\n",
       "      <td>-0.364195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.334839</td>\n",
       "      <td>-1.116819</td>\n",
       "      <td>1.081539</td>\n",
       "      <td>0.176231</td>\n",
       "      <td>-0.141856</td>\n",
       "      <td>-0.122218</td>\n",
       "      <td>-0.175769</td>\n",
       "      <td>-0.031636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025241</td>\n",
       "      <td>-0.013459</td>\n",
       "      <td>-0.004278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.436211</td>\n",
       "      <td>0.252417</td>\n",
       "      <td>-0.671879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448875</th>\n",
       "      <td>She pretty I love this song I miss the old kel...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.091552</td>\n",
       "      <td>-0.466926</td>\n",
       "      <td>0.291530</td>\n",
       "      <td>-0.020666</td>\n",
       "      <td>-0.141856</td>\n",
       "      <td>-0.122218</td>\n",
       "      <td>-0.175769</td>\n",
       "      <td>-0.031636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025241</td>\n",
       "      <td>-0.013459</td>\n",
       "      <td>-0.004278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.083129</td>\n",
       "      <td>-0.073559</td>\n",
       "      <td>1.369299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448876</th>\n",
       "      <td>Status-Online Im ZxkillergirlzX! I'm Zxkillerg...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.903077</td>\n",
       "      <td>-1.116819</td>\n",
       "      <td>0.702335</td>\n",
       "      <td>-0.768874</td>\n",
       "      <td>2.907767</td>\n",
       "      <td>-0.122218</td>\n",
       "      <td>-0.175769</td>\n",
       "      <td>-0.031636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025241</td>\n",
       "      <td>-0.013459</td>\n",
       "      <td>-0.004278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564378</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>1.866509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448877</th>\n",
       "      <td>JR so cute EXO M Better I agree like yeah yeah...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.317604</td>\n",
       "      <td>-0.407845</td>\n",
       "      <td>-0.125021</td>\n",
       "      <td>0.605824</td>\n",
       "      <td>0.144184</td>\n",
       "      <td>-0.122218</td>\n",
       "      <td>-0.175769</td>\n",
       "      <td>-0.031636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025241</td>\n",
       "      <td>-0.013459</td>\n",
       "      <td>-0.004278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073139</td>\n",
       "      <td>-0.144876</td>\n",
       "      <td>0.328092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448878</th>\n",
       "      <td>! !</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.334839</td>\n",
       "      <td>-1.116819</td>\n",
       "      <td>-2.710506</td>\n",
       "      <td>-2.186531</td>\n",
       "      <td>37.615373</td>\n",
       "      <td>-0.122218</td>\n",
       "      <td>-0.175769</td>\n",
       "      <td>-0.031636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025241</td>\n",
       "      <td>-0.013459</td>\n",
       "      <td>-0.004278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.686155</td>\n",
       "      <td>-0.643590</td>\n",
       "      <td>-0.671879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448879</th>\n",
       "      <td>great video and MERRY CHRISTMAS from greece :*...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452385</td>\n",
       "      <td>-0.466926</td>\n",
       "      <td>1.121040</td>\n",
       "      <td>-1.398944</td>\n",
       "      <td>1.938645</td>\n",
       "      <td>-0.122218</td>\n",
       "      <td>-0.175769</td>\n",
       "      <td>-0.031636</td>\n",
       "      <td>...</td>\n",
       "      <td>2.226755</td>\n",
       "      <td>-0.013459</td>\n",
       "      <td>-0.004278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.097356</td>\n",
       "      <td>-0.078146</td>\n",
       "      <td>2.897405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448880 rows × 597 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  oh_label  \\\n",
       "0       `- This is not ``creative``.  Those are the di...       0.0   \n",
       "1       `  :: the term ``standard model`` is itself le...       0.0   \n",
       "2         True or false, the situation as of March 200...       0.0   \n",
       "3        Next, maybe you could work on being less cond...       0.0   \n",
       "4                    This page will need disambiguation.        0.0   \n",
       "...                                                   ...       ...   \n",
       "448875  She pretty I love this song I miss the old kel...       1.0   \n",
       "448876  Status-Online Im ZxkillergirlzX! I'm Zxkillerg...       0.0   \n",
       "448877  JR so cute EXO M Better I agree like yeah yeah...       0.0   \n",
       "448878                                                ! !       0.0   \n",
       "448879  great video and MERRY CHRISTMAS from greece :*...       0.0   \n",
       "\n",
       "        adjective    adverb      noun      verb          !         \"  \\\n",
       "0        0.704151  0.130975 -0.511120  0.113224  -0.141856 -0.122218   \n",
       "1        0.611175  0.069942 -0.154997 -0.234684  -0.141856 -0.122218   \n",
       "2        0.431937 -1.116819  0.881958 -0.694260  -0.141856 -0.122218   \n",
       "3       -0.516089  1.165731 -1.184439  1.098284  -0.141856 -0.122218   \n",
       "4       -1.334839 -1.116819  1.081539  0.176231  -0.141856 -0.122218   \n",
       "...           ...       ...       ...       ...        ...       ...   \n",
       "448875  -0.091552 -0.466926  0.291530 -0.020666  -0.141856 -0.122218   \n",
       "448876   0.903077 -1.116819  0.702335 -0.768874   2.907767 -0.122218   \n",
       "448877  -0.317604 -0.407845 -0.125021  0.605824   0.144184 -0.122218   \n",
       "448878  -1.334839 -1.116819 -2.710506 -2.186531  37.615373 -0.122218   \n",
       "448879   0.452385 -0.466926  1.121040 -1.398944   1.938645 -0.122218   \n",
       "\n",
       "               #         $  ...        xx       xxx      yaoi  yellow showers  \\\n",
       "0      -0.175769 -0.031636  ... -0.025241 -0.013459 -0.004278             0.0   \n",
       "1      -0.175769 -0.031636  ... -0.025241 -0.013459 -0.004278             0.0   \n",
       "2      -0.175769 -0.031636  ... -0.025241 -0.013459 -0.004278             0.0   \n",
       "3      -0.175769 -0.031636  ... -0.025241 -0.013459 -0.004278             0.0   \n",
       "4      -0.175769 -0.031636  ... -0.025241 -0.013459 -0.004278             0.0   \n",
       "...          ...       ...  ...       ...       ...       ...             ...   \n",
       "448875 -0.175769 -0.031636  ... -0.025241 -0.013459 -0.004278             0.0   \n",
       "448876 -0.175769 -0.031636  ... -0.025241 -0.013459 -0.004278             0.0   \n",
       "448877 -0.175769 -0.031636  ... -0.025241 -0.013459 -0.004278             0.0   \n",
       "448878 -0.175769 -0.031636  ... -0.025241 -0.013459 -0.004278             0.0   \n",
       "448879 -0.175769 -0.031636  ...  2.226755 -0.013459 -0.004278             0.0   \n",
       "\n",
       "        yiffy  zoophilia  ðŸ–•  uppercase_count  avg_word_len  misspell_count  \n",
       "0         0.0  -0.003293   0.0        -0.097900      0.000670       -0.534211  \n",
       "1         0.0  -0.003293   0.0        -0.113050     -0.041753       -0.579315  \n",
       "2         0.0  -0.003293   0.0        -0.080581      0.001535       -0.471277  \n",
       "3         0.0  -0.003293   0.0        -0.125048      0.040398       -0.364195  \n",
       "4         0.0  -0.003293   0.0        -0.436211      0.252417       -0.671879  \n",
       "...       ...        ...   ...              ...           ...             ...  \n",
       "448875    0.0  -0.003293   0.0        -0.083129     -0.073559        1.369299  \n",
       "448876    0.0  -0.003293   0.0         0.564378      0.009215        1.866509  \n",
       "448877    0.0  -0.003293   0.0         0.073139     -0.144876        0.328092  \n",
       "448878    0.0  -0.003293   0.0        -8.686155     -0.643590       -0.671879  \n",
       "448879    0.0  -0.003293   0.0        -0.097356     -0.078146        2.897405  \n",
       "\n",
       "[448880 rows x 597 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test,df = preprocess(use_cache=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4331cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T15:31:02.757334Z",
     "start_time": "2021-11-07T15:31:02.451011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns[df.isna().any()].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdbadc92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T15:41:01.935958Z",
     "start_time": "2021-11-07T15:41:01.902519Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, X_train: np.ndarray, y_train: np.ndarray, num_iter=5000, learning_rate=0.001, batch_size=100,\n",
    "                 print_step=1000):\n",
    "        \"\"\"\n",
    "        :param X_train:\n",
    "        :param y_train:\n",
    "        :param num_iter:\n",
    "        :param learning_rate:\n",
    "        :param batch_size: -1 means all\n",
    "        \"\"\"\n",
    "        self.sess = tf.Session()\n",
    "        features = X_train.shape[1]\n",
    "        eps = 1e-12\n",
    "        self.x = tf.placeholder(tf.float32, [None, features])\n",
    "        y_train_variable = tf.placeholder(tf.float32, [None, 1])\n",
    "        W = tf.Variable(tf.zeros([features, 1]))\n",
    "        b = tf.Variable(tf.zeros([1]))\n",
    "        self.y = 1 / (1.0 + tf.exp(-(tf.matmul(self.x, W) + b)))\n",
    "        loss = tf.reduce_mean(-(0.2 * y_train_variable * tf.log(self.y + eps) + 0.8 * (1 - y_train_variable) * tf.log(\n",
    "            1 - self.y + eps)))  # cross entropy\n",
    "        update = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)  # TODO: check other optimizers\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        np.random.shuffle(X_train)\n",
    "        rows_num = X_train.shape[0]\n",
    "        for i in range(0, num_iter):\n",
    "            counter_step = i % (rows_num // batch_size)\n",
    "            X_batch = X_train[counter_step * batch_size:min((counter_step + 1) * batch_size, rows_num)]\n",
    "            Y_batch = y_train[counter_step * batch_size:min((counter_step + 1) * batch_size, rows_num)]\n",
    "            Y_batch = Y_batch.reshape((Y_batch.size, 1))\n",
    "            self.sess.run(update, feed_dict={self.x: X_batch, y_train_variable: Y_batch})\n",
    "\n",
    "            # if i % print_step == 0:\n",
    "            #     print(f\"iteration {i}: loss value is: {loss_value}\")\n",
    "\n",
    "    def predict(self, X_test, thr=0.5):\n",
    "        predictions = self.sess.run(self.y, feed_dict={self.x: X_test})\n",
    "        predictions[predictions >= thr] = 1\n",
    "        predictions[predictions < thr] = 0\n",
    "        return predictions\n",
    "\n",
    "\n",
    "class MLP:\n",
    "    \"\"\"\n",
    "    multi level perceptron implementation using tensorflow version 1\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_train: np.ndarray, y_train, layers_sizes: List[int], learning_rate=0.001, num_iter=5000,\n",
    "                 batch_size=100,\n",
    "                 print_step=100):\n",
    "        \"\"\"\n",
    "\n",
    "        :param X_train:\n",
    "        :param y_train:\n",
    "        :param layers_sizes: len of this list need to be greater than 1\n",
    "        :param learning_rate:\n",
    "        :param num_iter:\n",
    "        :param batch_size:\n",
    "        :param print_step:\n",
    "        \"\"\"\n",
    "        self.sess = tf.Session()\n",
    "        rows_num, features = X_train.shape[0], X_train.shape[1]\n",
    "        eps = 1e-12\n",
    "        self.x = tf.placeholder(tf.float32, [None, features])\n",
    "        y_train_variable = tf.placeholder(tf.float32, [None, 1])\n",
    "        layers_sizes = [features] + layers_sizes.copy() + [1]\n",
    "        W = []\n",
    "        b = []\n",
    "        for i, layer_size in enumerate(layers_sizes[1:]):\n",
    "            W.append(tf.Variable(tf.zeros([layers_sizes[i],layer_size])))\n",
    "            b.append(tf.Variable(tf.zeros(layer_size)))\n",
    "        # ff\n",
    "        prev_output = tf.nn.relu(tf.matmul(self.x, W[0]) + b[0])\n",
    "        for layer_w, layer_b in zip(W[1:], b[1:]):\n",
    "            prev_output = 1 / (1.0 + tf.exp(-(tf.add(tf.matmul(prev_output, layer_w), layer_b))))\n",
    "        self.y = prev_output\n",
    "        loss = tf.reduce_mean(-(y_train_variable * tf.log(self.y + eps) + (1 - y_train_variable) * tf.log(\n",
    "            1 - self.y + eps)))  # cross entropy\n",
    "        update = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)  # TODO: check other optimizers\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        np.random.shuffle(X_train)\n",
    "        for i in range(0, num_iter):\n",
    "            counter_step = i % (rows_num // batch_size)\n",
    "            X_batch = X_train[counter_step * batch_size:min((counter_step + 1) * batch_size, rows_num)]\n",
    "            Y_batch = y_train[counter_step * batch_size:min((counter_step + 1) * batch_size, rows_num)]\n",
    "            Y_batch = Y_batch.reshape((Y_batch.size, 1))\n",
    "            self.sess.run(update, feed_dict={self.x: X_batch, y_train_variable: Y_batch})\n",
    "\n",
    "    def predict(self, X_test, thr=0.5):\n",
    "        predictions = self.sess.run(self.y, feed_dict={self.x: X_test})\n",
    "        predictions[predictions >= thr] = 1\n",
    "        predictions[predictions < thr] = 0\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "980add29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T14:53:51.357226Z",
     "start_time": "2021-11-07T14:50:25.442198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      1.00      0.93    117492\n",
      "         1.0       0.17      0.00      0.00     17172\n",
      "\n",
      "    accuracy                           0.87    134664\n",
      "   macro avg       0.52      0.50      0.47    134664\n",
      "weighted avg       0.78      0.87      0.81    134664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# logistic = LogisticRegression(x_train,y_train,num_iter=500000)\n",
    "# predictions = logistic.predict(x_test)\n",
    "# print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa8daf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-07T15:41:58.654Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "mlp = MLP(x_train,y_train,[5,5,5])\n",
    "mlp_predictions = mlp.predict(x_test)\n",
    "print(classification_report(y_test, mlp_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761e944a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd454178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df7efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d66b6b8",
   "metadata": {},
   "source": [
    "## Data cleanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eb9c79d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T15:56:49.423700Z",
     "start_time": "2021-10-25T15:56:49.320904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>UserIndex</th>\n",
       "      <th>Text</th>\n",
       "      <th>Number of Comments</th>\n",
       "      <th>Number of Subscribers</th>\n",
       "      <th>Membership Duration</th>\n",
       "      <th>Number of Uploads</th>\n",
       "      <th>Profanity in UserID</th>\n",
       "      <th>Age</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>X1</td>\n",
       "      <td>Does N.e.bodyelse Hear her Crazy ass Screamin ...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>X2</td>\n",
       "      <td>There are so many things that are incorrect wi...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>X3</td>\n",
       "      <td>3:26 hahah my boyfriend showed this song to me...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>X2218</td>\n",
       "      <td>dick beyonce fuck y a ass hole you are truely ...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>X5</td>\n",
       "      <td>DongHaeTaemin and Kai ;A; luhansehun and bacon...</td>\n",
       "      <td>11</td>\n",
       "      <td>173</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>3464</td>\n",
       "      <td>X3465</td>\n",
       "      <td>She pretty I love this song I miss the old kel...</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>3465</td>\n",
       "      <td>X3466</td>\n",
       "      <td>Status-Online Im ZxkillergirlzX! I'm Zxkillerg...</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>3466</td>\n",
       "      <td>X3467</td>\n",
       "      <td>JR so cute EXO M Better I agree like yeah yeah...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>3467</td>\n",
       "      <td>X3468</td>\n",
       "      <td>! !</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>3468</td>\n",
       "      <td>X3469</td>\n",
       "      <td>great video and MERRY CHRISTMAS from greece :*...</td>\n",
       "      <td>27</td>\n",
       "      <td>220</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3464 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index UserIndex                                               Text  \\\n",
       "0         0        X1  Does N.e.bodyelse Hear her Crazy ass Screamin ...   \n",
       "1         1        X2  There are so many things that are incorrect wi...   \n",
       "2         2        X3  3:26 hahah my boyfriend showed this song to me...   \n",
       "3         3     X2218  dick beyonce fuck y a ass hole you are truely ...   \n",
       "4         4        X5  DongHaeTaemin and Kai ;A; luhansehun and bacon...   \n",
       "...     ...       ...                                                ...   \n",
       "3459   3464     X3465  She pretty I love this song I miss the old kel...   \n",
       "3460   3465     X3466  Status-Online Im ZxkillergirlzX! I'm Zxkillerg...   \n",
       "3461   3466     X3467  JR so cute EXO M Better I agree like yeah yeah...   \n",
       "3462   3467     X3468                                                ! !   \n",
       "3463   3468     X3469  great video and MERRY CHRISTMAS from greece :*...   \n",
       "\n",
       "      Number of Comments  Number of Subscribers  Membership Duration  \\\n",
       "0                     10                      1                    3   \n",
       "1                      3                      0                    6   \n",
       "2                      7                      0                    3   \n",
       "3                     34                      0                    3   \n",
       "4                     11                    173                    5   \n",
       "...                  ...                    ...                  ...   \n",
       "3459                  15                      2                    4   \n",
       "3460                   4                     28                    4   \n",
       "3461                  23                      0                    5   \n",
       "3462                   5                      0                    6   \n",
       "3463                  27                    220                    4   \n",
       "\n",
       "      Number of Uploads  Profanity in UserID  Age  oh_label  \n",
       "0                     3                    0   15         0  \n",
       "1                     5                    0   31         0  \n",
       "2                     5                    0   43         1  \n",
       "3                     5                    0   44         1  \n",
       "4                     5                    0   21         0  \n",
       "...                 ...                  ...  ...       ...  \n",
       "3459                  7                    0   23         1  \n",
       "3460                 23                    1   15         0  \n",
       "3461                  3                    0   33         0  \n",
       "3462                  5                    0   38         0  \n",
       "3463                 30                    0   18         0  \n",
       "\n",
       "[3464 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Data/Source1/youtube_parsed_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4be529a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T15:56:49.471523Z",
     "start_time": "2021-10-25T15:56:49.446565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does N.e.bodyelse Hear her Crazy ass Screamin ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There are so many things that are incorrect wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3:26 hahah my boyfriend showed this song to me...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dick beyonce fuck y a ass hole you are truely ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DongHaeTaemin and Kai ;A; luhansehun and bacon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>She pretty I love this song I miss the old kel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>Status-Online Im ZxkillergirlzX! I'm Zxkillerg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>JR so cute EXO M Better I agree like yeah yeah...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>! !</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>great video and MERRY CHRISTMAS from greece :*...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3464 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  oh_label\n",
       "0     Does N.e.bodyelse Hear her Crazy ass Screamin ...         0\n",
       "1     There are so many things that are incorrect wi...         0\n",
       "2     3:26 hahah my boyfriend showed this song to me...         1\n",
       "3     dick beyonce fuck y a ass hole you are truely ...         1\n",
       "4     DongHaeTaemin and Kai ;A; luhansehun and bacon...         0\n",
       "...                                                 ...       ...\n",
       "3459  She pretty I love this song I miss the old kel...         1\n",
       "3460  Status-Online Im ZxkillergirlzX! I'm Zxkillerg...         0\n",
       "3461  JR so cute EXO M Better I agree like yeah yeah...         0\n",
       "3462                                                ! !         0\n",
       "3463  great video and MERRY CHRISTMAS from greece :*...         0\n",
       "\n",
       "[3464 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['index',\"UserIndex\",\"Number of Comments\",\"Number of Subscribers\",\"Membership Duration\",\"Number of Uploads\",\"Profanity in UserID\",\"Age\"], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70a598ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T15:56:49.611128Z",
     "start_time": "2021-10-25T15:56:49.595171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"There are so many things that are incorrect with your comment it's unbelievable. Guns don't kill people. A gun doesn't get up off a table and then shoot someone. He's not the reason soldiers are at war he's merely showing us weapons and explaining how they work and whether he likes them or not. You blame him for violent video games...Why would this guy mess around with video games when he has real weapons he can use and practice with. I can't say much more coz I don't have more space. Retard. This is all we need an Australian version of 1 Direction.... my dick was bleeding from how hard I was masturbating to this\",\n",
       " 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Text\"][1],df[\"oh_label\"][1],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "315359f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T15:56:50.065798Z",
     "start_time": "2021-10-25T15:56:49.737284Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\eviat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\eviat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "words = set(nltk.corpus.words.words())\n",
    "spell = SpellChecker()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def process_row(row):\n",
    "    row = row.translate(str.maketrans('', '', string.punctuation))\n",
    "    row = re.sub('\\w*\\d\\w*', ' ', row) #remove words with numbers\n",
    "    row = re.sub('[‘’“”…]', ' ', row)\n",
    "    row = row.lower()\n",
    "    stop_words = stopwords.words('english')\n",
    "    row = \" \".join(lemmatizer.lemmatize(w) for w in nltk.wordpunct_tokenize(row)) # spell checker\n",
    "    row = \" \".join(spell.correction(w) for w in nltk.wordpunct_tokenize(row)) # spell checker\n",
    "    return \" \".join(w for w in nltk.wordpunct_tokenize(row) if w in words and w not in stop_words) # word exist in corpus and remove stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "985d5606",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T17:19:56.187995Z",
     "start_time": "2021-10-25T15:56:50.067760Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doe hear crazy hoe say stupid hoe nobody see b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>many thing incorrect comment unbelievable gun ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>song love seizure u corgi training want rape</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dick hole dog bitch look like dick god make si...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kai bacon ad kai henry dabba love rapping yeah...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>pretty love song miss old kelly yes love song ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>band band practice</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>cute better agree like yeah yeah yeah wow wow ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>great video merry ever love song great love ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3464 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  oh_label\n",
       "0     doe hear crazy hoe say stupid hoe nobody see b...         0\n",
       "1     many thing incorrect comment unbelievable gun ...         0\n",
       "2          song love seizure u corgi training want rape         1\n",
       "3     dick hole dog bitch look like dick god make si...         1\n",
       "4     kai bacon ad kai henry dabba love rapping yeah...         0\n",
       "...                                                 ...       ...\n",
       "3459  pretty love song miss old kelly yes love song ...         1\n",
       "3460                                 band band practice         0\n",
       "3461  cute better agree like yeah yeah yeah wow wow ...         0\n",
       "3462                                                            0\n",
       "3463  great video merry ever love song great love ba...         0\n",
       "\n",
       "[3464 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Text\"] = df[\"Text\"].apply(process_row)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76563d1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T17:19:56.518702Z",
     "start_time": "2021-10-25T17:19:56.189958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abase</th>\n",
       "      <th>abate</th>\n",
       "      <th>abb</th>\n",
       "      <th>abbas</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abdicate</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>...</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zo</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoned</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3464 rows × 13394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abandon  abandoned  abase  abate  abb  abbas  abbey  abbreviation  \\\n",
       "0           0          0      0      0    0      0      0             0   \n",
       "1           0          0      0      0    0      0      0             0   \n",
       "2           0          0      0      0    0      0      0             0   \n",
       "3           0          0      0      0    0      0      0             0   \n",
       "4           0          0      0      0    0      0      0             0   \n",
       "...       ...        ...    ...    ...  ...    ...    ...           ...   \n",
       "3459        0          0      0      0    0      0      0             0   \n",
       "3460        0          0      0      0    0      0      0             0   \n",
       "3461        0          0      0      0    0      0      0             0   \n",
       "3462        0          0      0      0    0      0      0             0   \n",
       "3463        0          0      0      0    0      0      0             0   \n",
       "\n",
       "      abdicate  abdomen  ...  zipper  zo  zombie  zone  zoned  zoning  zoo  \\\n",
       "0            0        0  ...       0   0       0     0      0       0    0   \n",
       "1            0        0  ...       0   0       0     0      0       0    0   \n",
       "2            0        0  ...       0   0       0     0      0       0    0   \n",
       "3            0        0  ...       0   0       0     0      0       0    0   \n",
       "4            0        0  ...       0   0       0     0      0       0    0   \n",
       "...        ...      ...  ...     ...  ..     ...   ...    ...     ...  ...   \n",
       "3459         0        0  ...       0   0       0     0      0       0    0   \n",
       "3460         0        0  ...       0   0       0     0      0       0    0   \n",
       "3461         0        0  ...       0   0       0     0      0       0    0   \n",
       "3462         0        0  ...       0   0       0     0      0       0    0   \n",
       "3463         0        0  ...       0   0       0     0      0       0    0   \n",
       "\n",
       "      zoom  zucchini  oh_label  \n",
       "0        0         0         0  \n",
       "1        0         0         0  \n",
       "2        0         0         1  \n",
       "3        0         0         1  \n",
       "4        0         0         0  \n",
       "...    ...       ...       ...  \n",
       "3459     0         0         1  \n",
       "3460     0         0         0  \n",
       "3461     0         0         0  \n",
       "3462     0         0         0  \n",
       "3463     0         0         0  \n",
       "\n",
       "[3464 rows x 13394 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "data_cv = cv.fit_transform(df.Text)\n",
    "data_cv = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_cv[\"oh_label\"] = df[\"oh_label\"]\n",
    "data_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5137689",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T17:20:05.890719Z",
     "start_time": "2021-10-25T17:19:56.520479Z"
    }
   },
   "outputs": [],
   "source": [
    "data_cv.to_csv(\"./Data/Source1/Youtube_Clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c40bb75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T17:26:38.390354Z",
     "start_time": "2021-10-25T17:26:30.697459Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaner = pd.read_csv(\"./Data/Source1/Youtube_Clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a7d9d469",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T17:42:46.343903Z",
     "start_time": "2021-10-25T17:42:46.226859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandoned</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abomination</th>\n",
       "      <th>abortion</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absorbed</th>\n",
       "      <th>abuse</th>\n",
       "      <th>abusive</th>\n",
       "      <th>...</th>\n",
       "      <th>zeppelin</th>\n",
       "      <th>zero</th>\n",
       "      <th>zest</th>\n",
       "      <th>zip</th>\n",
       "      <th>zo</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3464 rows × 5758 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abandoned  ability  able  abomination  abortion  absolute  absolutely  \\\n",
       "0             0        0     0            0         0         0           0   \n",
       "1             0        0     0            0         0         0           0   \n",
       "2             0        0     0            0         0         0           0   \n",
       "3             0        0     0            0         0         0           0   \n",
       "4             0        0     0            0         0         0           0   \n",
       "...         ...      ...   ...          ...       ...       ...         ...   \n",
       "3459          0        0     0            0         0         0           0   \n",
       "3460          0        0     0            0         0         0           0   \n",
       "3461          0        0     0            0         0         0           0   \n",
       "3462          0        0     0            0         0         0           0   \n",
       "3463          0        0     0            0         0         0           0   \n",
       "\n",
       "      absorbed  abuse  abusive  ...  zeppelin  zero  zest  zip  zo  zombie  \\\n",
       "0            0      0        0  ...         0     0     0    0   0       0   \n",
       "1            0      0        0  ...         0     0     0    0   0       0   \n",
       "2            0      0        0  ...         0     0     0    0   0       0   \n",
       "3            0      0        0  ...         0     0     0    0   0       0   \n",
       "4            0      0        0  ...         0     0     0    0   0       0   \n",
       "...        ...    ...      ...  ...       ...   ...   ...  ...  ..     ...   \n",
       "3459         0      0        0  ...         0     0     0    0   0       0   \n",
       "3460         0      0        0  ...         0     0     0    0   0       0   \n",
       "3461         0      0        0  ...         0     0     0    0   0       0   \n",
       "3462         0      0        0  ...         0     0     0    0   0       0   \n",
       "3463         0      0        0  ...         0     0     0    0   0       0   \n",
       "\n",
       "      zone  zoo  zoom  oh_label  \n",
       "0        0    0     0         0  \n",
       "1        0    0     0         0  \n",
       "2        0    0     0         1  \n",
       "3        0    0     0         1  \n",
       "4        0    0     0         0  \n",
       "...    ...  ...   ...       ...  \n",
       "3459     0    0     0         1  \n",
       "3460     0    0     0         0  \n",
       "3461     0    0     0         0  \n",
       "3462     0    0     0         0  \n",
       "3463     0    0     0         0  \n",
       "\n",
       "[3464 rows x 5758 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = cleaner.sum(axis=0)\n",
    "res = res[res > res.median()]\n",
    "ls = res.index.to_list()\n",
    "del ls[0]\n",
    "ls\n",
    "pandas_df = cleaner[cleaner.columns.intersection(ls)]\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4612b5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbe90ffd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T17:20:05.922145Z",
     "start_time": "2021-10-25T17:20:05.892128Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1e3698d2cb0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'oh_label'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_cv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"oh_label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'drop'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(pandas_df.drop('oh_label', axis=1), pandas_df[\"oh_label\"], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad2513",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T15:56:38.573364Z",
     "start_time": "2021-10-25T15:49:21.624Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e7f6ed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T14:18:26.752106Z",
     "start_time": "2021-10-25T14:18:26.737149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91       998\n",
      "           1       0.25      0.11      0.15       146\n",
      "\n",
      "    accuracy                           0.84      1144\n",
      "   macro avg       0.56      0.53      0.53      1144\n",
      "weighted avg       0.80      0.84      0.82      1144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df810c",
   "metadata": {},
   "source": [
    "## Basic FF NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efb057",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T10:36:29.577521Z",
     "start_time": "2021-10-25T10:36:29.561576Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf6d8728",
   "metadata": {},
   "source": [
    "## RNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee951d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
